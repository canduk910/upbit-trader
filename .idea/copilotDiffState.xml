<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/README.md">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/README.md" />
              <option name="originalContent" value="# Upbit 자동 트레이딩 봇 — 전체 구조와 흐름을 쉽게 이해하기&#10;&#10;이 프로젝트는 Upbit(업비트) 거래소에 연결해 자동으로 코인 전략을 실행하고, Streamlit UI와 FastAPI를 통해 설정·상황을 확인할 수 있는 개발·학습용 시스템입니다. 이 안내서는 사용 기술, 소스별 기능, 실행 흐름을 자주 쓰는 순서로 정리해 초등학생도 흐름을 따라갈 수 있게 설명합니다.&#10;&#10;##  핵심 목적과 사용자에게 주는 가치&#10;- **24시간 시장 관찰 자동화**: 변동성 돌파, 듀얼 모멘텀 등 전략을 자동으로 계산해 주문 후보를 만들고 켈리공식을 섞어 투자할 금액을 조절합니다.&#10;- **UI·API·스크립트로 제어**: Streamlit UI, FastAPI 엔드포인트, `scripts/run_dev.sh` 등을 통해 설정, 스크리닝, 워처, 백그라운드 작업을 쉽게 조작하고 로그를 확인할 수 있습니다.&#10;- **만들기 쉬운 실험 환경**: Docker와 로컬 모드 모두에서 실행 가능하므로 전략, 자금관리, 프리페치 성능을 바꿔가며 연구 가능합니다.&#10;&#10;##  기술 스택 요약&#10;| 층           | 핵심 기술                                                           | 역할 요약                                                                             |&#10;|-------------|-----------------------------------------------------------------|-----------------------------------------------------------------------------------|&#10;| 애플리케이션 레이어  | **Python 3.13**, `FastAPI`, `streamlit`, `plotly`, `requests`   | 서버 API, UI, 차트, HTTP 통신을 처리합니다. FastAPI는 설정/스크리닝/API 먹통 체크, Streamlit는 UI를 구현합니다. |&#10;| 전략·자금관리 로직  | `server.strategy`, `server.money_manager`, `Kelly criterion` 구현 | 변동성 돌파·모멘텀·RSI 전략과 Kelly 공식을 하나의 파이프라인으로 결합하여 주문 결정을 내립니다.                        |&#10;| 데이터 캐시·히스토리 | `Redis` (옵션), 내부 캐시, `runtime/history/positions_history.json`   | 클라이언트(특히 UI)의 429 발생을 막기 위해 prefetch 데이터를 모아두고, 파일 기반 히스토리로 시계열 차트를 그립니다.         |&#10;| 실행 인프라      | `uvicorn`, `docker compose`, `bash scripts`                     | 개발/배포 모드에서 백엔드와 UI를 동시에 띄우고 Docker 네트워크에서 서로 통신합니다.                               |&#10;&#10;핵심 개념을 아주 쉽게 설명&#10;- 전략(strategy): 코인 가격 데이터(캔들)를 보고 ‘사야 한다/팔아야 한다’고 결정하는 규칙입니다.&#10;- 켈리공식(Kelly criterion): 이길 확률과 기대 수익에 근거해 한 번에 투자할 금액을 계산하는 방법입니다.&#10;- 스크리닝(screening): 여러 종목을 모아 놓고 변동성이 큰 종목을 골라내는 기능입니다.&#10;- 워처(watcher): 실시간(폴링)으로 조건을 체크해 이벤트가 발생하면 로그/알림을 남기는 작은 백그라운드 작업입니다.&#10;&#10;프로젝트 구조 (중요한 파일과 역할)&#10;```&#10;/upbit-trader&#10;├── server/                # 서버(백엔드) 코드 (FastAPI + 감시봇 로직)&#10;│   ├── api.py             # FastAPI REST API: 설정, 스크리닝, watcher, klines_batch 등&#10;│   ├── bot.py             # 봇의 메인 루프: 시세 조회 → 전략 평가 → 주문(모의/실제)&#10;│   ├── upbit_api.py       # Upbit와 통신하는 로직(pyupbit 또는 직접 HTTP 사용)&#10;│   ├── strategy.py        # 여러 전략 구현 (VolatilityBreakout, DualMomentum, RSI 등)&#10;│   ├── money_manager.py   # 켈리공식 등 자금관리 로직&#10;│   ├── config.py          # runtime/config.json 읽기/쓰기, 전역 설정&#10;│   └── logger.py          # 로그 설정&#10;├── ui/                    # Streamlit 기반 사용자 인터페이스&#10;│   └── ui_dashboard.py    # 설정 편집, 종목 스크리닝, 워처 제어 페이지&#10;├── runtime/               # 실행 시 사용하는 설정 (PID, 히스토리 등)&#10;│   └── config.json        # 기본 실행 설정(전략, 마켓, 파라미터 등)&#10;│   └── history/            # 포지션 히스토리 JSON 파일 저장소&#10;├── logs/                  # 실행 로그 파일 저장소&#10;│   ├── backend.log        # 백엔드 로그&#10;│   ├── ui.log             # UI 로그&#10;│   └── trading_bot.log    # 트레이딩 봇 로그&#10;├── scripts/&#10;│   └── run_dev.sh         # 개발용 실행 스크립트 (백엔드 + UI 동시 실행 등)&#10;├── docker-compose.yml      # Docker 서비스 정의&#10;├── docker-compose.override.yml  # 개발용 바인드 마운트(코드 수정시 재시작 흐름 제어)&#10;├── requirements.txt        # Python 의존성 목록&#10;└── README.md&#10;```&#10;&#10;### 주요 폴더와 역할&#10;- `server/`: FastAPI 엔드포인트(API, 설정 저장/재로딩, 스크리닝, watcher·prefetch 등), Upbit 연동, 전략/자금 관리, 로그 설정, 히스토리 저장기를 포함합니다.&#10;- `ui/`: Streamlit 대시보드. 설정편집, 종목스크리닝, 이벤트 감시자 제어, 원화잔고/포지션 분석 등 여러 메뉴를 버튼 형식의 사이드바로 제공합니다.&#10;- `runtime/`: `config.json`, 실행 중 PID 파일, `history/positions_history.json` 등을 담아 상태를 보존합니다. 히스토리 디렉터리는 새로 만든 JSON 파일을 통해 과거 포지션 가치를 저장합니다.&#10;- `scripts/run_dev.sh`: 로컬에서 backend + UI를 순서대로 띄우고 로그를 모으며, `all`, `backend`, `ui` 모드를 지원합니다.&#10;- `docker-compose*.yml` + `Dockerfile.*`: Redis, backend, UI, bot 컨테이너를 조합해 통합 테스트/운영 환경을 제공합니다.&#10;&#10;##  주요 소스별 요약&#10;| 파일/모듈                                  | 기술                 | 기능 한 줄 요약                                                                                                                                                                                                   |&#10;|----------------------------------------|--------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|&#10;| `server/api.py`                        | FastAPI            | `/balances`, `/positions`, `/screen/volatility_top`, `/klines_batch`, `/watcher/*`, `/config`, `/reload`, `/positions/history`를 노출하여 설정/데이터/워처 제어를 처리한다. 토큰 버킷·세마포어로 Upbit 호출을 제한하고 Redis 또는 인메모리 캐시를 사용한다. |&#10;| `server/bot.py`                        | Python 스레드 기반 루프   | `runtime/config.json`을 읽고 주기적으로 전략을 평가하여 주문을 생성하고, 로깅 및 상태 업데이트를 남긴다.                                                                                                                                       |&#10;| `server/strategy.py`                   | 전략 구현              | 변동성 돌파, 듀얼 모멘텀(절대/상대), RSI 조합 등을 정의하고, 단일 전략으로부터 신호를 만드는 도우미 함수가 있다.                                                                                                                                        |&#10;| `server/money_manager.py`              | Kelly criterion    | 승률·수익비를 받아 주문 당 투자금과 레버리지 등을 계산한다.                                                                                                                                                                          |&#10;| `server/history.py`                    | JSON 기반 히스토리 스토어   | `runtime/history/positions_history.json`에 `ts`, `total_equity`, 각 종목의 평가금액·손익을 기록하고 읽는 헬퍼. UI 시계열 차트를 위해 `GET /positions/history`를 제공한다.                                                                    |&#10;| `server/config.py`                     | 설정 파싱              | `.env`, `runtime/config.json` 등을 읽어 글로벌 설정을 관리하고, 변경 시 저장/재시작을 안내한다.                                                                                                                                        |&#10;| `server/logger.py`                     | logging            | 로컬/컨테이너 환경 모두에서 통일된 로그 포맷과 파일/스트림 핸들러를 만든다.                                                                                                                                                                 |&#10;| `server/upbit_api.py`                  | pyupbit + https 호출 | 인증 키가 있으면 private API를 사용; 그 외에는 public klines만 호출하며 rate 제한을 최소화하기 위한 반복 로직이 있다.                                                                                                                           |&#10;| `ui/ui_dashboard.py`                   | Streamlit          | 버튼형 사이드바, 설정 폼, 화면별 상태(스크리닝 차트, watcher 상태, 포지션 테이블/차트) 및 `/positions/history`를 이용한 시계열 라인 및 손익 바 차트를 렌더링한다.                                                                                                |&#10;| `scripts/run_dev.sh`                   | Bash               | backend(Uvicorn) → `wait_for_backend()` → UI(Streamlit)를 순차 실행하며 `logs/`로 실시간 로그를 남긴다.                                                                                                                      |&#10;| `Dockerfile.*` + `docker-compose*.yml` | Docker             | backend/api/ui/bot 컨테이너와 Redis를 정의하고, UI에서는 `STREAMLIT_API_BASE`로 `http://backend:8000`을 기본값으로 잡아 통합 서비스를 실행한다.                                                                                             |&#10;&#10;##  데이터 흐름 (prefetch → 히스토리 → UI)&#10;1. `server/api.py` prefetched klines/positions → Redis 또는 인메모리 캐시에 저장 (`_cache_set/_cache_get`).&#10;2. `/positions` 호출 시 현재 포지션/평가금액/손익을 계산 → nodal history JSON(새로 만든 `server/history.py`)에 `ts` 단위로 누적 저장.&#10;3. Streamlit 포지션 페이지는 `/positions`, `/positions/history`를 연속 호출 → 표, 캔들+MA+RSI, 평가금액/손익 차트를 각각 렌더링.&#10;4. `runtime/history` 디렉터리가 존재하므로 컨테이너 재기동 후에도 최대 N개(기본 720개) 히스토리 유지해 시계열 차트를 부드럽게 만듭니다.&#10;&#10;###  WebSocket→캐시→봇/API/UI 흐름&#10;1. `server/ws_listener_private.py`(MyOrder 전용)와 `server/ws_listener_public.py`(공용 ticker 전용)로 WebSocket 핸들러가 분리되어 있고, `ws_timeframes`(`runtime/config.json`의 `timeframe`, `ws_timeframes` 필드 포함)를 기반으로 `ticker` 메시지로부터 1분봉을 집계합니다.&#10;2. 실제 업비트 주문 `order` 이벤트는 `runtime/history/exec_history.json`에 기록되고, `ws:trades:{ticker}` 리스트와 `ws:candles:{timeframe}:{ticker}` 키로 Redis에도 저장됩니다.&#10;3. `server/bot.py`는 가장 먼저 Redis `ws:candles:{desired_timeframe}:{ticker}` 캐시를 읽고(없으면 REST 호출), `ws_listener_private`이 만든 여러 타임프레임을 그대로 전략에 공급합니다.&#10;4. FastAPI의 `/klines_batch`는 기존 `ticker|timeframe|count` 캐시를 사용하므로 WebSocket 캔들 캐시와는 별개이며, UI는 항상 `/klines_batch` → `FastAPI` → `_cache_get` 흐름을 통해 데이터를 가져옵니다.&#10;&#10;```&#10;[Upbit WS ticker/order]&#10;           ↘&#10;      WebSocket Listener&#10;           ↘───────────┬──────────────┬─────────────&#10;                       │              │&#10;             redis ws:candles:*  runtime/history/exec_history.json&#10;                       │              │&#10;        ┌──────────────┴──────────────┴────────────┐&#10;        │                    │                    │&#10;    bot (Redis 우선)   FastAPI /klines_batch   Streamlit UI&#10; (ws:candles:tf:ticker)   (ticker|tf|count)     → /klines_batch&#10;```&#10;&#10;- 이 다이어그램은 WebSocket 수신이 Redis에 다양한 타임프레임 캐시를 만들고, bot/API/UI가 각자 필요한 저장소에서 먼저 읽도록 설계된 점을 강조합니다.&#10;- `runtime/config.json`에 `ws_timeframes`를 넣으면 `ws_listener`가 지정한 순서대로 간격을 추가로 계산합니다(예: `[&quot;minute1&quot;,&quot;minute5&quot;,&quot;minute15&quot;]`).&#10;- Redis가 없는 환경에서는 `bot`/`ui`/`api`가 각각 fallback 로직으로 REST 호출을 사용하지만, WebSocket과 `exec_history`는 계속 로깅됩니다.&#10;&#10;## ️ 실시간 WebSocket 수신 및 exec 기록&#10;1. `server/ws_listener.py`는 Upbit WebSocket(`ticker`+`trade`)을 구독해 Redis에 실시간 payload를 저장하고 `/ws/*` 엔드포인트로 상태를 제어할 수 있게 합니다.&#10;2. 체결(trade) 이벤트는 `runtime/history/exec_history.json`에 append 되어 영구 보존되며, Redis에는 `ws:trades:&lt;ticker&gt;` 리스트(최대 200개)도 유지합니다.&#10;3. FastAPI에서 `ws_start`, `ws_stop`, `ws_status`를 제공하므로 UI나 `curl`로 리스너를 직접 시작/중지하거나 상태를 확인할 수 있습니다.&#10;4. 이 데이터를 UI나 봇이 실시간 UI/알림용으로 조회하려면 Redis `ws:ticker:...` 키 또는 `runtime/history/exec_history.json`을 읽도록 새 위젯/로직을 추가하세요.&#10;&#10;##  실행하기 (로컬 &amp; Docker)&#10;### 1) 로컬 개발&#10;```bash&#10;python -m venv venv&#10;source venv/bin/activate&#10;pip install -r requirements.txt&#10;chmod +x scripts/run_dev.sh&#10;./scripts/run_dev.sh all&#10;```&#10;- 위 스크립트는 로컬에서 backend(uvicorn)과 UI(streamlit)를 동시에 실행합니다.&#10;- `--no-reload` 또는 `--detached` 같은 플래그로 동작을 조절할 수 있습니다. `./scripts/run_dev.sh --help`로 확인하세요.&#10;&#10;개별 컴포넌트 실행&#10;- 백엔드만: uvicorn server.api:app --host 127.0.0.1 --port 8000&#10;- UI만: streamlit run ui/ui_dashboard.py&#10;- 봇: python -m server.bot&#10;&#10;### 2) Docker (권장 통합 테스트)&#10;```bash&#10;docker compose up --build&#10;docker compose up&#10;```&#10;- `docker-compose.override.yml`는 개발용 바인드 마운트를 추가하고, UI는 `STREAMLIT_API_BASE=http://backend:8000`으로 backend를 호출합니다.&#10;- 필요시 `docker compose logs -f backend` 등으로 로그를 확인하고 `docker compose down`으로 정리합니다.&#10;&#10;### 3) 개별 컴포넌트 (안정적으로 짧게 실행)&#10;```bash&#10;uvicorn server.api:app --reload --host 127.0.0.1 --port 8000&#10;streamlit run ui/ui_dashboard.py&#10;python -m server.bot&#10;```&#10;- FastAPI는 `--reload`로 코드 변경시 재시작(개발 전용).&#10;- Streamlit UI는 `--server.port` 등을 조정해 여러 창 테스트 가능합니다.&#10;&#10;설정 파일 설명 (runtime/config.json)&#10;- strategy_name: 사용할 전략 이름(예: VolatilityBreakout, DualMomentum, RSI)&#10;- market: 거래할 마켓 (예: KRW-BTC)&#10;- timeframe: 캔들 단위(예: minute5, minute15)&#10;- candle_count: 과거 캔들 수&#10;- loop_interval_sec: 봇이 다음 루프를 시작하기까지 대기 시간(초)&#10;- order_settings: 주문과 관련된 최소/기본 금액 설정&#10;- use_kelly_criterion: 켈리공식 사용 여부&#10;- kelly_criterion: 켈리용 파라미터(win_rate, payoff_ratio, fraction)&#10;- strategy_params: 전략별 세부 파라미터(예: VolatilityBreakout.k_value)&#10;&#10;간단한 예시 (runtime/config.json)&#10;```json&#10;{&#10;  &quot;strategy_name&quot;: &quot;VolatilityBreakout&quot;,&#10;  &quot;market&quot;: &quot;KRW-BTC&quot;,&#10;  &quot;timeframe&quot;: &quot;minute5&quot;,&#10;  &quot;candle_count&quot;: 200,&#10;  &quot;loop_interval_sec&quot;: 5,&#10;  &quot;order_settings&quot;: { &quot;min_order_amount&quot;: 5500, &quot;trade_amount_krw&quot;: 6000 },&#10;  &quot;use_kelly_criterion&quot;: true,&#10;  &quot;kelly_criterion&quot;: { &quot;win_rate&quot;: 0.65, &quot;payoff_ratio&quot;: 1.2, &quot;fraction&quot;: 0.5 },&#10;  &quot;strategy_params&quot;: {&#10;    &quot;VolatilityBreakout&quot;: { &quot;k_value&quot;: 0.5 },&#10;    &quot;DualMomentum&quot;: { &quot;window&quot;: 12 },&#10;    &quot;RSI&quot;: { &quot;period&quot;: 14, &quot;oversold&quot;: 30, &quot;overbought&quot;: 70 }&#10;  },&#10;  &quot;prefetch_count&quot;: 200,&#10;  &quot;prefetch_interval_sec&quot;: 60,&#10;  &quot;prefetch_batch_size&quot;: 5,&#10;  &quot;prefetch_rate_per_sec&quot;: 5,&#10;  &quot;prefetch_rate_capacity&quot;: 5,&#10;  &quot;prefetch_max_concurrent&quot;: 3,&#10;  &quot;KLINES_CACHE_TTL&quot;: 600&#10;}&#10;```&#10;&#10;문제 해결(자주 발생하는 상황과 대응)&#10;- UI에서 &quot;서버 호출 실패&quot; 또는 Connection refused&#10;  - 백엔드가 동작 중인지 확인: `curl -sS http://127.0.0.1:8000/health` (정상 시 {&quot;status&quot;:&quot;ok&quot;} 반환)&#10;  - 도커 사용시: `docker compose ps`와 `docker compose logs -f backend` 확인&#10;- Upbit API에서 429(Too Many Requests)가 발생&#10;  - 서버는 캐시와 재시도(backoff) 로직을 사용하도록 설계되어 있지만, 요청량이 많으면 업비트에서 차단됩니다.&#10;  - 해결 방법: 프리페치 간격 늘리기(runtime/config.json에서 prefetch 관련 값 수정), Redis 사용으로 공유 캐시 적용, 또는 요청 빈도 자체를 낮추세요.&#10;- SSL/네트워크 오류 또는 API 인증 오류&#10;  - 인증키 문제가 있으면 `.env`에 키를 넣고 `server/config.py`를 통해 로드하세요. 테스트 단계에서는 인증이 필요없도록 설정되어 있습니다.&#10;- `prefetch_*` 필드를 조정하면 Upbit 호출 빈도 제한, Redis 여부, cache ttl 등을 튜닝할 수 있습니다.&#10;&#10;##  운영 팁&#10;- **로그 장소**: `logs/backend.log`, `logs/ui.log`, `logs/trading_bot.log`에 각 시스템 로그가 기록됩니다. `scripts/run_dev.sh`는 `wait_for_backend`로 backend 준비를 기다립니다.&#10;- **API 오류 대응**: `curl http://127.0.0.1:8000/health` → `{&quot;status&quot;:&quot;ok&quot;}` 확인. 문제가 있으면 `docker compose logs -f backend` 등으로 로그를 확인하고, 컨테이너 재시작 후에도 문제가 지속되면 설정이나 코드 문제일 수 있습니다.&#10;" />
              <option name="updatedContent" value="# Upbit 자동 트레이딩 봇 — 전체 구조와 흐름을 쉽게 이해하기&#10;&#10;이 프로젝트는 Upbit(업비트) 거래소에 연결해 자동으로 코인 전략을 실행하고, Streamlit UI와 FastAPI를 통해 설정·상황을 확인할 수 있는 개발·학습용 시스템입니다. 이 안내서는 사용 기술, 소스별 기능, 실행 흐름을 자주 쓰는 순서로 정리해 초등학생도 흐름을 따라갈 수 있게 설명합니다.&#10;&#10;##  핵심 목적과 사용자에게 주는 가치&#10;- **24시간 시장 관찰 자동화**: 변동성 돌파, 듀얼 모멘텀 등 전략을 자동으로 계산해 주문 후보를 만들고 켈리공식을 섞어 투자할 금액을 조절합니다.&#10;- **UI·API·스크립트로 제어**: Streamlit UI, FastAPI 엔드포인트, `scripts/run_dev.sh` 등을 통해 설정, 스크리닝, 워처, 백그라운드 작업을 쉽게 조작하고 로그를 확인할 수 있습니다.&#10;- **만들기 쉬운 실험 환경**: Docker와 로컬 모드 모두에서 실행 가능하므로 전략, 자금관리, 프리페치 성능을 바꿔가며 연구 가능합니다.&#10;&#10;##  기술 스택 요약&#10;| 층           | 핵심 기술                                                           | 역할 요약                                                                             |&#10;|-------------|-----------------------------------------------------------------|-----------------------------------------------------------------------------------|&#10;| 애플리케이션 레이어  | **Python 3.13**, `FastAPI`, `streamlit`, `plotly`, `requests`   | 서버 API, UI, 차트, HTTP 통신을 처리합니다. FastAPI는 설정/스크리닝/API 먹통 체크, Streamlit는 UI를 구현합니다. |&#10;| 전략·자금관리 로직  | `server.strategy`, `server.money_manager`, `Kelly criterion` 구현 | 변동성 돌파·모멘텀·RSI 전략과 Kelly 공식을 하나의 파이프라인으로 결합하여 주문 결정을 내립니다.                        |&#10;| 데이터 캐시·히스토리 | `Redis` (옵션), 내부 캐시, `runtime/history/positions_history.json`   | 클라이언트(특히 UI)의 429 발생을 막기 위해 prefetch 데이터를 모아두고, 파일 기반 히스토리로 시계열 차트를 그립니다.         |&#10;| 실행 인프라      | `uvicorn`, `docker compose`, `bash scripts`                     | 개발/배포 모드에서 백엔드와 UI를 동시에 띄우고 Docker 네트워크에서 서로 통신합니다.                               |&#10;&#10;핵심 개념을 아주 쉽게 설명&#10;- 전략(strategy): 코인 가격 데이터(캔들)를 보고 ‘사야 한다/팔아야 한다’고 결정하는 규칙입니다.&#10;- 켈리공식(Kelly criterion): 이길 확률과 기대 수익에 근거해 한 번에 투자할 금액을 계산하는 방법입니다.&#10;- 스크리닝(screening): 여러 종목을 모아 놓고 변동성이 큰 종목을 골라내는 기능입니다.&#10;- 워처(watcher): 실시간(폴링)으로 조건을 체크해 이벤트가 발생하면 로그/알림을 남기는 작은 백그라운드 작업입니다.&#10;&#10;프로젝트 구조 (중요한 파일과 역할)&#10;```&#10;/upbit-trader&#10;├── server/                # 서버(백엔드) 코드 (FastAPI + 감시봇 로직)&#10;│   ├── api.py             # FastAPI REST API: 설정, 스크리닝, watcher, klines_batch 등&#10;│   ├── bot.py             # 봇의 메인 루프: 시세 조회 → 전략 평가 → 주문(모의/실제)&#10;│   ├── upbit_api.py       # Upbit와 통신하는 로직(pyupbit 또는 직접 HTTP 사용)&#10;│   ├── strategy.py        # 여러 전략 구현 (VolatilityBreakout, DualMomentum, RSI 등)&#10;│   ├── money_manager.py   # 켈리공식 등 자금관리 로직&#10;│   ├── config.py          # runtime/config.json 읽기/쓰기, 전역 설정&#10;│   └── logger.py          # 로그 설정&#10;├── ui/                    # Streamlit 기반 사용자 인터페이스&#10;│   └── ui_dashboard.py    # 설정 편집, 종목 스크리닝, 워처 제어 페이지&#10;├── runtime/               # 실행 시 사용하는 설정 (PID, 히스토리 등)&#10;│   └── config.json        # 기본 실행 설정(전략, 마켓, 파라미터 등)&#10;│   └── history/            # 포지션 히스토리 JSON 파일 저장소&#10;├── logs/                  # 실행 로그 파일 저장소&#10;│   ├── backend.log        # 백엔드 로그&#10;│   ├── ui.log             # UI 로그&#10;│   └── trading_bot.log    # 트레이딩 봇 로그&#10;├── scripts/&#10;│   └── run_dev.sh         # 개발용 실행 스크립트 (백엔드 + UI 동시 실행 등)&#10;├── docker-compose.yml      # Docker 서비스 정의&#10;├── docker-compose.override.yml  # 개발용 바인드 마운트(코드 수정시 재시작 흐름 제어)&#10;├── requirements.txt        # Python 의존성 목록&#10;└── README.md&#10;```&#10;&#10;### 주요 폴더와 역할&#10;- `server/`: FastAPI 엔드포인트(API, 설정 저장/재로딩, 스크리닝, watcher·prefetch 등), Upbit 연동, 전략/자금 관리, 로그 설정, 히스토리 저장기를 포함합니다.&#10;- `ui/`: Streamlit 대시보드. 설정편집, 종목스크리닝, 이벤트 감시자 제어, 원화잔고/포지션 분석 등 여러 메뉴를 버튼 형식의 사이드바로 제공합니다.&#10;- `runtime/`: `config.json`, 실행 중 PID 파일, `history/positions_history.json` 등을 담아 상태를 보존합니다. 히스토리 디렉터리는 새로 만든 JSON 파일을 통해 과거 포지션 가치를 저장합니다.&#10;- `scripts/run_dev.sh`: 로컬에서 backend + UI를 순서대로 띄우고 로그를 모으며, `all`, `backend`, `ui` 모드를 지원합니다.&#10;- `docker-compose*.yml` + `Dockerfile.*`: Redis, backend, UI, bot 컨테이너를 조합해 통합 테스트/운영 환경을 제공합니다.&#10;&#10;##  주요 소스별 요약&#10;| 파일/모듈                                  | 기술                 | 기능 한 줄 요약                                                                                                                                                                                                   |&#10;|----------------------------------------|--------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|&#10;| `server/api.py`                        | FastAPI            | `/balances`, `/positions`, `/screen/volatility_top`, `/klines_batch`, `/watcher/*`, `/config`, `/reload`, `/positions/history`를 노출하여 설정/데이터/워처 제어를 처리한다. 토큰 버킷·세마포어로 Upbit 호출을 제한하고 Redis 또는 인메모리 캐시를 사용한다. |&#10;| `server/bot.py`                        | Python 스레드 기반 루프   | `runtime/config.json`을 읽고 주기적으로 전략을 평가하여 주문을 생성하고, 로깅 및 상태 업데이트를 남긴다.                                                                                                                                       |&#10;| `server/strategy.py`                   | 전략 구현              | 변동성 돌파, 듀얼 모멘텀(절대/상대), RSI 조합 등을 정의하고, 단일 전략으로부터 신호를 만드는 도우미 함수가 있다.                                                                                                                                        |&#10;| `server/money_manager.py`              | Kelly criterion    | 승률·수익비를 받아 주문 당 투자금과 레버리지 등을 계산한다.                                                                                                                                                                          |&#10;| `server/history.py`                    | JSON 기반 히스토리 스토어   | `runtime/history/positions_history.json`에 `ts`, `total_equity`, 각 종목의 평가금액·손익을 기록하고 읽는 헬퍼. UI 시계열 차트를 위해 `GET /positions/history`를 제공한다.                                                                    |&#10;| `server/config.py`                     | 설정 파싱              | `.env`, `runtime/config.json` 등을 읽어 글로벌 설정을 관리하고, 변경 시 저장/재시작을 안내한다.                                                                                                                                        |&#10;| `server/logger.py`                     | logging            | 로컬/컨테이너 환경 모두에서 통일된 로그 포맷과 파일/스트림 핸들러를 만든다.                                                                                                                                                                 |&#10;| `server/upbit_api.py`                  | pyupbit + https 호출 | 인증 키가 있으면 private API를 사용; 그 외에는 public klines만 호출하며 rate 제한을 최소화하기 위한 반복 로직이 있다.                                                                                                                           |&#10;| `ui/ui_dashboard.py`                   | Streamlit          | 버튼형 사이드바, 설정 폼, 화면별 상태(스크리닝 차트, watcher 상태, 포지션 테이블/차트) 및 `/positions/history`를 이용한 시계열 라인 및 손익 바 차트를 렌더링한다.                                                                                                |&#10;| `scripts/run_dev.sh`                   | Bash               | backend(Uvicorn) → `wait_for_backend()` → UI(Streamlit)를 순차 실행하며 `logs/`로 실시간 로그를 남긴다.                                                                                                                      |&#10;| `Dockerfile.*` + `docker-compose*.yml` | Docker             | backend/api/ui/bot 컨테이너와 Redis를 정의하고, UI에서는 `STREAMLIT_API_BASE`로 `http://backend:8000`을 기본값으로 잡아 통합 서비스를 실행한다.                                                                                             |&#10;&#10;##  데이터 흐름 (prefetch → 히스토리 → UI)&#10;1. `server/api.py` prefetched klines/positions → Redis 또는 인메모리 캐시에 저장 (`_cache_set/_cache_get`).&#10;2. `/positions` 호출 시 현재 포지션/평가금액/손익을 계산 → nodal history JSON(새로 만든 `server/history.py`)에 `ts` 단위로 누적 저장.&#10;3. Streamlit 포지션 페이지는 `/positions`, `/positions/history`를 연속 호출 → 표, 캔들+MA+RSI, 평가금액/손익 차트를 각각 렌더링.&#10;4. `runtime/history` 디렉터리가 존재하므로 컨테이너 재기동 후에도 최대 N개(기본 720개) 히스토리 유지해 시계열 차트를 부드럽게 만듭니다.&#10;&#10;###  WebSocket→캐시→봇/API/UI 흐름&#10;1. `server/ws_listener_private.py`(MyOrder 전용)와 `server/ws_listener_public.py`(공용 ticker 전용)로 WebSocket 핸들러가 분리되어 있고, `ws_timeframes`(`runtime/config.json`의 `timeframe`, `ws_timeframes` 필드 포함)를 기반으로 `ticker` 메시지로부터 1분봉을 집계합니다.&#10;2. 실제 업비트 주문 `order` 이벤트는 `runtime/history/exec_history.json`에 기록되고, `ws:trades:{ticker}` 리스트와 `ws:candles:{timeframe}:{ticker}` 키로 Redis에도 저장됩니다.&#10;3. `server/bot.py`는 가장 먼저 Redis `ws:candles:{desired_timeframe}:{ticker}` 캐시를 읽고(없으면 REST 호출), `ws_listener_private`이 만든 여러 타임프레임을 그대로 전략에 공급합니다.&#10;4. FastAPI의 `/klines_batch`는 기존 `ticker|timeframe|count` 캐시를 사용하므로 WebSocket 캔들 캐시와는 별개이며, UI는 항상 `/klines_batch` → `FastAPI` → `_cache_get` 흐름을 통해 데이터를 가져옵니다.&#10;&#10;```&#10;[Upbit WS ticker/order]&#10;           ↘&#10;      WebSocket Listener&#10;           ↘───────────┬──────────────┬─────────────&#10;                       │              │&#10;             redis ws:candles:*  runtime/history/exec_history.json&#10;                       │              │&#10;        ┌──────────────┴──────────────┴────────────┐&#10;        │                    │                    │&#10;    bot (Redis 우선)   FastAPI /klines_batch   Streamlit UI&#10; (ws:candles:tf:ticker)   (ticker|tf|count)     → /klines_batch&#10;```&#10;&#10;- 이 다이어그램은 WebSocket 수신이 Redis에 다양한 타임프레임 캐시를 만들고, bot/API/UI가 각자 필요한 저장소에서 먼저 읽도록 설계된 점을 강조합니다.&#10;- `runtime/config.json`에 `ws_timeframes`를 넣으면 `ws_listener`가 지정한 순서대로 간격을 추가로 계산합니다(예: `[&quot;minute1&quot;,&quot;minute5&quot;,&quot;minute15&quot;]`).&#10;- Redis가 없는 환경에서는 `bot`/`ui`/`api`가 각각 fallback 로직으로 REST 호출을 사용하지만, WebSocket과 `exec_history`는 계속 로깅됩니다.&#10;&#10;## ️ 실시간 WebSocket 수신 및 exec 기록&#10;1. `server/ws_listener.py`는 Upbit WebSocket(`ticker`+`trade`)을 구독해 Redis에 실시간 payload를 저장하고 `/ws/*` 엔드포인트로 상태를 제어할 수 있게 합니다.&#10;2. 체결(trade) 이벤트는 `runtime/history/exec_history.json`에 append 되어 영구 보존되며, Redis에는 `ws:trades:&lt;ticker&gt;` 리스트(최대 200개)도 유지합니다.&#10;3. FastAPI에서 `ws_start`, `ws_stop`, `ws_status`를 제공하므로 UI나 `curl`로 리스너를 직접 시작/중지하거나 상태를 확인할 수 있습니다.&#10;4. 이 데이터를 UI나 봇이 실시간 UI/알림용으로 조회하려면 Redis `ws:ticker:...` 키 또는 `runtime/history/exec_history.json`을 읽도록 새 위젯/로직을 추가하세요.&#10;&#10;##  실행하기 (로컬 &amp; Docker)&#10;### 1) 로컬 개발&#10;```bash&#10;python -m venv venv&#10;source venv/bin/activate&#10;pip install -r requirements.txt&#10;chmod +x scripts/run_dev.sh&#10;./scripts/run_dev.sh all&#10;```&#10;- 위 스크립트는 로컬에서 backend(uvicorn)과 UI(streamlit)를 동시에 실행합니다.&#10;- `--no-reload` 또는 `--detached` 같은 플래그로 동작을 조절할 수 있습니다. `./scripts/run_dev.sh --help`로 확인하세요.&#10;&#10;개별 컴포넌트 실행&#10;- 백엔드만: uvicorn server.api:app --host 127.0.0.1 --port 8000&#10;- UI만: streamlit run ui/ui_dashboard.py&#10;- 봇: python -m server.bot&#10;&#10;### 2) Docker (권장 통합 테스트)&#10;```bash&#10;docker compose up --build&#10;docker compose up&#10;```&#10;- `docker-compose.override.yml`는 개발용 바인드 마운트를 추가하고, UI는 `STREAMLIT_API_BASE=http://backend:8000`으로 backend를 호출합니다.&#10;- 필요시 `docker compose logs -f backend` 등으로 로그를 확인하고 `docker compose down`으로 정리합니다.&#10;&#10;### 3) 개별 컴포넌트 (안정적으로 짧게 실행)&#10;```bash&#10;uvicorn server.api:app --reload --host 127.0.0.1 --port 8000&#10;streamlit run ui/ui_dashboard.py&#10;python -m server.bot&#10;```&#10;- FastAPI는 `--reload`로 코드 변경시 재시작(개발 전용).&#10;- Streamlit UI는 `--server.port` 등을 조정해 여러 창 테스트 가능합니다.&#10;&#10;설정 파일 설명 (runtime/config.json)&#10;- strategy_name: 사용할 전략 이름(예: VolatilityBreakout, DualMomentum, RSI)&#10;- market: 거래할 마켓 (예: KRW-BTC)&#10;- timeframe: 캔들 단위(예: minute5, minute15)&#10;- candle_count: 과거 캔들 수&#10;- loop_interval_sec: 봇이 다음 루프를 시작하기까지 대기 시간(초)&#10;- order_settings: 주문과 관련된 최소/기본 금액 설정&#10;- use_kelly_criterion: 켈리공식 사용 여부&#10;- kelly_criterion: 켈리용 파라미터(win_rate, payoff_ratio, fraction)&#10;- strategy_params: 전략별 세부 파라미터(예: VolatilityBreakout.k_value)&#10;&#10;간단한 예시 (runtime/config.json)&#10;```json&#10;{&#10;  &quot;strategy_name&quot;: &quot;VolatilityBreakout&quot;,&#10;  &quot;market&quot;: &quot;KRW-BTC&quot;,&#10;  &quot;timeframe&quot;: &quot;minute5&quot;,&#10;  &quot;candle_count&quot;: 200,&#10;  &quot;loop_interval_sec&quot;: 5,&#10;  &quot;order_settings&quot;: { &quot;min_order_amount&quot;: 5500, &quot;trade_amount_krw&quot;: 6000 },&#10;  &quot;use_kelly_criterion&quot;: true,&#10;  &quot;kelly_criterion&quot;: { &quot;win_rate&quot;: 0.65, &quot;payoff_ratio&quot;: 1.2, &quot;fraction&quot;: 0.5 },&#10;  &quot;strategy_params&quot;: {&#10;    &quot;VolatilityBreakout&quot;: { &quot;k_value&quot;: 0.5 },&#10;    &quot;DualMomentum&quot;: { &quot;window&quot;: 12 },&#10;    &quot;RSI&quot;: { &quot;period&quot;: 14, &quot;oversold&quot;: 30, &quot;overbought&quot;: 70 }&#10;  },&#10;  &quot;prefetch_count&quot;: 200,&#10;  &quot;prefetch_interval_sec&quot;: 60,&#10;  &quot;prefetch_batch_size&quot;: 5,&#10;  &quot;prefetch_rate_per_sec&quot;: 5,&#10;  &quot;prefetch_rate_capacity&quot;: 5,&#10;  &quot;prefetch_max_concurrent&quot;: 3,&#10;  &quot;KLINES_CACHE_TTL&quot;: 600&#10;}&#10;```&#10;&#10;문제 해결(자주 발생하는 상황과 대응)&#10;- UI에서 &quot;서버 호출 실패&quot; 또는 Connection refused&#10;  - 백엔드가 동작 중인지 확인: `curl -sS http://127.0.0.1:8000/health` (정상 시 {&quot;status&quot;:&quot;ok&quot;} 반환)&#10;  - 도커 사용시: `docker compose ps`와 `docker compose logs -f backend` 확인&#10;- Upbit API에서 429(Too Many Requests)가 발생&#10;  - 서버는 캐시와 재시도(backoff) 로직을 사용하도록 설계되어 있지만, 요청량이 많으면 업비트에서 차단됩니다.&#10;  - 해결 방법: 프리페치 간격 늘리기(runtime/config.json에서 prefetch 관련 값 수정), Redis 사용으로 공유 캐시 적용, 또는 요청 빈도 자체를 낮추세요.&#10;- SSL/네트워크 오류 또는 API 인증 오류&#10;  - 인증키 문제가 있으면 `.env`에 키를 넣고 `server/config.py`를 통해 로드하세요. 테스트 단계에서는 인증이 필요없도록 설정되어 있습니다.&#10;- `prefetch_*` 필드를 조정하면 Upbit 호출 빈도 제한, Redis 여부, cache ttl 등을 튜닝할 수 있습니다.&#10;&#10;##  운영 팁&#10;- **로그 장소**: `logs/backend.log`, `logs/ui.log`, `logs/trading_bot.log`에 각 시스템 로그가 기록됩니다. `scripts/run_dev.sh`는 `wait_for_backend`로 backend 준비를 기다립니다.&#10;- **API 오류 대응**: `curl http://127.0.0.1:8000/health` → `{&quot;status&quot;:&quot;ok&quot;}` 확인. 문제가 있으면 `docker compose logs -f backend` 등으로 로그를 확인하고, 컨테이너 재시작 후에도 문제가 지속되면 설정이나 코드 문제일 수 있습니다." />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/server/api.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/server/api.py" />
              <option name="originalContent" value="from fastapi import FastAPI, HTTPException # web framework&#10;from contextlib import asynccontextmanager # for lifespan management&#10;from pydantic import BaseModel # data validation, settings management&#10;from typing import Any, Dict, List, Optional # type hints&#10;import threading&#10;import time&#10;import os&#10;&#10;# 시간대 설정&#10;os.environ.setdefault('TZ', 'Asia/Seoul')&#10;try:&#10;    time.tzset()&#10;except Exception:&#10;    pass&#10;&#10;# 외부라이브러리 임포트&#10;import redis # Redis 클라이언트&#10;import json&#10;from concurrent.futures import ThreadPoolExecutor, as_completed # for parallel prefetching&#10;&#10;# 내부API 모듈 임포트&#10;from server import config               # 런타임 설정 관리&#10;from server.upbit_api import UpbitAPI   # 업비트 API 연동&#10;from server.logger import log           # 로깅 설정&#10;from server.history import history_store&#10;from server.ws_listener_base import (&#10;    load_ws_stats,&#10;    summarize_ws_stats,&#10;    read_exec_history,&#10;)&#10;from server.ws_listener_private import PrivateWebsocketListener&#10;from server.ws_listener_public import PublicWebsocketlistener&#10;&#10;# Token Bucket 구현 for prefetch&#10;# 간단한 토큰 버킷(rate limiter) 구현&#10;# rate: 초당 토큰 생성 속도&#10;# capacity: 버킷 최대 토큰 수&#10;# consume(tokens, timeout): 지정된 토큰 수를 소비 시도, 타임아웃 내에 성공 여부 반환&#10;# 스레드 안전 구현&#10;# 사용 예시:&#10;# tb = TokenBucket(rate=5, capacity=10)  # 초당 5토큰, 최대 10토큰&#10;# if tb.consume(tokens=1, timeout=2.0):&#10;#     print(&quot;Token acquired&quot;)&#10;# else:&#10;#     print(&quot;Failed to acquire token within timeout&quot;)&#10;class TokenBucket:&#10;    def __init__(self, rate: float, capacity: float):&#10;        self.rate = float(rate)         # 토큰 생성 속도 (초당)&#10;        self.capacity = float(capacity) # 버킷 최대 용량&#10;        self._tokens = float(capacity)  # 현재 토큰 수&#10;        self._last = time.time()        # 마지막 토큰 갱신 시각&#10;        self._lock = threading.Lock()   # 스레드 안전을 위한 락&#10;&#10;    # 토큰 소비 메서드&#10;    # tokens: 소비할 토큰 수&#10;    # timeout: 최대 대기 시간 (초)&#10;    # 반환값: 성공 시 True, 실패 시 False&#10;    def consume(self, tokens: float = 1.0, timeout: float = 5.0) -&gt; bool:&#10;        end = time.time() + float(timeout)&#10;        while time.time() &lt; end:&#10;            with self._lock:&#10;                now = time.time()&#10;                elapsed = max(0.0, now - self._last)&#10;                self._tokens = min(self.capacity, self._tokens + elapsed * self.rate)&#10;                self._last = now&#10;                if self._tokens &gt;= tokens:&#10;                    self._tokens -= tokens&#10;                    return True&#10;            time.sleep(0.01)&#10;        return False&#10;&#10;&#10;# 세마포어 및 토큰 버킷 초기화 (스케줄러 시작 시)&#10;_prefetch_token_bucket: Optional[TokenBucket] = None&#10;_prefetch_semaphore: Optional[threading.BoundedSemaphore] = None&#10;&#10;# 기본 klines 캐시 TTL (초)&#10;# 환경변수 'KLINES_CACHE_TTL'로 설정 가능, 기본값 600초&#10;# 예: os.environ['KLINES_CACHE_TTL'] = '600'&#10;# (기본값 600초로 설정하여 중복 Upbit 요청 감소, 실시간성은 다소 희생, 값이 클수록 캐시 지속시간 증가)&#10;_KLINES_CACHE_TTL = int(os.getenv('KLINES_CACHE_TTL', str(600)))  # default 600s&#10;&#10;# Balances cache TTL (seconds)&#10;_BALANCES_CACHE_TTL = int(os.getenv('BALANCES_CACHE_TTL', '15'))&#10;&#10;# FastAPI 앱 생성 및 수명 주기 관리&#10;@asynccontextmanager&#10;async def lifespan(app: FastAPI): # 수명 주기 관리&#10;    # start prefetch scheduler on startup&#10;    try:&#10;        # read interval from config, default 30s&#10;        # if invalid, fallback to 30s&#10;        # prefetch interval 설정&#10;        # 기본값 30초&#10;        # 환경변수나 config.json의 'prefetch_interval_sec' 키로 설정 가능&#10;        interval = int(config._config.get('prefetch_interval_sec', 30))&#10;    except Exception:&#10;        interval = 30&#10;&#10;    # 스케쥴러 시작&#10;    start_prefetch_scheduler(interval=interval)&#10;    try:&#10;        start_ws_listener()&#10;        start_ticker_listener()&#10;    except Exception as exc:&#10;        log.warning(f'Failed to start websocket listener on startup: {exc}')&#10;    try:&#10;        yield&#10;    finally:&#10;        # 스케쥴러 중지&#10;        stop_prefetch_scheduler()&#10;        stop_ws_listener()&#10;        stop_ticker_listener()&#10;&#10;app = FastAPI(title=&quot;Upbit Trader Runtime API&quot;, lifespan=lifespan) # FastAPI 앱 생성&#10;&#10;# 데이터 모델 정의&#10;class ConfigPayload(BaseModel):&#10;    config: Dict[str, Any]&#10;&#10;# 배치 klines 요청 모델&#10;class KlinesBatchRequest(BaseModel):&#10;    tickers: List[str]&#10;    timeframe: Optional[str] = 'minute15'&#10;    count: Optional[int] = 100&#10;&#10;# 포지션 모델 정의&#10;class Position(BaseModel):&#10;    ticker: str&#10;    amount: float&#10;    avg_price: float&#10;    current_price: float&#10;    pnl: float&#10;&#10;# --- Background Prefetch Scheduler 및 캐시 관리 ---&#10;# 전역 상태 변수들&#10;# Prefetch 스레드 및 제어 변수&#10;# Simple in-memory watcher state (explicit typing to satisfy linters)&#10;_watcher: Dict[str, Any] = {&#10;    'running': False,&#10;    'thread': None,&#10;    'stop_event': None,&#10;}&#10;&#10;# 캐시 딕셔너리&#10;# Simple in-memory cache for batch klines: { key: (timestamp, data) }&#10;_klines_cache: Dict[str, Any] = {}&#10;&#10;&#10;# 레디스(Redis) 클라이언트 초기화&#10;# Redis setup (optional). Use local redis://localhost:6379 if REDIS_URL not set&#10;# 환경변수 'REDIS_URL'로 Redis URL 설정 가능&#10;REDIS_URL = os.getenv('REDIS_URL', 'redis://localhost:6379/0')&#10;_redis_client = None&#10;try:&#10;    # Redis 클라이언트 생성 및 연결 테스트&#10;    _redis_client = redis.from_url(REDIS_URL, decode_responses=True)&#10;    # ping 테스트&#10;    _redis_client.ping()&#10;    log.info(f'Redis cache connected: {REDIS_URL}')&#10;except Exception as e:&#10;    _redis_client = None&#10;    log.warning(f'Redis not available ({REDIS_URL}): {e}. Falling back to in-memory cache')&#10;&#10;# 캐시 설정 함수&#10;# key: 캐시 키&#10;# value: 캐시 값&#10;# ttl: 캐시 만료 시간 (초)&#10;# 기본 TTL은 _KLINES_CACHE_TTL 사용&#10;# Redis 사용 가능 시 Redis에 저장, 아니면 메모리 내 딕셔너리에 저장&#10;# 캐시 조회 시 만료 시간 확인&#10;# 반환값: (타임스탬프, 값) 또는 None&#10;def _cache_set(key: str, value: Any, ttl: int = _KLINES_CACHE_TTL):&#10;    &quot;&quot;&quot;Set cache in Redis if available, else in-memory.&quot;&quot;&quot;&#10;    now = time.time()&#10;    if _redis_client:&#10;        try:&#10;            # store JSON string&#10;            import json as _json&#10;            payload = {'ts': now, 'value': value}&#10;            _redis_client.setex(key, ttl, _json.dumps(payload)) # set with expiry&#10;            return&#10;        except Exception:&#10;            pass&#10;    _klines_cache[key] = (now, value) # store in-memory&#10;&#10;# 캐시 조회 함수&#10;# key: 캐시 키&#10;# ttl: 캐시 만료 시간 (초)&#10;# 기본 TTL은 _KLINES_CACHE_TTL 사용&#10;# 반환값: (타임스탬프, 값) 또는 None&#10;def _cache_get(key: str, ttl: int = _KLINES_CACHE_TTL):&#10;    &quot;&quot;&quot;Get cache value. Return (timestamp, value) or None.&quot;&quot;&quot;&#10;    if _redis_client:&#10;        try:&#10;            import json as _json&#10;            s = _redis_client.get(key) # get JSON string&#10;            if not s:&#10;                return None&#10;            obj = _json.loads(s) # parse JSON&#10;            if time.time() - obj.get('ts', 0) &gt; ttl:&#10;                return None&#10;            return (obj.get('ts'), obj.get('value')) # return (timestamp, value)&#10;        except Exception:&#10;            return None&#10;    return _klines_cache.get(key) # return (timestamp, value) or None&#10;&#10;# Websocket listener state&#10;_ws_listener: Optional[PrivateWebsocketListener] = None&#10;_ticker_listener: Optional[PublicWebsocketlistener] = None&#10;&#10;def start_ws_listener() -&gt; None:&#10;    global _ws_listener&#10;    if _ws_listener and _ws_listener._thread and _ws_listener._thread.is_alive():&#10;        return&#10;    _ws_listener = PrivateWebsocketListener(redis_client=_redis_client)&#10;    _ws_listener.start()&#10;&#10;&#10;def start_ticker_listener() -&gt; None:&#10;    global _ticker_listener&#10;    if _ticker_listener and _ticker_listener._thread and _ticker_listener._thread.is_alive():&#10;        return&#10;    _ticker_listener = PublicWebsocketlistener(redis_client=_redis_client)&#10;    _ticker_listener.start()&#10;&#10;&#10;def stop_ws_listener() -&gt; None:&#10;    global _ws_listener&#10;    if _ws_listener:&#10;        _ws_listener.stop()&#10;&#10;&#10;def stop_ticker_listener() -&gt; None:&#10;    global _ticker_listener&#10;    if _ticker_listener:&#10;        _ticker_listener.stop()&#10;&#10;# Rate-limited Upbit klines fetcher&#10;# ticker_local: 업비트 로컬 티커명 (예: KRW-BTC)&#10;# timeframe: 캔들 시간대 (예: 'minute15')&#10;# count: 조회할 캔들 개수&#10;# 반환값: UpbitAPI.get_klines() 결과&#10;# 전역 토큰 버킷 및 세마포어를 사용하여 호출 제한 및 동시성 제어&#10;# 토큰 획득 및 세마포어 획득 시 타임아웃 처리&#10;# 예외 발생 시 호출 실패&#10;# 반환값: UpbitAPI.get_klines() 결과&#10;def _rate_limited_get_klines(ticker_local: str, timeframe: str, count: int):&#10;    # 전역 토큰 버킷 및 세마포어 사용&#10;    global _prefetch_token_bucket, _prefetch_semaphore&#10;&#10;    # 세마포어 및 토큰 획득 시도&#10;    # 타임아웃은 config의 'prefetch_token_wait_timeout' 키로 설정 가능, 기본 10초&#10;    # 실제 Upbit 호출 수행&#10;    # 예외 발생 시 호출 실패&#10;    acquired = False&#10;    try:&#10;        # 세마포어 획득 시도&#10;        if _prefetch_semaphore is not None:&#10;            # 세마포어 획득 (대기 시간 설정 기본값 10초)&#10;            acquired = _prefetch_semaphore.acquire(timeout=10)&#10;            if not acquired:&#10;                raise RuntimeError('prefetch_semaphore_timeout')&#10;&#10;        # 토큰 획득 시도&#10;        if _prefetch_token_bucket is not None:&#10;            # 토큰 대기 시간 설정&#10;            # 기본값 10초 (즉시 호출 선호), config의 'prefetch_token_wait_timeout' 키로 설정 가능&#10;            try:&#10;                token_wait = float(config._config.get('prefetch_token_wait_timeout', 10.0))&#10;            except Exception:&#10;                token_wait = 10.0&#10;            ok = _prefetch_token_bucket.consume(tokens=1.0, timeout=token_wait)&#10;            if not ok:&#10;                raise RuntimeError('rate_limited')&#10;        # 업비트 공용 API 호출 수행&#10;        # 반환값: UpbitAPI.get_klines() 결과&#10;        # 참고: UpbitAPI 인스턴스는 전역 _upbit_public 사용&#10;        # 이 인스턴스는 API 키를 사용하지 않음&#10;        return _upbit_public.get_klines(ticker_local, timeframe, count=count)&#10;    finally:&#10;        if acquired and _prefetch_semaphore is not None:&#10;            try:&#10;                _prefetch_semaphore.release() # 세마포어 해제&#10;            except Exception:&#10;                pass&#10;&#10;&#10;# 업비트 공용 API 인스턴스&#10;_upbit_public = UpbitAPI()&#10;&#10;# 업비트 인증(Private) API 인스턴스&#10;try:&#10;    access = getattr(config, 'UPBIT_ACCESS_KEY', None)&#10;    secret = getattr(config, 'UPBIT_SECRET_KEY', None)&#10;    if access and secret:&#10;        _upbit_private = UpbitAPI(access_key=access, secret_key=secret)&#10;        log.info('Upbit private API initialized with provided keys')&#10;    else:&#10;        _upbit_private = None&#10;        log.warning('Upbit API keys not provided: private endpoints will be unavailable')&#10;except Exception as e:&#10;    _upbit_private = None&#10;    log.warning(f'Failed to initialize Upbit private API: {e}')&#10;&#10;# 스케쥴러 스레드 및 제어 변수&#10;_prefetch_thread: Optional[threading.Thread] = None&#10;_prefetch_stop = threading.Event()&#10;_prefetch_index = 0&#10;&#10;# 루프 함수 - 주기적으로 universe의 티커들에 대해 klines를 미리 가져와 캐시에 저장&#10;# interval: 루프 주기 (초)&#10;# 기본값 30초&#10;def _prefetch_loop(interval: int = 30):&#10;    log.info('Prefetch scheduler started')&#10;    effective_interval = interval&#10;    while not _prefetch_stop.is_set():&#10;        try:&#10;            # 설정 읽기&#10;            cfg = config._config&#10;            # 티커 유니버스&#10;            universe = cfg.get('universe', [])&#10;            # 실행 중 설정 체크 (런타임 config에서 재정의 허용)&#10;            cfg_count = int(cfg.get('prefetch_count', 200))&#10;            # Redis 미사용 시 보수적으로 설정, upper bound 허용&#10;            if _redis_client is None:&#10;                # When Redis is missing, be conservative but allow a configurable upper bound&#10;                # Redis 미사용 시 최대값 설정, 기본 120, config의 'prefetch_no_redis_max_count' 키로 설정 가능&#10;                try:&#10;                    no_redis_max = int(cfg.get('prefetch_no_redis_max_count', 120))&#10;                except Exception:&#10;                    no_redis_max = 120&#10;                count = min(cfg_count, no_redis_max)&#10;                per_ticker_sleep = float(cfg.get('prefetch_sleep_sec', 1.0))&#10;                log.info('Redis not available: using conservative prefetch settings (count=%s, sleep=%.2f)', count, per_ticker_sleep)&#10;            else:&#10;                count = cfg_count&#10;                per_ticker_sleep = float(cfg.get('prefetch_sleep_sec', 0.2))&#10;&#10;            # Redis 미사용 시 최소 간격 보장&#10;            effective_interval = interval&#10;            if _redis_client is None:&#10;                effective_interval = max(interval, int(cfg.get('prefetch_min_interval_sec', 60)))&#10;            if universe:&#10;                # staggered batch processing to avoid bursts&#10;                batch_size = int(cfg.get('prefetch_batch_size', 5))     # batch size per run&#10;                parallelism = int(cfg.get('prefetch_parallelism', 3))   # max parallel fetches per batch&#10;                global _prefetch_index&#10;                n = len(universe)&#10;                if n == 0:&#10;                    pass&#10;                else:&#10;                    start = _prefetch_index % n # start index&#10;                    end = start + batch_size    # end index (exclusive)&#10;                    indices = list(range(start, min(end, n)))&#10;                    # wrap-around if needed&#10;                    if end &gt; n:&#10;                        indices += list(range(0, end - n))&#10;                    tickers_to_process = [universe[i] for i in indices]&#10;                    # advance index for next run&#10;                    _prefetch_index = (start + len(tickers_to_process)) % max(n,1)&#10;&#10;                    # helper to fetch and cache single ticker&#10;                    def _prefetch_single(ticker_local: str):&#10;                        try:&#10;                            key_local = f&quot;{ticker_local}|minute15|{count}&quot;&#10;                            cached_local = _cache_get(key_local)&#10;                            if cached_local and (time.time() - cached_local[0]) &lt; _KLINES_CACHE_TTL:&#10;                                return (ticker_local, True, 'cached')&#10;                            # use rate-limited fetch so prefetch respects global rate/concurrency limits&#10;                            klines_local = _rate_limited_get_klines(ticker_local, 'minute15', count=count)&#10;                            _cache_set(key_local, klines_local, ttl=_KLINES_CACHE_TTL)&#10;                            return (ticker_local, True, 'fetched')&#10;                        except Exception as exc:&#10;                            log.error(f'Prefetch ticker error for {ticker_local}: {exc}')&#10;                            return (ticker_local, False, str(exc))&#10;&#10;                    # run in ThreadPoolExecutor with limited parallelism&#10;                    with ThreadPoolExecutor(max_workers=min(parallelism, len(tickers_to_process))) as executor:&#10;                        futures = {executor.submit(_prefetch_single, t): t for t in tickers_to_process}&#10;                        for fut in as_completed(futures):&#10;                            try:&#10;                                ticker_res, ok, msg = fut.result()&#10;                                log.debug(f'Prefetch result: {ticker_res} ok={ok} info={msg}')&#10;                            except Exception as e:&#10;                                log.error(f'Prefetch future error: {e}')&#10;                    # after parallel batch, small pause to avoid immediate repeated calls&#10;                    time.sleep(per_ticker_sleep)&#10;        except Exception as e:&#10;            log.error(f'Prefetch error: {e}')&#10;        # wait using effective interval (recompute per loop)&#10;        try:&#10;            _prefetch_stop.wait(effective_interval)&#10;        except UnboundLocalError:&#10;            _prefetch_stop.wait(interval)&#10;    log.info('Prefetch scheduler stopped')&#10;&#10;# 스케쥴러 시작 함수&#10;# interval: 루프 주기 (초)&#10;# 기본값 30초&#10;def start_prefetch_scheduler(interval: int = 30):&#10;    global _prefetch_thread, _prefetch_stop&#10;    if _prefetch_thread is not None and _prefetch_thread.is_alive():&#10;        return&#10;    _prefetch_stop.clear()&#10;    # Redis 미사용 시 기본 간격 증가&#10;    # Upbit 호출 부담 축소를 위한 조치&#10;    # 기본 최소 60초&#10;    if _redis_client is None:&#10;        interval = max(interval, 60)&#10;        log.info('Redis not connected: starting prefetch with interval %s seconds', interval)&#10;    # Redis 미사용 시 기본 배치 크기 축소&#10;    if _redis_client is None:&#10;        try:&#10;            # 배치사이즈 기본 3으로 축소, config에 없으면 설정&#10;            if 'prefetch_batch_size' not in config._config:&#10;                config._config['prefetch_batch_size'] = 3&#10;        except Exception:&#10;            pass&#10;    # 프리페치 레이트 리미터 및 세마포어 초기화&#10;    # 설정값 읽기 및 기본값 적용&#10;    global _prefetch_token_bucket, _prefetch_semaphore # 전역 변수&#10;    try:&#10;        # 초당 5토큰&#10;        rate = int(config._config.get('prefetch_rate_per_sec', 5))&#10;    except Exception:&#10;        rate = 5&#10;    try:&#10;        # 용량은 rate와 같게&#10;        capacity = int(config._config.get('prefetch_rate_capacity', max(1, rate)))&#10;    except Exception:&#10;        capacity = max(1, rate)&#10;    try:&#10;        # 동시 3개&#10;        max_concurrent = int(config._config.get('prefetch_max_concurrent', 3))&#10;    except Exception:&#10;        max_concurrent = 3&#10;    try:&#10;        # 토큰 버킷 및 세마포어 초기화&#10;        _prefetch_token_bucket = TokenBucket(rate=float(rate), capacity=float(capacity))&#10;        _prefetch_semaphore = threading.BoundedSemaphore(max_concurrent)&#10;        log.info(f'Prefetch rate limiter initialized: rate={rate}/s, capacity={capacity}, max_concurrent={max_concurrent}')&#10;    except Exception as e:&#10;        _prefetch_token_bucket = None&#10;        _prefetch_semaphore = None&#10;        log.warning(f'Failed to initialize prefetch rate limiter: {e}')&#10;    _prefetch_thread = threading.Thread(target=_prefetch_loop, args=(interval,), daemon=True)&#10;    _prefetch_thread.start()&#10;&#10;# 스케쥴러 중지 함수&#10;# 스케쥴러 스레드 종료 대기 (최대 2초)&#10;# 기본값 30초&#10;def stop_prefetch_scheduler():&#10;    global _prefetch_thread, _prefetch_stop&#10;    _prefetch_stop.set()&#10;    if _prefetch_thread is not None:&#10;        _prefetch_thread.join(timeout=2)&#10;    _prefetch_thread = None&#10;&#10;&#10;@app.get(&quot;/health&quot;) # 헬스체크 엔드포인트&#10;def health():&#10;    return {&quot;status&quot;: &quot;ok&quot;}&#10;&#10;&#10;@app.get('/debug/status') # 디버그 상태 엔드포인트&#10;def debug_status():&#10;    &quot;&quot;&quot;Return diagnostic info: pyupbit presence, redis connection, prefetch thread state, universe size.&quot;&quot;&quot;&#10;    try:&#10;        import server.upbit_api as upbit_api&#10;        has_pyupbit = bool(getattr(upbit_api, '_HAS_PYUPBIT', False))&#10;    except Exception:&#10;        has_pyupbit = False&#10;&#10;    redis_up = False&#10;    try:&#10;        redis_up = _redis_client is not None&#10;    except Exception:&#10;        redis_up = False&#10;&#10;    prefetch_running = False&#10;    try:&#10;        prefetch_running = (_prefetch_thread is not None and _prefetch_thread.is_alive())&#10;    except Exception:&#10;        prefetch_running = False&#10;&#10;    universe_len = 0&#10;    try:&#10;        universe_len = len(config._config.get('universe', []))&#10;    except Exception:&#10;        universe_len = 0&#10;&#10;    return {&#10;        'pyupbit': has_pyupbit,&#10;        'redis': redis_up,&#10;        'prefetch_running': prefetch_running,&#10;        'prefetch_index': _prefetch_index,&#10;        'universe_len': universe_len,&#10;    }&#10;&#10;&#10;@app.get(&quot;/config&quot;) # 설정 조회 엔드포인트&#10;def get_config():&#10;    cfg = config._config&#10;    return {&quot;config&quot;: cfg}&#10;&#10;&#10;@app.post(&quot;/config&quot;) # 설정 저장 엔드포인트&#10;def post_config(payload: ConfigPayload):&#10;    new_cfg = payload.config&#10;    # 기본적인 검증: 반드시 strategy_name과 market이 있어야 함&#10;    if not isinstance(new_cfg, dict) or 'strategy_name' not in new_cfg or 'market' not in new_cfg:&#10;        raise HTTPException(status_code=400, detail=&quot;Invalid config payload. 'strategy_name' and 'market' required.&quot;)&#10;&#10;    success = config.save_config(new_cfg)&#10;    if not success:&#10;        raise HTTPException(status_code=500, detail=&quot;Failed to save configuration&quot;)&#10;&#10;    # 저장 후 재로딩&#10;    config.reload_config()&#10;    return {&quot;status&quot;: &quot;saved&quot;}&#10;&#10;&#10;@app.post(&quot;/reload&quot;) # 설정 재로딩 엔드포인트&#10;def reload_config():&#10;    config.reload_config()&#10;    return {&quot;status&quot;: &quot;reloaded&quot;}&#10;&#10;&#10;# --- Screening endpoints ---&#10;# 변동성 상위 N개 티커 조회&#10;# market_prefix: 마켓 접두사 (기본값 &quot;KRW&quot;)&#10;# top_n: 상위 N개 (기본값 10)&#10;# timeframe: 변동성 계산에 사용할 시간대 (기본값 &quot;minute15&quot;)&#10;# 반환값: 변동성 상위 N개 티커 리스트&#10;# 변동성 계산은 (최고가 - 최저가) / 평균 종가 방식 사용&#10;# Upbit의 공용 kline 엔드포인트 사용&#10;# config.json의 'universe' 키에 티커 리스트가 없으면 기본 샘플 리스트 사용, 폴백 처리&#10;# 반환값: {&quot;top&quot;: [ {&quot;ticker&quot;: 티커명, &quot;volatility&quot;: 변동성}, ... ] }&#10;# 캐시 사용으로 중복 Upbit 호출 최소화&#10;# 캐시 TTL은 _KLINES_CACHE_TTL 사용&#10;# 예외 발생 시 해당 티커는 건너뜀&#10;@app.get(&quot;/screen/volatility_top&quot;) # 변동성 상위 티커 조회 엔드포인트&#10;def volatility_top(market_prefix: str = &quot;KRW&quot;, top_n: int = 10, timeframe: str = &quot;minute15&quot;):&#10;    cfg = config._config # 설정 읽기&#10;    universe = cfg.get('universe', []) # 유니버스 읽기&#10;    if not universe:&#10;        # 폴백: 기본 샘플 유니버스&#10;        universe = [f&quot;{market_prefix}-BTC&quot;, f&quot;{market_prefix}-ETH&quot;, f&quot;{market_prefix}-XRP&quot;, f&quot;{market_prefix}-ADA&quot;, f&quot;{market_prefix}-DOGE&quot;, f&quot;{market_prefix}-SOL&quot;, f&quot;{market_prefix}-DOT&quot;, f&quot;{market_prefix}-MATIC&quot;, f&quot;{market_prefix}-BCH&quot;, f&quot;{market_prefix}-LTC&quot;]&#10;&#10;    results = []&#10;    # Try to use internal cache to avoid hammering Upbit when checking multiple tickers&#10;    now = time.time()&#10;    for ticker in universe:&#10;        # 캐시 키 생성 (가장 최근 15캔들 기준)&#10;        key = f&quot;{ticker}|{timeframe}|15&quot;&#10;        # 캐시 조회&#10;        cached = _cache_get(key)&#10;        # 캐시 유효성 검사&#10;        if cached and (now - cached[0]) &lt; _KLINES_CACHE_TTL: # 캐시 유효 시&#10;            klines = cached[1] # 캐시된 값 사용&#10;        else:&#10;            try:&#10;                # Upbit에서 변동성 계산용 klines 조회 (rate-limited)&#10;                # 15캔들 기준 (폴백 200캔들 아님)&#10;                klines = _rate_limited_get_klines(ticker, timeframe, count=15)&#10;            except Exception as e:&#10;                log.warning(f'Rate-limited fetch failed for {ticker}: {e}')&#10;                klines = None&#10;            # 캐시 설정, None도 캐시하여 반복 실패 방지&#10;            _cache_set(key, klines, ttl=_KLINES_CACHE_TTL)&#10;        if not klines:&#10;            continue&#10;        highs = [float(k['high_price']) for k in klines]&#10;        lows = [float(k['low_price']) for k in klines]&#10;        closes = [float(k['trade_price']) for k in klines]&#10;        # 변동성 계산 : (최고가 - 최저가) / 평균 종가 방식&#10;        try:&#10;            vol = (max(highs) - min(lows)) / (sum(closes) / len(closes))&#10;        except Exception:&#10;            vol = 0&#10;        results.append({'ticker': ticker, 'volatility': vol})&#10;&#10;    # 변동성 기준 내림차순 정렬 후 상위 N개 반환&#10;    results_sorted = sorted(results, key=lambda x: x['volatility'], reverse=True)[:top_n]&#10;    return {&quot;top&quot;: results_sorted}&#10;&#10;&#10;# --- Background Event Watcher ---&#10;# 단순 폴링 기반 워처 구현&#10;# 워처는 별도 스레드에서 동작하며, 지정된 마켓의 klines를 주기적으로 조회&#10;# 지정된 조건에 부합하는 이벤트 발생 시 로그 출력&#10;# 조건은 JSON 배열로 전달되며, 각 조건은 다음과 같은 형태를 가짐&#10;# {&quot;type&quot;: &quot;volatility_breakout&quot;, &quot;k&quot;: 0.5} : 변동성 돌파 이벤트 (Larry Williams 스타일)&#10;# {&quot;type&quot;: &quot;volume_spike&quot;, &quot;multiplier&quot;: 3} : 거래량 급증 이벤트&#10;# 워처 시작 엔드포인트&#10;# 요청 본문 예시:&#10;# {&quot;market&quot;: &quot;KRW-BTC&quot;,&#10;# &quot;interval&quot;: 1,&#10;# &quot;callbacks&quot;:[&#10;#     {&quot;type&quot;:&quot;volatility_breakout&quot;, &quot;k&quot;:0.5},&#10;#     {&quot;type&quot;:&quot;volume_spike&quot;, &quot;multiplier&quot;:3}&#10;# ]}&#10;# 워처 중지 엔드포인트&#10;def _watcher_loop(stop_event, market: str, check_interval: float, callbacks: List[dict]):&#10;    &quot;&quot;&quot;Simple polling watcher that fetches latest klines and invokes callbacks when conditions met.&quot;&quot;&quot;&#10;    log.info(f&quot;Starting watcher loop for {market} (interval {check_interval}s)&quot;)&#10;    last_checked_time = None&#10;    while not stop_event.is_set():&#10;        try:&#10;            try:&#10;                # Upbit에서 최신 60캔들 조회 (rate-limited)&#10;                klines = _rate_limited_get_klines(market, 'minute1', count=60)&#10;            except Exception as e:&#10;                log.error(f'Watcher fetch rate-limited or failed for {market}: {e}')&#10;                klines = None&#10;&#10;            # 이벤트 체크&#10;            if klines:&#10;                # 최근 캔들&#10;                latest = klines[0]&#10;                # 변동성 체크용 15캔들 윈도우 준비&#10;                window = klines[:15]&#10;                highs = [float(k['high_price']) for k in window]&#10;                lows = [float(k['low_price']) for k in window]&#10;                volumes = [float(k['candle_acc_trade_volume']) for k in window]&#10;                closes = [float(k['trade_price']) for k in window]&#10;&#10;                # 변동성 돌파 체크 (간단화된 Larry Williams 스타일)&#10;                try:&#10;                    prev_close = closes[1]&#10;                    curr_close = closes[0]&#10;                    volatility_range = max(highs) - min(lows)&#10;                except Exception:&#10;                    prev_close = curr_close = volatility_range = None&#10;&#10;                # 콜백 조건 체크&#10;                if prev_close is not None and curr_close is not None: # 유효한 데이터 시&#10;                    # 각 콜백 조건별 체크&#10;                    for cb in callbacks:&#10;                        if cb.get('type') == 'volatility_breakout':&#10;                            k = cb.get('k', 0.5) # 기본 k=0.5&#10;                            # when current close &gt; prev_close + range * k&#10;                            if curr_close &gt; (prev_close + volatility_range * k):&#10;                                log.info(f&quot;Watcher detected volatility breakout on {market} (k={k})&quot;)&#10;                        elif cb.get('type') == 'volume_spike':&#10;                            multiplier = cb.get('multiplier', 3) # 기본 multiplier=3&#10;                            # 평균 거래량 대비 현재 거래량이 multiplier 배 이상인 경우&#10;                            avg_vol = sum(volumes[1:]) / (len(volumes)-1) if len(volumes) &gt; 1 else 0&#10;                            if avg_vol and volumes[0] &gt; avg_vol * multiplier: # 거래량 급증 감지&#10;                                log.info(f&quot;Watcher detected volume spike on {market} (x{multiplier})&quot;)&#10;&#10;            time.sleep(check_interval)&#10;        except Exception as e:&#10;            log.error(f&quot;Error in watcher loop: {e}&quot;)&#10;            time.sleep(check_interval)&#10;    log.info(&quot;Watcher loop stopped.&quot;)&#10;&#10;# 워처 시작 엔드포인트&#10;# 요청 본문 예시:&#10;# {&quot;market&quot;: &quot;KRW-BTC&quot;,&#10;# &quot;interval&quot;: 1,&#10;# &quot;callbacks&quot;:[&#10;#     {&quot;type&quot;:&quot;volatility_breakout&quot;, &quot;k&quot;:0.5},&#10;#     {&quot;type&quot;:&quot;volume_spike&quot;, &quot;multiplier&quot;:3}&#10;# ]}&#10;@app.post(&quot;/watcher/start&quot;) # 워처 시작 엔드포인트&#10;def start_watcher(payload: Dict[str, Any]):&#10;    if _watcher['running']:&#10;        raise HTTPException(status_code=400, detail=&quot;Watcher already running&quot;)&#10;&#10;    # 파라미터 추출&#10;    market = payload.get('market', config.MARKET)   # 마켓 (기본값 config.MARKET)&#10;    interval = float(payload.get('interval', 1.0))  # 체크 간격 (초)&#10;    callbacks = payload.get('callbacks', [])        # 콜백 조건 리스트&#10;&#10;    # 워처 스레드 시작&#10;    stop_event = threading.Event()&#10;    # 워처 루프 스레드 생성 및 시작&#10;    t = threading.Thread(target=_watcher_loop, args=(stop_event, market, interval, callbacks), daemon=True)&#10;    _watcher['running'] = True              # 워처 상태 갱신&#10;    _watcher['thread'] = t                  # 워처 스레드 저장&#10;    _watcher['stop_event'] = stop_event     # 중지 이벤트 저장&#10;    t.start()&#10;    return {&quot;status&quot;: &quot;started&quot;}&#10;&#10;# 워처 중지 엔드포인트&#10;# 워처 중지 이벤트 설정 및 스레드 종료 대기&#10;# 워처 상태 초기화&#10;# 반환값: {&quot;status&quot;: &quot;stopped&quot;} 또는 {&quot;status&quot;: &quot;not_running&quot;}&#10;@app.post(&quot;/watcher/stop&quot;)&#10;def stop_watcher():&#10;    if not _watcher['running']:&#10;        return {&quot;status&quot;: &quot;not_running&quot;}&#10;    _watcher['stop_event'].set()&#10;    _watcher['thread'].join(timeout=5)&#10;    _watcher['running'] = False&#10;    _watcher['thread'] = None&#10;    _watcher['stop_event'] = None&#10;    return {&quot;status&quot;: &quot;stopped&quot;}&#10;&#10;# 배치 klines 조회 엔드포인트&#10;# 티커/타임프레임/카운트 조합별로 캐시 키 생성 (인메모리 또는 Redis)&#10;# 요청 본문 예시:&#10;# {&quot;tickers&quot;: [&quot;KRW-BTC&quot;,&quot;KRW-ETH&quot;], &quot;timeframe&quot;:&quot;minute15&quot;, &quot;count&quot;:100}&#10;# 반환값 예시:&#10;# {&quot;klines&quot;: {&quot;KRW-BTC&quot;: [...], &quot;KRW-ETH&quot;: [...]} }&#10;# 각 티커별로 klines를 조회하여 결과 딕셔너리에 저장&#10;# 내부적으로 캐시를 사용하여 중복 Upbit 호출 최소화&#10;# 캐시 TTL은 _KLINES_CACHE_TTL 사용&#10;# 캐시 미스 시 rate-limited fetcher를 사용하여 Upbit에서 klines 조회&#10;# 예외 발생 시 해당 티커는 None으로 설정&#10;@app.post('/klines_batch')&#10;def klines_batch(payload: KlinesBatchRequest):&#10;    req = payload.model_dump()&#10;    tickers = req.get('tickers', []) or []&#10;    timeframe = req.get('timeframe', 'minute15')&#10;    count = int(req.get('count', 100))&#10;&#10;    result = {}&#10;    now = time.time()&#10;    for ticker in tickers:&#10;        key = f&quot;{ticker}|{timeframe}|{count}&quot; # 캐시 키 생성&#10;        cached = _cache_get(key)&#10;        # 캐시 유효성 검사&#10;        # 캐시 유효 시 캐시된 값 사용&#10;        if cached and (now - cached[0]) &lt; _KLINES_CACHE_TTL:&#10;            result[ticker] = cached[1]&#10;            continue&#10;&#10;        # 카운트 이상인 캐시 항목 검색 시도 (인메모리 및 Redis 모두 지원)&#10;        # 가장 큰 count를 가진 항목 선택&#10;        # 캐시 미스 시 rate-limited fetcher 사용&#10;        klines = None&#10;        try:&#10;            # 가능한 경우 Redis에서 검색&#10;            if _redis_client:&#10;                try:&#10;                    pattern = f&quot;{ticker}|{timeframe}|*&quot;&#10;                    # 패턴 매칭 키 조회&#10;                    keys = _redis_client.keys(pattern)&#10;                    # 후보 탐색 및 선택 (요청보다 가장 큰 count)&#10;                    best = None&#10;                    best_cnt = 0&#10;                    for k in keys:&#10;                        try:&#10;                            # 키 파싱 [ticker, timeframe, count]&#10;                            parts = k.split('|')&#10;&#10;                            # 유효한 키 형식 시 (3개 이상 파트로 구성)&#10;                            if len(parts) &gt;= 3:&#10;                                # count 부분 (마지막 부분)&#10;                                kcnt = int(parts[-1])&#10;                                # 요청한 카운트보다 크고 현재 최상위 후보보다 큰 경우&#10;                                if kcnt &gt;= count and kcnt &gt; best_cnt:&#10;                                    best = k        # 후보 키 갱신&#10;                                    best_cnt = kcnt # 후보 카운트 갱신&#10;                        except Exception:&#10;                            continue&#10;                    # 후보 키가 발견된 경우&#10;                    if best:&#10;                        # 후보 키로 캐시 조회&#10;                        cached2 = _cache_get(best, ttl=_KLINES_CACHE_TTL)&#10;                        # 후보 캐시에서 klines 추출&#10;                        if cached2:&#10;                            klines_full = cached2[1]&#10;                            # 유효한 klines 시&#10;                            if isinstance(klines_full, list) and len(klines_full) &gt; 0:&#10;                                # 요청한 개수만큼 슬라이싱하여 반환&#10;                                klines = klines_full[-count:]&#10;                except Exception:&#10;                    pass&#10;            else:&#10;                # 인-메모리 캐시에서 후보 탐색&#10;                try:&#10;                    candidates = []&#10;                    # 인-메모리 캐시 순회&#10;                    for k, v in list(_klines_cache.items()):&#10;                        try:&#10;                            # 키 파싱 [ticker, timeframe, count]&#10;                            parts = k.split('|')&#10;                            # 유효한 키 형식 시 (3개 이상 파트로 구성)&#10;                            if parts[0] == ticker and parts[1] == timeframe:&#10;                                kcnt = int(parts[2])            # count 부분&#10;                                candidates.append((kcnt, v))    # 후보 리스트에 추가&#10;                        except Exception:&#10;                            continue&#10;                    # 후보 정렬 및 선택 (요청보다 큰 count)&#10;                    candidates = sorted(candidates, key=lambda x: x[0], reverse=True) # 내림차순 정렬&#10;                    for kcnt, v in candidates:&#10;                        if kcnt &gt;= count:&#10;                            klines_full = v[1]&#10;                            # 유효한 klines 시&#10;                            if isinstance(klines_full, list) and len(klines_full) &gt; 0:&#10;                                # 요청한 개수만큼 슬라이싱하여 반환&#10;                                klines = klines_full[-count:]&#10;                                break&#10;                except Exception:&#10;                    pass&#10;&#10;            # 캐시에서 발견되지 않은 경우 rate-limited fetcher 사용&#10;            if klines is None:&#10;                try:&#10;                    klines = _rate_limited_get_klines(ticker, timeframe, count=count)&#10;                except Exception as e:&#10;                    log.warning(f'Rate-limited batch fetch failed for {ticker}: {e}')&#10;                    klines = None&#10;        except Exception as e:&#10;            log.warning(f'klines_batch lookup error for {ticker}: {e}')&#10;            klines = None&#10;&#10;        # 캐시 설정 (실패 시에도 캐시하여 반복 실패 방지)&#10;        _cache_set(key, klines, ttl=_KLINES_CACHE_TTL)&#10;        result[ticker] = klines&#10;&#10;    return {'klines': result}&#10;&#10;# --- Private API Endpoints ---&#10;# 잔고 조회 엔드포인트&#10;# Upbit 개인 API 키를 사용하여 잔고 조회&#10;# 키가 구성되지 않은 경우 503 반환&#10;# 이 엔드포인트는 짧은 TTL(_BALANCES_CACHE_TTL)로 잔고를 캐시하여 반복된 Upbit 호출을 줄임&#10;# 반환값에는 추가 진단 필드 포함:&#10;#   - balances: Upbit에서 반환된 원시 잔고 리스트&#10;#   - reported_krw_balance: 잔고에서 보고된 KRW 잔고 (없으면 0)&#10;#   - cached: 응답이 서버 캐시에서 왔는지 여부&#10;#   - cached_ts: 캐시된 시점 타임스탬프&#10;@app.get('/balances')&#10;def get_balances():&#10;    # 잔고 조회 엔드포인트&#10;    if _upbit_private is None:&#10;        raise HTTPException(status_code=503, detail='Upbit API keys not configured on server; balances unavailable')&#10;&#10;    cache_key = 'upbit:balances:all'&#10;    now = time.time()&#10;&#10;    # 캐시 조회 시도&#10;    cached = _cache_get(cache_key, ttl=_BALANCES_CACHE_TTL)&#10;    if cached and (now - cached[0]) &lt; _BALANCES_CACHE_TTL:&#10;        bl = cached[1]&#10;        cached_flag = True&#10;        cached_ts = cached[0]&#10;        log.debug('Balances: cache hit')&#10;    else:&#10;        cached_flag = False&#10;        cached_ts = None&#10;        try:&#10;            bl = _upbit_private.get_balances()&#10;        except Exception as e:&#10;            log.error(f'Balances retrieval failed: {e}')&#10;            # 캐시가 존재하면 캐시된 값 반환 (최선의 노력)&#10;            if cached:&#10;                bl = cached[1]&#10;                cached_flag = True&#10;                cached_ts = cached[0]&#10;            else:&#10;                raise HTTPException(status_code=502, detail=f'Upbit API call failed: {e}')&#10;        # 캐시 설정 (실패 시에도 캐시하여 반복 실패 방지)&#10;        _cache_set(cache_key, bl, ttl=_BALANCES_CACHE_TTL)&#10;&#10;    # KRW 잔고 계산 (반환된 잔고에서)&#10;    # 'currency' 또는 'unit' 필드 사용&#10;    reported_krw = 0.0&#10;    try:&#10;        if isinstance(bl, list):&#10;            for item in bl:&#10;                # 업비트API /v1/accounts는 'currency'와 'balance' 필드를 가진 항목 반환&#10;                try:&#10;                    cur = str(item.get('currency') or item.get('unit') or '').upper()&#10;                    bal = float(item.get('balance') or 0.0)&#10;                except Exception:&#10;                    continue&#10;                if cur == 'KRW' or cur.startswith('KRW'):&#10;                    reported_krw += bal&#10;        elif isinstance(bl, dict):&#10;            # 딕셔너리 형태인 경우 'balances' 키에서 리스트 추출&#10;            lst = bl.get('balances') if 'balances' in bl else None&#10;            if isinstance(lst, list):&#10;                for item in lst:&#10;                    try:&#10;                        cur = str(item.get('currency') or item.get('unit') or '').upper()&#10;                        bal = float(item.get('balance') or 0.0)&#10;                    except Exception:&#10;                        continue&#10;                    if cur == 'KRW' or cur.startswith('KRW'):&#10;                        reported_krw += bal&#10;    except Exception:&#10;        reported_krw = 0.0&#10;&#10;    return {&#10;        'balances': bl,&#10;        'reported_krw_balance': reported_krw,&#10;        'cached': bool(cached_flag),&#10;        'cached_ts': cached_ts,&#10;    }&#10;&#10;# 포지션 조회 엔드포인트&#10;# Upbit 개인 API 키를 사용하여 잔고 조회 후 현재 가격과 결합하여 포지션 계산&#10;# 키가 구성되지 않은 경우 503 반환&#10;# 각 자산별 포지션 정보와 요약 총계 반환&#10;# 포지션 정보에는 다음 필드 포함:&#10;#   - symbol: 마켓 심볼 (예: KRW-BTC)&#10;#   - side: 포지션 방향 (항상 'LONG'으로 설정)&#10;#   - size: 보유 수량&#10;#   - entry_price: 평균 매수가 (없으면 null)&#10;#   - current_price: 현재 가격&#10;#   - unrealized_pnl: 미실현 손익 (없으면 null)&#10;#   - unrealized_pnl_rate: 미실현 손익률 (없으면 null)&#10;#   - notional_krw: 원화 기준 명목 가치&#10;# 요약 정보에는 다음 필드 포함:&#10;#   - total_equity_krw: 총 자산 가치 (원화 기준)&#10;#   - available_krw: 사용 가능한 원화 잔고&#10;#   - prices_fetched: 현재 가격을 성공적으로 조회한 자산 수&#10;#   - excluded_assets: 현재 가격을 조회하지 못해 제외된 자산 목록 (심볼 및 사유 포함)&#10;# 포지션 스냅샷은 히스토리 스토어에 기록됨&#10;# 반환값 예시:&#10;# {&#10;#   &quot;positions&quot;: [ {...}, {...}, ... ],&#10;#   &quot;total_equity_krw&quot;: 12345678.9,&#10;#   &quot;available_krw&quot;: 2345678.9,&#10;#   &quot;prices_fetched&quot;: 5,&#10;#   &quot;excluded_assets&quot;: [ {&quot;symbol&quot;: &quot;KRW-XYZ&quot;, &quot;reason&quot;: &quot;no_price&quot;}, ... ]&#10;# }&#10;@app.get(&quot;/positions&quot;)&#10;def get_positions():&#10;    if _upbit_private is None:&#10;        raise HTTPException(status_code=503, detail='Upbit API keys not configured on server; positions unavailable')&#10;&#10;    try:&#10;        bl = _upbit_private.get_balances() or []&#10;    except Exception as e:&#10;        log.error(f'Failed to retrieve balances for positions endpoint: {e}')&#10;        raise HTTPException(status_code=502, detail=f'Failed to retrieve balances: {e}')&#10;&#10;    positions = []&#10;    total_equity = 0.0&#10;    available_krw = 0.0&#10;&#10;    #시장리스트 작성 및 통화맵 작성 (가격 조회용)&#10;    markets = []&#10;    currency_map = {}&#10;    try:&#10;        for item in bl:&#10;            cur = str(item.get('currency') or item.get('unit') or '').upper()&#10;            bal = float(item.get('balance') or 0) if item is not None else 0.0&#10;            locked = float(item.get('locked') or 0) if item is not None else 0.0&#10;&#10;            # 원화 현금잔고 처리&#10;            if cur == 'KRW' or cur.startswith('KRW'):&#10;                available_krw += bal&#10;                total_equity += bal&#10;                continue&#10;            size = bal + locked&#10;            if size &lt;= 0:&#10;                continue&#10;            market = f'KRW-{cur}'&#10;            markets.append(market)&#10;            currency_map[market] = {&#10;                'currency': cur,&#10;                'size': size,&#10;                'avg_buy_price': float(item.get('avg_buy_price') or 0)&#10;            }&#10;    except Exception as e:&#10;        log.warning(f'Error while parsing balances for positions: {e}')&#10;&#10;    # 현재가격 조회 (1개 캔들 minute1, count=1) (조회수 제한 주의)&#10;    price_map = {}&#10;    for m in set(markets):&#10;        try:&#10;            kl = None&#10;            try:&#10;                kl = _rate_limited_get_klines(m, 'minute1', count=1)&#10;            except Exception as e:&#10;                log.warning(f'Price fetch failed for {m}: {e}')&#10;                kl = None&#10;            price = None&#10;            if kl and isinstance(kl, list) and len(kl) &gt; 0:&#10;                try:&#10;                    first = kl[0]&#10;                    price_candidate = None&#10;&#10;                    # 딕셔너리 레코드 작업&#10;                    # (Upbit API는 'trade_price' 사용)&#10;                    if isinstance(first, dict):&#10;                        price_candidate = first.get('trade_price') or first.get('close')&#10;                    else:&#10;                        # 속성 접근 시도 (일부 래퍼는 .close 또는 .trade_price 노출 가능)&#10;                        price_candidate = getattr(first, 'trade_price', None) or getattr(first, 'close', None)&#10;                    if price_candidate is None:&#10;                        price = None&#10;                    else:&#10;                        price = float(price_candidate)&#10;                except Exception:&#10;                    price = None&#10;            price_map[m] = price&#10;        except Exception as e:&#10;             log.warning(f'Unexpected error fetching price for {m}: {e}')&#10;             price_map[m] = None&#10;&#10;    # 포지션 구성 및 미실현 손익/명목 가치 계산&#10;    excluded_assets = []&#10;    for market, meta in currency_map.items():&#10;        cur = meta['currency']&#10;        size = float(meta['size'])&#10;        avg_price = float(meta.get('avg_buy_price') or 0.0)&#10;        current_price = price_map.get(market)&#10;&#10;        # 자산 현재 가격이 없으면 건너뛰고 보고&#10;        if current_price is None:&#10;            excluded_assets.append({'symbol': market, 'reason': 'no_price'})&#10;            continue&#10;&#10;        notional = size * float(current_price)&#10;        total_equity += notional&#10;        unrealized = None&#10;        unrealized_rate = None&#10;        if avg_price and avg_price &gt; 0:&#10;            unrealized = (float(current_price) - avg_price) * size&#10;            unrealized_rate = (float(current_price) - avg_price) / avg_price * 100&#10;&#10;        pos = {&#10;            'symbol': market,&#10;            'side': 'LONG',&#10;            'size': size,&#10;            'entry_price': avg_price if avg_price &gt; 0 else None,&#10;            'current_price': current_price,&#10;            'unrealized_pnl': unrealized,&#10;            'unrealized_pnl_rate': unrealized_rate,&#10;            'notional_krw': notional,&#10;        }&#10;        positions.append(pos)&#10;&#10;    # Also include list of excluded assets so UI can show a friendly message.&#10;    result = {&#10;        'positions': positions,&#10;        'total_equity_krw': total_equity,&#10;        'available_krw': available_krw,&#10;        'prices_fetched': len([p for p in price_map.values() if p is not None]),&#10;        'excluded_assets': excluded_assets,&#10;    }&#10;    history_store.record_snapshot({&#10;        'ts': time.time(),&#10;        'total_equity': total_equity,&#10;        'available_krw': available_krw,&#10;        'positions': [&#10;            {&#10;                'symbol': pos['symbol'],&#10;                'notional_krw': pos['notional_krw'],&#10;                'unrealized_pnl': pos['unrealized_pnl'],&#10;            }&#10;            for pos in positions&#10;        ],&#10;    })&#10;    return result&#10;&#10;&#10;@app.get('/positions/history')&#10;def get_positions_history(limit: int = 365, days: int = 365):&#10;    since = time.time() - float(days) * 86400&#10;    history = history_store.get_history(since=since, limit=limit)&#10;    return {'history': history}&#10;&#10;@app.post('/ws/start')&#10;def ws_start():&#10;    try:&#10;        start_ws_listener()&#10;        start_ticker_listener()&#10;        return {'status': 'started'}&#10;    except Exception as exc:&#10;        raise HTTPException(status_code=500, detail=f'Failed to start websocket listener: {exc}')&#10;&#10;@app.post('/ws/stop')&#10;def ws_stop():&#10;    try:&#10;        stop_ws_listener()&#10;        stop_ticker_listener()&#10;        return {'status': 'stopped'}&#10;    except Exception as exc:&#10;        raise HTTPException(status_code=500, detail=f'Failed to stop websocket listener: {exc}')&#10;&#10;@app.get('/ws/status')&#10;def ws_status():&#10;    running = bool(_ws_listener and _ws_listener._thread and _ws_listener._thread.is_alive())&#10;    return {'running': running, 'targets': _ws_listener.targets if _ws_listener else []}&#10;&#10;@app.get('/ws/stats')&#10;def ws_stats(last_hour_sec: int = 3600, recent_limit: int = 10):&#10;    raw_stats = load_ws_stats()&#10;    summary = summarize_ws_stats(raw_stats, last_hour_secs=last_hour_sec, recent_limit=recent_limit)&#10;    summary.update({&#10;        'running': bool(_ws_listener and _ws_listener._thread and _ws_listener._thread.is_alive()),&#10;        'targets': _ws_listener.targets if _ws_listener else [],&#10;    })&#10;    return summary&#10;&#10;@app.get('/ws/executions')&#10;def ws_executions(limit: int = 0):&#10;    try:&#10;        entries = read_exec_history(limit=limit)&#10;    except Exception as exc:&#10;        raise HTTPException(status_code=500, detail=f'Failed to load exec history: {exc}')&#10;    return {'executions': entries}&#10;&#10;@app.get('/ws/trades')&#10;def ws_trades(symbol: str, limit: int = 20):&#10;    if _redis_client is None:&#10;        raise HTTPException(status_code=503, detail='Redis cache unavailable; cannot read trades.')&#10;    if not symbol:&#10;        raise HTTPException(status_code=400, detail='symbol query parameter is required.')&#10;    max_limit = min(max(limit, 1), 200)&#10;    key = f'ws:trades:{symbol}'&#10;    raw = _redis_client.lrange(key, 0, max_limit - 1)&#10;    trades = []&#10;    try:&#10;        for item in raw:&#10;            import json as _json&#10;            trades.append(_json.loads(item))&#10;    except Exception:&#10;        trades = []&#10;    return {'symbol': symbol, 'trades': trades}&#10;&#10;&#10;def _ws_ticker_targets() -&gt; List[str]:&#10;    if _ws_listener:&#10;        return _ws_listener.targets&#10;    universe = config._config.get('universe')&#10;    if isinstance(universe, list) and universe:&#10;        return universe&#10;    return [&#10;        'KRW-BTC',&#10;        'KRW-ETH',&#10;        'KRW-ADA',&#10;        'KRW-XRP',&#10;        'KRW-SOL',&#10;    ]&#10;&#10;&#10;@app.get('/ws/ticker_data')&#10;def ws_ticker_data():&#10;    if _redis_client is None:&#10;        raise HTTPException(status_code=503, detail='Redis cache unavailable; cannot read ticker data.')&#10;    targets = _ws_ticker_targets()&#10;    payloads: List[Dict[str, Any]] = []&#10;    for symbol in targets:&#10;        key = f'ws:ticker:{symbol}'&#10;        raw = _redis_client.get(key)&#10;        if not raw:&#10;            continue&#10;        try:&#10;            data = json.loads(raw)&#10;        except Exception:&#10;            continue&#10;        payloads.append({&#10;            'symbol': symbol,&#10;            'opening_price': data.get('opening_price'),&#10;            'high_price': data.get('high_price'),&#10;            'low_price': data.get('low_price'),&#10;            'trade_price': data.get('trade_price') or data.get('trade_price'),&#10;            'prev_closing_price': data.get('prev_closing_price'),&#10;            'change': data.get('change'),&#10;            'timestamp': data.get('trade_timestamp') or data.get('timestamp'),&#10;        })&#10;    return {'tickers': payloads}" />
              <option name="updatedContent" value="from fastapi import FastAPI, HTTPException # web framework&#10;from contextlib import asynccontextmanager # for lifespan management&#10;from pydantic import BaseModel # data validation, settings management&#10;from typing import Any, Dict, List, Optional # type hints&#10;import threading&#10;import time&#10;import os&#10;&#10;# 시간대 설정&#10;os.environ.setdefault('TZ', 'Asia/Seoul')&#10;try:&#10;    time.tzset()&#10;except Exception:&#10;    pass&#10;&#10;# 외부라이브러리 임포트&#10;import redis # Redis 클라이언트&#10;import json&#10;from concurrent.futures import ThreadPoolExecutor, as_completed # for parallel prefetching&#10;&#10;# 내부API 모듈 임포트&#10;from server import config               # 런타임 설정 관리&#10;from server.upbit_api import UpbitAPI   # 업비트 API 연동&#10;from server.logger import log           # 로깅 설정&#10;from server.history import history_store&#10;from server.ws_listener_base import (&#10;    load_ws_stats,&#10;    summarize_ws_stats,&#10;    read_exec_history,&#10;)&#10;from server.ws_listener_private import PrivateWebsocketListener&#10;from server.ws_listener_public import PublicWebsocketlistener&#10;&#10;# Token Bucket 구현 for prefetch&#10;# 간단한 토큰 버킷(rate limiter) 구현&#10;# rate: 초당 토큰 생성 속도&#10;# capacity: 버킷 최대 토큰 수&#10;# consume(tokens, timeout): 지정된 토큰 수를 소비 시도, 타임아웃 내에 성공 여부 반환&#10;# 스레드 안전 구현&#10;# 사용 예시:&#10;# tb = TokenBucket(rate=5, capacity=10)  # 초당 5토큰, 최대 10토큰&#10;# if tb.consume(tokens=1, timeout=2.0):&#10;#     print(&quot;Token acquired&quot;)&#10;# else:&#10;#     print(&quot;Failed to acquire token within timeout&quot;)&#10;class TokenBucket:&#10;    def __init__(self, rate: float, capacity: float):&#10;        self.rate = float(rate)         # 토큰 생성 속도 (초당)&#10;        self.capacity = float(capacity) # 버킷 최대 용량&#10;        self._tokens = float(capacity)  # 현재 토큰 수&#10;        self._last = time.time()        # 마지막 토큰 갱신 시각&#10;        self._lock = threading.Lock()   # 스레드 안전을 위한 락&#10;&#10;    # 토큰 소비 메서드&#10;    # tokens: 소비할 토큰 수&#10;    # timeout: 최대 대기 시간 (초)&#10;    # 반환값: 성공 시 True, 실패 시 False&#10;    def consume(self, tokens: float = 1.0, timeout: float = 5.0) -&gt; bool:&#10;        end = time.time() + float(timeout)&#10;        while time.time() &lt; end:&#10;            with self._lock:&#10;                now = time.time()&#10;                elapsed = max(0.0, now - self._last)&#10;                self._tokens = min(self.capacity, self._tokens + elapsed * self.rate)&#10;                self._last = now&#10;                if self._tokens &gt;= tokens:&#10;                    self._tokens -= tokens&#10;                    return True&#10;            time.sleep(0.01)&#10;        return False&#10;&#10;&#10;# 세마포어 및 토큰 버킷 초기화 (스케줄러 시작 시)&#10;_prefetch_token_bucket: Optional[TokenBucket] = None&#10;_prefetch_semaphore: Optional[threading.BoundedSemaphore] = None&#10;&#10;# 기본 klines 캐시 TTL (초)&#10;# 환경변수 'KLINES_CACHE_TTL'로 설정 가능, 기본값 600초&#10;# 예: os.environ['KLINES_CACHE_TTL'] = '600'&#10;# (기본값 600초로 설정하여 중복 Upbit 요청 감소, 실시간성은 다소 희생, 값이 클수록 캐시 지속시간 증가)&#10;_KLINES_CACHE_TTL = int(os.getenv('KLINES_CACHE_TTL', str(600)))  # default 600s&#10;&#10;# Balances cache TTL (seconds)&#10;_BALANCES_CACHE_TTL = int(os.getenv('BALANCES_CACHE_TTL', '15'))&#10;&#10;# FastAPI 앱 생성 및 수명 주기 관리&#10;@asynccontextmanager&#10;async def lifespan(app: FastAPI): # 수명 주기 관리&#10;    # start prefetch scheduler on startup&#10;    try:&#10;        # read interval from config, default 30s&#10;        # if invalid, fallback to 30s&#10;        # prefetch interval 설정&#10;        # 기본값 30초&#10;        # 환경변수나 config.json의 'prefetch_interval_sec' 키로 설정 가능&#10;        interval = int(config._config.get('prefetch_interval_sec', 30))&#10;    except Exception:&#10;        interval = 30&#10;&#10;    # 스케쥴러 시작&#10;    start_prefetch_scheduler(interval=interval)&#10;    try:&#10;        start_ws_listener()&#10;        start_ticker_listener()&#10;    except Exception as exc:&#10;        log.warning(f'Failed to start websocket listener on startup: {exc}')&#10;    try:&#10;        yield&#10;    finally:&#10;        # 스케쥴러 중지&#10;        stop_prefetch_scheduler()&#10;        stop_ws_listener()&#10;        stop_ticker_listener()&#10;&#10;app = FastAPI(title=&quot;Upbit Trader Runtime API&quot;, lifespan=lifespan) # FastAPI 앱 생성&#10;&#10;# 데이터 모델 정의&#10;class ConfigPayload(BaseModel):&#10;    config: Dict[str, Any]&#10;&#10;# 배치 klines 요청 모델&#10;class KlinesBatchRequest(BaseModel):&#10;    tickers: List[str]&#10;    timeframe: Optional[str] = 'minute15'&#10;    count: Optional[int] = 100&#10;&#10;# 포지션 모델 정의&#10;class Position(BaseModel):&#10;    ticker: str&#10;    amount: float&#10;    avg_price: float&#10;    current_price: float&#10;    pnl: float&#10;&#10;# --- Background Prefetch Scheduler 및 캐시 관리 ---&#10;# 전역 상태 변수들&#10;# Prefetch 스레드 및 제어 변수&#10;# Simple in-memory watcher state (explicit typing to satisfy linters)&#10;_watcher: Dict[str, Any] = {&#10;    'running': False,&#10;    'thread': None,&#10;    'stop_event': None,&#10;}&#10;&#10;# 캐시 딕셔너리&#10;# Simple in-memory cache for batch klines: { key: (timestamp, data) }&#10;_klines_cache: Dict[str, Any] = {}&#10;&#10;&#10;# 레디스(Redis) 클라이언트 초기화&#10;# Redis setup (optional). Use local redis://localhost:6379 if REDIS_URL not set&#10;# 환경변수 'REDIS_URL'로 Redis URL 설정 가능&#10;REDIS_URL = os.getenv('REDIS_URL', 'redis://localhost:6379/0')&#10;_redis_client = None&#10;try:&#10;    # Redis 클라이언트 생성 및 연결 테스트&#10;    _redis_client = redis.from_url(REDIS_URL, decode_responses=True)&#10;    # ping 테스트&#10;    _redis_client.ping()&#10;    log.info(f'Redis cache connected: {REDIS_URL}')&#10;except Exception as e:&#10;    _redis_client = None&#10;    log.warning(f'Redis not available ({REDIS_URL}): {e}. Falling back to in-memory cache')&#10;&#10;# 캐시 설정 함수&#10;# key: 캐시 키&#10;# value: 캐시 값&#10;# ttl: 캐시 만료 시간 (초)&#10;# 기본 TTL은 _KLINES_CACHE_TTL 사용&#10;# Redis 사용 가능 시 Redis에 저장, 아니면 메모리 내 딕셔너리에 저장&#10;# 캐시 조회 시 만료 시간 확인&#10;# 반환값: (타임스탬프, 값) 또는 None&#10;def _cache_set(key: str, value: Any, ttl: int = _KLINES_CACHE_TTL):&#10;    &quot;&quot;&quot;Set cache in Redis if available, else in-memory.&quot;&quot;&quot;&#10;    now = time.time()&#10;    if _redis_client:&#10;        try:&#10;            # store JSON string&#10;            import json as _json&#10;            payload = {'ts': now, 'value': value}&#10;            _redis_client.setex(key, ttl, _json.dumps(payload)) # set with expiry&#10;            return&#10;        except Exception:&#10;            pass&#10;    _klines_cache[key] = (now, value) # store in-memory&#10;&#10;# 캐시 조회 함수&#10;# key: 캐시 키&#10;# ttl: 캐시 만료 시간 (초)&#10;# 기본 TTL은 _KLINES_CACHE_TTL 사용&#10;# 반환값: (타임스탬프, 값) 또는 None&#10;def _cache_get(key: str, ttl: int = _KLINES_CACHE_TTL):&#10;    &quot;&quot;&quot;Get cache value. Return (timestamp, value) or None.&quot;&quot;&quot;&#10;    if _redis_client:&#10;        try:&#10;            import json as _json&#10;            s = _redis_client.get(key) # get JSON string&#10;            if not s:&#10;                return None&#10;            obj = _json.loads(s) # parse JSON&#10;            if time.time() - obj.get('ts', 0) &gt; ttl:&#10;                return None&#10;            return (obj.get('ts'), obj.get('value')) # return (timestamp, value)&#10;        except Exception:&#10;            return None&#10;    return _klines_cache.get(key) # return (timestamp, value) or None&#10;&#10;# Websocket listener state&#10;_ws_listener: Optional[PrivateWebsocketListener] = None&#10;_ticker_listener: Optional[PublicWebsocketlistener] = None&#10;&#10;def start_ws_listener() -&gt; None:&#10;    global _ws_listener&#10;    if _ws_listener and _ws_listener._thread and _ws_listener._thread.is_alive():&#10;        return&#10;    _ws_listener = PrivateWebsocketListener(redis_client=_redis_client)&#10;    _ws_listener.start()&#10;&#10;&#10;def start_ticker_listener() -&gt; None:&#10;    global _ticker_listener&#10;    if _ticker_listener and _ticker_listener._thread and _ticker_listener._thread.is_alive():&#10;        return&#10;    _ticker_listener = PublicWebsocketlistener(redis_client=_redis_client)&#10;    _ticker_listener.start()&#10;&#10;&#10;def stop_ws_listener() -&gt; None:&#10;    global _ws_listener&#10;    if _ws_listener:&#10;        _ws_listener.stop()&#10;&#10;&#10;def stop_ticker_listener() -&gt; None:&#10;    global _ticker_listener&#10;    if _ticker_listener:&#10;        _ticker_listener.stop()&#10;&#10;# Rate-limited Upbit klines fetcher&#10;# ticker_local: 업비트 로컬 티커명 (예: KRW-BTC)&#10;# timeframe: 캔들 시간대 (예: 'minute15')&#10;# count: 조회할 캔들 개수&#10;# 반환값: UpbitAPI.get_klines() 결과&#10;# 전역 토큰 버킷 및 세마포어를 사용하여 호출 제한 및 동시성 제어&#10;# 토큰 획득 및 세마포어 획득 시 타임아웃 처리&#10;# 예외 발생 시 호출 실패&#10;# 반환값: UpbitAPI.get_klines() 결과&#10;def _rate_limited_get_klines(ticker_local: str, timeframe: str, count: int):&#10;    # 전역 토큰 버킷 및 세마포어 사용&#10;    global _prefetch_token_bucket, _prefetch_semaphore&#10;&#10;    # 세마포어 및 토큰 획득 시도&#10;    # 타임아웃은 config의 'prefetch_token_wait_timeout' 키로 설정 가능, 기본 10초&#10;    # 실제 Upbit 호출 수행&#10;    # 예외 발생 시 호출 실패&#10;    acquired = False&#10;    try:&#10;        # 세마포어 획득 시도&#10;        if _prefetch_semaphore is not None:&#10;            # 세마포어 획득 (대기 시간 설정 기본값 10초)&#10;            acquired = _prefetch_semaphore.acquire(timeout=10)&#10;            if not acquired:&#10;                raise RuntimeError('prefetch_semaphore_timeout')&#10;&#10;        # 토큰 획득 시도&#10;        if _prefetch_token_bucket is not None:&#10;            # 토큰 대기 시간 설정&#10;            # 기본값 10초 (즉시 호출 선호), config의 'prefetch_token_wait_timeout' 키로 설정 가능&#10;            try:&#10;                token_wait = float(config._config.get('prefetch_token_wait_timeout', 10.0))&#10;            except Exception:&#10;                token_wait = 10.0&#10;            ok = _prefetch_token_bucket.consume(tokens=1.0, timeout=token_wait)&#10;            if not ok:&#10;                raise RuntimeError('rate_limited')&#10;        # 업비트 공용 API 호출 수행&#10;        # 반환값: UpbitAPI.get_klines() 결과&#10;        # 참고: UpbitAPI 인스턴스는 전역 _upbit_public 사용&#10;        # 이 인스턴스는 API 키를 사용하지 않음&#10;        return _upbit_public.get_klines(ticker_local, timeframe, count=count)&#10;    finally:&#10;        if acquired and _prefetch_semaphore is not None:&#10;            try:&#10;                _prefetch_semaphore.release() # 세마포어 해제&#10;            except Exception:&#10;                pass&#10;&#10;&#10;# 업비트 공용 API 인스턴스&#10;_upbit_public = UpbitAPI()&#10;&#10;# 업비트 인증(Private) API 인스턴스&#10;try:&#10;    access = getattr(config, 'UPBIT_ACCESS_KEY', None)&#10;    secret = getattr(config, 'UPBIT_SECRET_KEY', None)&#10;    if access and secret:&#10;        _upbit_private = UpbitAPI(access_key=access, secret_key=secret)&#10;        log.info('Upbit private API initialized with provided keys')&#10;    else:&#10;        _upbit_private = None&#10;        log.warning('Upbit API keys not provided: private endpoints will be unavailable')&#10;except Exception as e:&#10;    _upbit_private = None&#10;    log.warning(f'Failed to initialize Upbit private API: {e}')&#10;&#10;# 스케쥴러 스레드 및 제어 변수&#10;_prefetch_thread: Optional[threading.Thread] = None&#10;_prefetch_stop = threading.Event()&#10;_prefetch_index = 0&#10;&#10;# 루프 함수 - 주기적으로 universe의 티커들에 대해 klines를 미리 가져와 캐시에 저장&#10;# interval: 루프 주기 (초)&#10;# 기본값 30초&#10;def _prefetch_loop(interval: int = 30):&#10;    log.info('Prefetch scheduler started')&#10;    effective_interval = interval&#10;    while not _prefetch_stop.is_set():&#10;        try:&#10;            # 설정 읽기&#10;            cfg = config._config&#10;            # 티커 유니버스&#10;            universe = cfg.get('universe', [])&#10;            # 실행 중 설정 체크 (런타임 config에서 재정의 허용)&#10;            cfg_count = int(cfg.get('prefetch_count', 200))&#10;            # Redis 미사용 시 보수적으로 설정, upper bound 허용&#10;            if _redis_client is None:&#10;                # When Redis is missing, be conservative but allow a configurable upper bound&#10;                # Redis 미사용 시 최대값 설정, 기본 120, config의 'prefetch_no_redis_max_count' 키로 설정 가능&#10;                try:&#10;                    no_redis_max = int(cfg.get('prefetch_no_redis_max_count', 120))&#10;                except Exception:&#10;                    no_redis_max = 120&#10;                count = min(cfg_count, no_redis_max)&#10;                per_ticker_sleep = float(cfg.get('prefetch_sleep_sec', 1.0))&#10;                log.info('Redis not available: using conservative prefetch settings (count=%s, sleep=%.2f)', count, per_ticker_sleep)&#10;            else:&#10;                count = cfg_count&#10;                per_ticker_sleep = float(cfg.get('prefetch_sleep_sec', 0.2))&#10;&#10;            # Redis 미사용 시 최소 간격 보장&#10;            effective_interval = interval&#10;            if _redis_client is None:&#10;                effective_interval = max(interval, int(cfg.get('prefetch_min_interval_sec', 60)))&#10;            if universe:&#10;                # staggered batch processing to avoid bursts&#10;                batch_size = int(cfg.get('prefetch_batch_size', 5))     # batch size per run&#10;                parallelism = int(cfg.get('prefetch_parallelism', 3))   # max parallel fetches per batch&#10;                global _prefetch_index&#10;                n = len(universe)&#10;                if n == 0:&#10;                    pass&#10;                else:&#10;                    start = _prefetch_index % n # start index&#10;                    end = start + batch_size    # end index (exclusive)&#10;                    indices = list(range(start, min(end, n)))&#10;                    # wrap-around if needed&#10;                    if end &gt; n:&#10;                        indices += list(range(0, end - n))&#10;                    tickers_to_process = [universe[i] for i in indices]&#10;                    # advance index for next run&#10;                    _prefetch_index = (start + len(tickers_to_process)) % max(n,1)&#10;&#10;                    # helper to fetch and cache single ticker&#10;                    def _prefetch_single(ticker_local: str):&#10;                        try:&#10;                            key_local = f&quot;{ticker_local}|minute15|{count}&quot;&#10;                            cached_local = _cache_get(key_local)&#10;                            if cached_local and (time.time() - cached_local[0]) &lt; _KLINES_CACHE_TTL:&#10;                                return (ticker_local, True, 'cached')&#10;                            # use rate-limited fetch so prefetch respects global rate/concurrency limits&#10;                            klines_local = _rate_limited_get_klines(ticker_local, 'minute15', count=count)&#10;                            _cache_set(key_local, klines_local, ttl=_KLINES_CACHE_TTL)&#10;                            return (ticker_local, True, 'fetched')&#10;                        except Exception as exc:&#10;                            log.error(f'Prefetch ticker error for {ticker_local}: {exc}')&#10;                            return (ticker_local, False, str(exc))&#10;&#10;                    # run in ThreadPoolExecutor with limited parallelism&#10;                    with ThreadPoolExecutor(max_workers=min(parallelism, len(tickers_to_process))) as executor:&#10;                        futures = {executor.submit(_prefetch_single, t): t for t in tickers_to_process}&#10;                        for fut in as_completed(futures):&#10;                            try:&#10;                                ticker_res, ok, msg = fut.result()&#10;                                log.debug(f'Prefetch result: {ticker_res} ok={ok} info={msg}')&#10;                            except Exception as e:&#10;                                log.error(f'Prefetch future error: {e}')&#10;                    # after parallel batch, small pause to avoid immediate repeated calls&#10;                    time.sleep(per_ticker_sleep)&#10;        except Exception as e:&#10;            log.error(f'Prefetch error: {e}')&#10;        # wait using effective interval (recompute per loop)&#10;        try:&#10;            _prefetch_stop.wait(effective_interval)&#10;        except UnboundLocalError:&#10;            _prefetch_stop.wait(interval)&#10;    log.info('Prefetch scheduler stopped')&#10;&#10;# 스케쥴러 시작 함수&#10;# interval: 루프 주기 (초)&#10;# 기본값 30초&#10;def start_prefetch_scheduler(interval: int = 30):&#10;    global _prefetch_thread, _prefetch_stop&#10;    if _prefetch_thread is not None and _prefetch_thread.is_alive():&#10;        return&#10;    _prefetch_stop.clear()&#10;    # Redis 미사용 시 기본 간격 증가&#10;    # Upbit 호출 부담 축소를 위한 조치&#10;    # 기본 최소 60초&#10;    if _redis_client is None:&#10;        interval = max(interval, 60)&#10;        log.info('Redis not connected: starting prefetch with interval %s seconds', interval)&#10;    # Redis 미사용 시 기본 배치 크기 축소&#10;    if _redis_client is None:&#10;        try:&#10;            # 배치사이즈 기본 3으로 축소, config에 없으면 설정&#10;            if 'prefetch_batch_size' not in config._config:&#10;                config._config['prefetch_batch_size'] = 3&#10;        except Exception:&#10;            pass&#10;    # 프리페치 레이트 리미터 및 세마포어 초기화&#10;    # 설정값 읽기 및 기본값 적용&#10;    global _prefetch_token_bucket, _prefetch_semaphore # 전역 변수&#10;    try:&#10;        # 초당 5토큰&#10;        rate = int(config._config.get('prefetch_rate_per_sec', 5))&#10;    except Exception:&#10;        rate = 5&#10;    try:&#10;        # 용량은 rate와 같게&#10;        capacity = int(config._config.get('prefetch_rate_capacity', max(1, rate)))&#10;    except Exception:&#10;        capacity = max(1, rate)&#10;    try:&#10;        # 동시 3개&#10;        max_concurrent = int(config._config.get('prefetch_max_concurrent', 3))&#10;    except Exception:&#10;        max_concurrent = 3&#10;    try:&#10;        # 토큰 버킷 및 세마포어 초기화&#10;        _prefetch_token_bucket = TokenBucket(rate=float(rate), capacity=float(capacity))&#10;        _prefetch_semaphore = threading.BoundedSemaphore(max_concurrent)&#10;        log.info(f'Prefetch rate limiter initialized: rate={rate}/s, capacity={capacity}, max_concurrent={max_concurrent}')&#10;    except Exception as e:&#10;        _prefetch_token_bucket = None&#10;        _prefetch_semaphore = None&#10;        log.warning(f'Failed to initialize prefetch rate limiter: {e}')&#10;    _prefetch_thread = threading.Thread(target=_prefetch_loop, args=(interval,), daemon=True)&#10;    _prefetch_thread.start()&#10;&#10;# 스케쥴러 중지 함수&#10;# 스케쥴러 스레드 종료 대기 (최대 2초)&#10;# 기본값 30초&#10;def stop_prefetch_scheduler():&#10;    global _prefetch_thread, _prefetch_stop&#10;    _prefetch_stop.set()&#10;    if _prefetch_thread is not None:&#10;        _prefetch_thread.join(timeout=2)&#10;    _prefetch_thread = None&#10;&#10;&#10;@app.get(&quot;/health&quot;) # 헬스체크 엔드포인트&#10;def health():&#10;    return {&quot;status&quot;: &quot;ok&quot;}&#10;&#10;&#10;@app.get('/debug/status') # 디버그 상태 엔드포인트&#10;def debug_status():&#10;    &quot;&quot;&quot;Return diagnostic info: pyupbit presence, redis connection, prefetch thread state, universe size.&quot;&quot;&quot;&#10;    try:&#10;        import server.upbit_api as upbit_api&#10;        has_pyupbit = bool(getattr(upbit_api, '_HAS_PYUPBIT', False))&#10;    except Exception:&#10;        has_pyupbit = False&#10;&#10;    redis_up = False&#10;    try:&#10;        redis_up = _redis_client is not None&#10;    except Exception:&#10;        redis_up = False&#10;&#10;    prefetch_running = False&#10;    try:&#10;        prefetch_running = (_prefetch_thread is not None and _prefetch_thread.is_alive())&#10;    except Exception:&#10;        prefetch_running = False&#10;&#10;    universe_len = 0&#10;    try:&#10;        universe_len = len(config._config.get('universe', []))&#10;    except Exception:&#10;        universe_len = 0&#10;&#10;    return {&#10;        'pyupbit': has_pyupbit,&#10;        'redis': redis_up,&#10;        'prefetch_running': prefetch_running,&#10;        'prefetch_index': _prefetch_index,&#10;        'universe_len': universe_len,&#10;    }&#10;&#10;&#10;@app.get(&quot;/config&quot;) # 설정 조회 엔드포인트&#10;def get_config():&#10;    cfg = config._config&#10;    return {&quot;config&quot;: cfg}&#10;&#10;&#10;@app.post(&quot;/config&quot;) # 설정 저장 엔드포인트&#10;def post_config(payload: ConfigPayload):&#10;    new_cfg = payload.config&#10;    # 기본적인 검증: 반드시 strategy_name과 market이 있어야 함&#10;    if not isinstance(new_cfg, dict) or 'strategy_name' not in new_cfg or 'market' not in new_cfg:&#10;        raise HTTPException(status_code=400, detail=&quot;Invalid config payload. 'strategy_name' and 'market' required.&quot;)&#10;&#10;    success = config.save_config(new_cfg)&#10;    if not success:&#10;        raise HTTPException(status_code=500, detail=&quot;Failed to save configuration&quot;)&#10;&#10;    # 저장 후 재로딩&#10;    config.reload_config()&#10;    return {&quot;status&quot;: &quot;saved&quot;}&#10;&#10;&#10;@app.post(&quot;/reload&quot;) # 설정 재로딩 엔드포인트&#10;def reload_config():&#10;    config.reload_config()&#10;    return {&quot;status&quot;: &quot;reloaded&quot;}&#10;&#10;&#10;# --- Screening endpoints ---&#10;# 변동성 상위 N개 티커 조회&#10;# market_prefix: 마켓 접두사 (기본값 &quot;KRW&quot;)&#10;# top_n: 상위 N개 (기본값 10)&#10;# timeframe: 변동성 계산에 사용할 시간대 (기본값 &quot;minute15&quot;)&#10;# 반환값: 변동성 상위 N개 티커 리스트&#10;# 변동성 계산은 (최고가 - 최저가) / 평균 종가 방식 사용&#10;# Upbit의 공용 kline 엔드포인트 사용&#10;# config.json의 'universe' 키에 티커 리스트가 없으면 기본 샘플 리스트 사용, 폴백 처리&#10;# 반환값: {&quot;top&quot;: [ {&quot;ticker&quot;: 티커명, &quot;volatility&quot;: 변동성}, ... ] }&#10;# 캐시 사용으로 중복 Upbit 호출 최소화&#10;# 캐시 TTL은 _KLINES_CACHE_TTL 사용&#10;# 예외 발생 시 해당 티커는 건너뜀&#10;@app.get(&quot;/screen/volatility_top&quot;) # 변동성 상위 티커 조회 엔드포인트&#10;def volatility_top(market_prefix: str = &quot;KRW&quot;, top_n: int = 10, timeframe: str = &quot;minute15&quot;):&#10;    cfg = config._config # 설정 읽기&#10;    universe = cfg.get('universe', []) # 유니버스 읽기&#10;    if not universe:&#10;        # 폴백: 기본 샘플 유니버스&#10;        universe = [f&quot;{market_prefix}-BTC&quot;, f&quot;{market_prefix}-ETH&quot;, f&quot;{market_prefix}-XRP&quot;, f&quot;{market_prefix}-ADA&quot;, f&quot;{market_prefix}-DOGE&quot;, f&quot;{market_prefix}-SOL&quot;, f&quot;{market_prefix}-DOT&quot;, f&quot;{market_prefix}-MATIC&quot;, f&quot;{market_prefix}-BCH&quot;, f&quot;{market_prefix}-LTC&quot;]&#10;&#10;    results = []&#10;    # Try to use internal cache to avoid hammering Upbit when checking multiple tickers&#10;    now = time.time()&#10;    for ticker in universe:&#10;        # 캐시 키 생성 (가장 최근 15캔들 기준)&#10;        key = f&quot;{ticker}|{timeframe}|15&quot;&#10;        # 캐시 조회&#10;        cached = _cache_get(key)&#10;        # 캐시 유효성 검사&#10;        if cached and (now - cached[0]) &lt; _KLINES_CACHE_TTL: # 캐시 유효 시&#10;            klines = cached[1] # 캐시된 값 사용&#10;        else:&#10;            try:&#10;                # Upbit에서 변동성 계산용 klines 조회 (rate-limited)&#10;                # 15캔들 기준 (폴백 200캔들 아님)&#10;                klines = _rate_limited_get_klines(ticker, timeframe, count=15)&#10;            except Exception as e:&#10;                log.warning(f'Rate-limited fetch failed for {ticker}: {e}')&#10;                klines = None&#10;            # 캐시 설정, None도 캐시하여 반복 실패 방지&#10;            _cache_set(key, klines, ttl=_KLINES_CACHE_TTL)&#10;        if not klines:&#10;            continue&#10;        highs = [float(k['high_price']) for k in klines]&#10;        lows = [float(k['low_price']) for k in klines]&#10;        closes = [float(k['trade_price']) for k in klines]&#10;        # 변동성 계산 : (최고가 - 최저가) / 평균 종가 방식&#10;        try:&#10;            vol = (max(highs) - min(lows)) / (sum(closes) / len(closes))&#10;        except Exception:&#10;            vol = 0&#10;        results.append({'ticker': ticker, 'volatility': vol})&#10;&#10;    # 변동성 기준 내림차순 정렬 후 상위 N개 반환&#10;    results_sorted = sorted(results, key=lambda x: x['volatility'], reverse=True)[:top_n]&#10;    return {&quot;top&quot;: results_sorted}&#10;&#10;&#10;# --- Background Event Watcher ---&#10;# 단순 폴링 기반 워처 구현&#10;# 워처는 별도 스레드에서 동작하며, 지정된 마켓의 klines를 주기적으로 조회&#10;# 지정된 조건에 부합하는 이벤트 발생 시 로그 출력&#10;# 조건은 JSON 배열로 전달되며, 각 조건은 다음과 같은 형태를 가짐&#10;# {&quot;type&quot;: &quot;volatility_breakout&quot;, &quot;k&quot;: 0.5} : 변동성 돌파 이벤트 (Larry Williams 스타일)&#10;# {&quot;type&quot;: &quot;volume_spike&quot;, &quot;multiplier&quot;: 3} : 거래량 급증 이벤트&#10;# 워처 시작 엔드포인트&#10;# 요청 본문 예시:&#10;# {&quot;market&quot;: &quot;KRW-BTC&quot;,&#10;# &quot;interval&quot;: 1,&#10;# &quot;callbacks&quot;:[&#10;#     {&quot;type&quot;:&quot;volatility_breakout&quot;, &quot;k&quot;:0.5},&#10;#     {&quot;type&quot;:&quot;volume_spike&quot;, &quot;multiplier&quot;:3}&#10;# ]}&#10;# 워처 중지 엔드포인트&#10;def _watcher_loop(stop_event, market: str, check_interval: float, callbacks: List[dict]):&#10;    &quot;&quot;&quot;Simple polling watcher that fetches latest klines and invokes callbacks when conditions met.&quot;&quot;&quot;&#10;    log.info(f&quot;Starting watcher loop for {market} (interval {check_interval}s)&quot;)&#10;    last_checked_time = None&#10;    while not stop_event.is_set():&#10;        try:&#10;            try:&#10;                # Upbit에서 최신 60캔들 조회 (rate-limited)&#10;                klines = _rate_limited_get_klines(market, 'minute1', count=60)&#10;            except Exception as e:&#10;                log.error(f'Watcher fetch rate-limited or failed for {market}: {e}')&#10;                klines = None&#10;&#10;            # 이벤트 체크&#10;            if klines:&#10;                # 최근 캔들&#10;                latest = klines[0]&#10;                # 변동성 체크용 15캔들 윈도우 준비&#10;                window = klines[:15]&#10;                highs = [float(k['high_price']) for k in window]&#10;                lows = [float(k['low_price']) for k in window]&#10;                volumes = [float(k['candle_acc_trade_volume']) for k in window]&#10;                closes = [float(k['trade_price']) for k in window]&#10;&#10;                # 변동성 돌파 체크 (간단화된 Larry Williams 스타일)&#10;                try:&#10;                    prev_close = closes[1]&#10;                    curr_close = closes[0]&#10;                    volatility_range = max(highs) - min(lows)&#10;                except Exception:&#10;                    prev_close = curr_close = volatility_range = None&#10;&#10;                # 콜백 조건 체크&#10;                if prev_close is not None and curr_close is not None: # 유효한 데이터 시&#10;                    # 각 콜백 조건별 체크&#10;                    for cb in callbacks:&#10;                        if cb.get('type') == 'volatility_breakout':&#10;                            k = cb.get('k', 0.5) # 기본 k=0.5&#10;                            # when current close &gt; prev_close + range * k&#10;                            if curr_close &gt; (prev_close + volatility_range * k):&#10;                                log.info(f&quot;Watcher detected volatility breakout on {market} (k={k})&quot;)&#10;                        elif cb.get('type') == 'volume_spike':&#10;                            multiplier = cb.get('multiplier', 3) # 기본 multiplier=3&#10;                            # 평균 거래량 대비 현재 거래량이 multiplier 배 이상인 경우&#10;                            avg_vol = sum(volumes[1:]) / (len(volumes)-1) if len(volumes) &gt; 1 else 0&#10;                            if avg_vol and volumes[0] &gt; avg_vol * multiplier: # 거래량 급증 감지&#10;                                log.info(f&quot;Watcher detected volume spike on {market} (x{multiplier})&quot;)&#10;&#10;            time.sleep(check_interval)&#10;        except Exception as e:&#10;            log.error(f&quot;Error in watcher loop: {e}&quot;)&#10;            time.sleep(check_interval)&#10;    log.info(&quot;Watcher loop stopped.&quot;)&#10;&#10;# 워처 시작 엔드포인트&#10;# 요청 본문 예시:&#10;# {&quot;market&quot;: &quot;KRW-BTC&quot;,&#10;# &quot;interval&quot;: 1,&#10;# &quot;callbacks&quot;:[&#10;#     {&quot;type&quot;:&quot;volatility_breakout&quot;, &quot;k&quot;:0.5},&#10;#     {&quot;type&quot;:&quot;volume_spike&quot;, &quot;multiplier&quot;:3}&#10;# ]}&#10;@app.post(&quot;/watcher/start&quot;) # 워처 시작 엔드포인트&#10;def start_watcher(payload: Dict[str, Any]):&#10;    if _watcher['running']:&#10;        raise HTTPException(status_code=400, detail=&quot;Watcher already running&quot;)&#10;&#10;    # 파라미터 추출&#10;    market = payload.get('market', config.MARKET)   # 마켓 (기본값 config.MARKET)&#10;    interval = float(payload.get('interval', 1.0))  # 체크 간격 (초)&#10;    callbacks = payload.get('callbacks', [])        # 콜백 조건 리스트&#10;&#10;    # 워처 스레드 시작&#10;    stop_event = threading.Event()&#10;    # 워처 루프 스레드 생성 및 시작&#10;    t = threading.Thread(target=_watcher_loop, args=(stop_event, market, interval, callbacks), daemon=True)&#10;    _watcher['running'] = True              # 워처 상태 갱신&#10;    _watcher['thread'] = t                  # 워처 스레드 저장&#10;    _watcher['stop_event'] = stop_event     # 중지 이벤트 저장&#10;    t.start()&#10;    return {&quot;status&quot;: &quot;started&quot;}&#10;&#10;# 워처 중지 엔드포인트&#10;# 워처 중지 이벤트 설정 및 스레드 종료 대기&#10;# 워처 상태 초기화&#10;# 반환값: {&quot;status&quot;: &quot;stopped&quot;} 또는 {&quot;status&quot;: &quot;not_running&quot;}&#10;@app.post(&quot;/watcher/stop&quot;)&#10;def stop_watcher():&#10;    if not _watcher['running']:&#10;        return {&quot;status&quot;: &quot;not_running&quot;}&#10;    _watcher['stop_event'].set()&#10;    _watcher['thread'].join(timeout=5)&#10;    _watcher['running'] = False&#10;    _watcher['thread'] = None&#10;    _watcher['stop_event'] = None&#10;    return {&quot;status&quot;: &quot;stopped&quot;}&#10;&#10;# 배치 klines 조회 엔드포인트&#10;# 티커/타임프레임/카운트 조합별로 캐시 키 생성 (인메모리 또는 Redis)&#10;# 요청 본문 예시:&#10;# {&quot;tickers&quot;: [&quot;KRW-BTC&quot;,&quot;KRW-ETH&quot;], &quot;timeframe&quot;:&quot;minute15&quot;, &quot;count&quot;:100}&#10;# 반환값 예시:&#10;# {&quot;klines&quot;: {&quot;KRW-BTC&quot;: [...], &quot;KRW-ETH&quot;: [...]} }&#10;# 각 티커별로 klines를 조회하여 결과 딕셔너리에 저장&#10;# 내부적으로 캐시를 사용하여 중복 Upbit 호출 최소화&#10;# 캐시 TTL은 _KLINES_CACHE_TTL 사용&#10;# 캐시 미스 시 rate-limited fetcher를 사용하여 Upbit에서 klines 조회&#10;# 예외 발생 시 해당 티커는 None으로 설정&#10;@app.post('/klines_batch')&#10;def klines_batch(payload: KlinesBatchRequest):&#10;    req = payload.model_dump()&#10;    tickers = req.get('tickers', []) or []&#10;    timeframe = req.get('timeframe', 'minute15')&#10;    count = int(req.get('count', 100))&#10;&#10;    result = {}&#10;    now = time.time()&#10;    for ticker in tickers:&#10;        key = f&quot;{ticker}|{timeframe}|{count}&quot; # 캐시 키 생성&#10;        cached = _cache_get(key)&#10;        # 캐시 유효성 검사&#10;        # 캐시 유효 시 캐시된 값 사용&#10;        if cached and (now - cached[0]) &lt; _KLINES_CACHE_TTL:&#10;            result[ticker] = cached[1]&#10;            continue&#10;&#10;        # 카운트 이상인 캐시 항목 검색 시도 (인메모리 및 Redis 모두 지원)&#10;        # 가장 큰 count를 가진 항목 선택&#10;        # 캐시 미스 시 rate-limited fetcher 사용&#10;        klines = None&#10;        try:&#10;            # 가능한 경우 Redis에서 검색&#10;            if _redis_client:&#10;                try:&#10;                    pattern = f&quot;{ticker}|{timeframe}|*&quot;&#10;                    # 패턴 매칭 키 조회&#10;                    keys = _redis_client.keys(pattern)&#10;                    # 후보 탐색 및 선택 (요청보다 가장 큰 count)&#10;                    best = None&#10;                    best_cnt = 0&#10;                    for k in keys:&#10;                        try:&#10;                            # 키 파싱 [ticker, timeframe, count]&#10;                            parts = k.split('|')&#10;&#10;                            # 유효한 키 형식 시 (3개 이상 파트로 구성)&#10;                            if len(parts) &gt;= 3:&#10;                                # count 부분 (마지막 부분)&#10;                                kcnt = int(parts[-1])&#10;                                # 요청한 카운트보다 크고 현재 최상위 후보보다 큰 경우&#10;                                if kcnt &gt;= count and kcnt &gt; best_cnt:&#10;                                    best = k        # 후보 키 갱신&#10;                                    best_cnt = kcnt # 후보 카운트 갱신&#10;                        except Exception:&#10;                            continue&#10;                    # 후보 키가 발견된 경우&#10;                    if best:&#10;                        # 후보 키로 캐시 조회&#10;                        cached2 = _cache_get(best, ttl=_KLINES_CACHE_TTL)&#10;                        # 후보 캐시에서 klines 추출&#10;                        if cached2:&#10;                            klines_full = cached2[1]&#10;                            # 유효한 klines 시&#10;                            if isinstance(klines_full, list) and len(klines_full) &gt; 0:&#10;                                # 요청한 개수만큼 슬라이싱하여 반환&#10;                                klines = klines_full[-count:]&#10;                except Exception:&#10;                    pass&#10;            else:&#10;                # 인-메모리 캐시에서 후보 탐색&#10;                try:&#10;                    candidates = []&#10;                    # 인-메모리 캐시 순회&#10;                    for k, v in list(_klines_cache.items()):&#10;                        try:&#10;                            # 키 파싱 [ticker, timeframe, count]&#10;                            parts = k.split('|')&#10;                            # 유효한 키 형식 시 (3개 이상 파트로 구성)&#10;                            if parts[0] == ticker and parts[1] == timeframe:&#10;                                kcnt = int(parts[2])            # count 부분&#10;                                candidates.append((kcnt, v))    # 후보 리스트에 추가&#10;                        except Exception:&#10;                            continue&#10;                    # 후보 정렬 및 선택 (요청보다 큰 count)&#10;                    candidates = sorted(candidates, key=lambda x: x[0], reverse=True) # 내림차순 정렬&#10;                    for kcnt, v in candidates:&#10;                        if kcnt &gt;= count:&#10;                            klines_full = v[1]&#10;                            # 유효한 klines 시&#10;                            if isinstance(klines_full, list) and len(klines_full) &gt; 0:&#10;                                # 요청한 개수만큼 슬라이싱하여 반환&#10;                                klines = klines_full[-count:]&#10;                                break&#10;                except Exception:&#10;                    pass&#10;&#10;            # 캐시에서 발견되지 않은 경우 rate-limited fetcher 사용&#10;            if klines is None:&#10;                try:&#10;                    klines = _rate_limited_get_klines(ticker, timeframe, count=count)&#10;                except Exception as e:&#10;                    log.warning(f'Rate-limited batch fetch failed for {ticker}: {e}')&#10;                    klines = None&#10;        except Exception as e:&#10;            log.warning(f'klines_batch lookup error for {ticker}: {e}')&#10;            klines = None&#10;&#10;        # 캐시 설정 (실패 시에도 캐시하여 반복 실패 방지)&#10;        _cache_set(key, klines, ttl=_KLINES_CACHE_TTL)&#10;        result[ticker] = klines&#10;&#10;    return {'klines': result}&#10;&#10;# --- Private API Endpoints ---&#10;# 잔고 조회 엔드포인트&#10;# Upbit 개인 API 키를 사용하여 잔고 조회&#10;# 키가 구성되지 않은 경우 503 반환&#10;# 이 엔드포인트는 짧은 TTL(_BALANCES_CACHE_TTL)로 잔고를 캐시하여 반복된 Upbit 호출을 줄임&#10;# 반환값에는 추가 진단 필드 포함:&#10;#   - balances: Upbit에서 반환된 원시 잔고 리스트&#10;#   - reported_krw_balance: 잔고에서 보고된 KRW 잔고 (없으면 0)&#10;#   - cached: 응답이 서버 캐시에서 왔는지 여부&#10;#   - cached_ts: 캐시된 시점 타임스탬프&#10;@app.get('/balances')&#10;def get_balances():&#10;    # 잔고 조회 엔드포인트&#10;    if _upbit_private is None:&#10;        raise HTTPException(status_code=503, detail='Upbit API keys not configured on server; balances unavailable')&#10;&#10;    cache_key = 'upbit:balances:all'&#10;    now = time.time()&#10;&#10;    # 캐시 조회 시도&#10;    cached = _cache_get(cache_key, ttl=_BALANCES_CACHE_TTL)&#10;    if cached and (now - cached[0]) &lt; _BALANCES_CACHE_TTL:&#10;        bl = cached[1]&#10;        cached_flag = True&#10;        cached_ts = cached[0]&#10;        log.debug('Balances: cache hit')&#10;    else:&#10;        cached_flag = False&#10;        cached_ts = None&#10;        try:&#10;            bl = _upbit_private.get_balances()&#10;        except Exception as e:&#10;            log.error(f'Balances retrieval failed: {e}')&#10;            # 캐시가 존재하면 캐시된 값 반환 (최선의 노력)&#10;            if cached:&#10;                bl = cached[1]&#10;                cached_flag = True&#10;                cached_ts = cached[0]&#10;            else:&#10;                raise HTTPException(status_code=502, detail=f'Upbit API call failed: {e}')&#10;        # 캐시 설정 (실패 시에도 캐시하여 반복 실패 방지)&#10;        _cache_set(cache_key, bl, ttl=_BALANCES_CACHE_TTL)&#10;&#10;    # KRW 잔고 계산 (반환된 잔고에서)&#10;    # 'currency' 또는 'unit' 필드 사용&#10;    reported_krw = 0.0&#10;    try:&#10;        if isinstance(bl, list):&#10;            for item in bl:&#10;                # 업비트API /v1/accounts는 'currency'와 'balance' 필드를 가진 항목 반환&#10;                try:&#10;                    cur = str(item.get('currency') or item.get('unit') or '').upper()&#10;                    bal = float(item.get('balance') or 0.0)&#10;                except Exception:&#10;                    continue&#10;                if cur == 'KRW' or cur.startswith('KRW'):&#10;                    reported_krw += bal&#10;        elif isinstance(bl, dict):&#10;            # 딕셔너리 형태인 경우 'balances' 키에서 리스트 추출&#10;            lst = bl.get('balances') if 'balances' in bl else None&#10;            if isinstance(lst, list):&#10;                for item in lst:&#10;                    try:&#10;                        cur = str(item.get('currency') or item.get('unit') or '').upper()&#10;                        bal = float(item.get('balance') or 0.0)&#10;                    except Exception:&#10;                        continue&#10;                    if cur == 'KRW' or cur.startswith('KRW'):&#10;                        reported_krw += bal&#10;    except Exception:&#10;        reported_krw = 0.0&#10;&#10;    return {&#10;        'balances': bl,&#10;        'reported_krw_balance': reported_krw,&#10;        'cached': bool(cached_flag),&#10;        'cached_ts': cached_ts,&#10;    }&#10;&#10;# 포지션 조회 엔드포인트&#10;# Upbit 개인 API 키를 사용하여 잔고 조회 후 현재 가격과 결합하여 포지션 계산&#10;# 키가 구성되지 않은 경우 503 반환&#10;# 각 자산별 포지션 정보와 요약 총계 반환&#10;# 포지션 정보에는 다음 필드 포함:&#10;#   - symbol: 마켓 심볼 (예: KRW-BTC)&#10;#   - side: 포지션 방향 (항상 'LONG'으로 설정)&#10;#   - size: 보유 수량&#10;#   - entry_price: 평균 매수가 (없으면 null)&#10;#   - current_price: 현재 가격&#10;#   - unrealized_pnl: 미실현 손익 (없으면 null)&#10;#   - unrealized_pnl_rate: 미실현 손익률 (없으면 null)&#10;#   - notional_krw: 원화 기준 명목 가치&#10;# 요약 정보에는 다음 필드 포함:&#10;#   - total_equity_krw: 총 자산 가치 (원화 기준)&#10;#   - available_krw: 사용 가능한 원화 잔고&#10;#   - prices_fetched: 현재 가격을 성공적으로 조회한 자산 수&#10;#   - excluded_assets: 현재 가격을 조회하지 못해 제외된 자산 목록 (심볼 및 사유 포함)&#10;# 포지션 스냅샷은 히스토리 스토어에 기록됨&#10;# 반환값 예시:&#10;# {&#10;#   &quot;positions&quot;: [ {...}, {...}, ... ],&#10;#   &quot;total_equity_krw&quot;: 12345678.9,&#10;#   &quot;available_krw&quot;: 2345678.9,&#10;#   &quot;prices_fetched&quot;: 5,&#10;#   &quot;excluded_assets&quot;: [ {&quot;symbol&quot;: &quot;KRW-XYZ&quot;, &quot;reason&quot;: &quot;no_price&quot;}, ... ]&#10;# }&#10;@app.get(&quot;/positions&quot;)&#10;def get_positions():&#10;    if _upbit_private is None:&#10;        raise HTTPException(status_code=503, detail='Upbit API keys not configured on server; positions unavailable')&#10;&#10;    try:&#10;        bl = _upbit_private.get_balances() or []&#10;    except Exception as e:&#10;        log.error(f'Failed to retrieve balances for positions endpoint: {e}')&#10;        raise HTTPException(status_code=502, detail=f'Failed to retrieve balances: {e}')&#10;&#10;    positions = []&#10;    total_equity = 0.0&#10;    available_krw = 0.0&#10;&#10;    #시장리스트 작성 및 통화맵 작성 (가격 조회용)&#10;    markets = []&#10;    currency_map = {}&#10;    try:&#10;        for item in bl:&#10;            cur = str(item.get('currency') or item.get('unit') or '').upper()&#10;            bal = float(item.get('balance') or 0) if item is not None else 0.0&#10;            locked = float(item.get('locked') or 0) if item is not None else 0.0&#10;&#10;            # 원화 현금잔고 처리&#10;            if cur == 'KRW' or cur.startswith('KRW'):&#10;                available_krw += bal&#10;                total_equity += bal&#10;                continue&#10;            size = bal + locked&#10;            if size &lt;= 0:&#10;                continue&#10;            market = f'KRW-{cur}'&#10;            markets.append(market)&#10;            currency_map[market] = {&#10;                'currency': cur,&#10;                'size': size,&#10;                'avg_buy_price': float(item.get('avg_buy_price') or 0)&#10;            }&#10;    except Exception as e:&#10;        log.warning(f'Error while parsing balances for positions: {e}')&#10;&#10;    # 현재가격 조회 (1개 캔들 minute1, count=1) (조회수 제한 주의)&#10;    price_map = {}&#10;    for m in set(markets):&#10;        try:&#10;            kl = None&#10;            try:&#10;                kl = _rate_limited_get_klines(m, 'minute1', count=1)&#10;            except Exception as e:&#10;                log.warning(f'Price fetch failed for {m}: {e}')&#10;                kl = None&#10;            price = None&#10;            if kl and isinstance(kl, list) and len(kl) &gt; 0:&#10;                try:&#10;                    first = kl[0]&#10;                    price_candidate = None&#10;&#10;                    # 딕셔너리 레코드 작업&#10;                    # (Upbit API는 'trade_price' 사용)&#10;                    if isinstance(first, dict):&#10;                        price_candidate = first.get('trade_price') or first.get('close')&#10;                    else:&#10;                        # 속성 접근 시도 (일부 래퍼는 .close 또는 .trade_price 노출 가능)&#10;                        price_candidate = getattr(first, 'trade_price', None) or getattr(first, 'close', None)&#10;                    if price_candidate is None:&#10;                        price = None&#10;                    else:&#10;                        price = float(price_candidate)&#10;                except Exception:&#10;                    price = None&#10;            price_map[m] = price&#10;        except Exception as e:&#10;             log.warning(f'Unexpected error fetching price for {m}: {e}')&#10;             price_map[m] = None&#10;&#10;    # 포지션 구성 및 미실현 손익/명목 가치 계산&#10;    excluded_assets = []&#10;    for market, meta in currency_map.items():&#10;        cur = meta['currency']&#10;        size = float(meta['size'])&#10;        avg_price = float(meta.get('avg_buy_price') or 0.0)&#10;        current_price = price_map.get(market)&#10;&#10;        # 자산 현재 가격이 없으면 건너뛰고 보고&#10;        if current_price is None:&#10;            excluded_assets.append({'symbol': market, 'reason': 'no_price'})&#10;            continue&#10;&#10;        notional = size * float(current_price)&#10;        total_equity += notional&#10;        unrealized = None&#10;        unrealized_rate = None&#10;        if avg_price and avg_price &gt; 0:&#10;            unrealized = (float(current_price) - avg_price) * size&#10;            unrealized_rate = (float(current_price) - avg_price) / avg_price * 100&#10;&#10;        pos = {&#10;            'symbol': market,&#10;            'side': 'LONG',&#10;            'size': size,&#10;            'entry_price': avg_price if avg_price &gt; 0 else None,&#10;            'current_price': current_price,&#10;            'unrealized_pnl': unrealized,&#10;            'unrealized_pnl_rate': unrealized_rate,&#10;            'notional_krw': notional,&#10;        }&#10;        positions.append(pos)&#10;&#10;    # Also include list of excluded assets so UI can show a friendly message.&#10;    result = {&#10;        'positions': positions,&#10;        'total_equity_krw': total_equity,&#10;        'available_krw': available_krw,&#10;        'prices_fetched': len([p for p in price_map.values() if p is not None]),&#10;        'excluded_assets': excluded_assets,&#10;    }&#10;    history_store.record_snapshot({&#10;        'ts': time.time(),&#10;        'total_equity': total_equity,&#10;        'available_krw': available_krw,&#10;        'positions': [&#10;            {&#10;                'symbol': pos['symbol'],&#10;                'notional_krw': pos['notional_krw'],&#10;                'unrealized_pnl': pos['unrealized_pnl'],&#10;            }&#10;            for pos in positions&#10;        ],&#10;    })&#10;    return result&#10;&#10;&#10;@app.get('/positions/history')&#10;def get_positions_history(limit: int = 365, days: int = 365):&#10;    since = time.time() - float(days) * 86400&#10;    history = history_store.get_history(since=since, limit=limit)&#10;    return {'history': history}&#10;&#10;@app.post('/ws/start')&#10;def ws_start():&#10;    try:&#10;        start_ws_listener()&#10;        start_ticker_listener()&#10;        return {'status': 'started'}&#10;    except Exception as exc:&#10;        raise HTTPException(status_code=500, detail=f'Failed to start websocket listener: {exc}')&#10;&#10;@app.post('/ws/stop')&#10;def ws_stop():&#10;    try:&#10;        stop_ws_listener()&#10;        stop_ticker_listener()&#10;        return {'status': 'stopped'}&#10;    except Exception as exc:&#10;        raise HTTPException(status_code=500, detail=f'Failed to stop websocket listener: {exc}')&#10;&#10;@app.get('/ws/status')&#10;def ws_status():&#10;    running = bool(_ws_listener and _ws_listener._thread and _ws_listener._thread.is_alive())&#10;    return {'running': running, 'targets': _ws_listener.targets if _ws_listener else []}&#10;&#10;@app.get('/ws/stats')&#10;def ws_stats(last_hour_sec: int = 3600, recent_limit: int = 10):&#10;    raw_stats = load_ws_stats()&#10;    summary = summarize_ws_stats(raw_stats, last_hour_secs=last_hour_sec, recent_limit=recent_limit)&#10;    summary.update({&#10;        'running': bool(_ws_listener and _ws_listener._thread and _ws_listener._thread.is_alive()),&#10;        'targets': _ws_listener.targets if _ws_listener else [],&#10;    })&#10;    return summary&#10;&#10;@app.get('/ws/executions')&#10;def ws_executions(limit: int = 0):&#10;    try:&#10;        entries = read_exec_history(limit=limit)&#10;    except Exception as exc:&#10;        raise HTTPException(status_code=500, detail=f'Failed to load exec history: {exc}')&#10;    return {'executions': entries}&#10;&#10;@app.get('/ws/trades')&#10;def ws_trades(symbol: str, limit: int = 20):&#10;    if _redis_client is None:&#10;        raise HTTPException(status_code=503, detail='Redis cache unavailable; cannot read trades.')&#10;    if not symbol:&#10;        raise HTTPException(status_code=400, detail='symbol query parameter is required.')&#10;    max_limit = min(max(limit, 1), 200)&#10;    key = f'ws:trades:{symbol}'&#10;    raw = _redis_client.lrange(key, 0, max_limit - 1)&#10;    trades = []&#10;    try:&#10;        for item in raw:&#10;            import json as _json&#10;            trades.append(_json.loads(item))&#10;    except Exception:&#10;        trades = []&#10;    return {'symbol': symbol, 'trades': trades}&#10;&#10;&#10;def _ws_ticker_targets() -&gt; List[str]:&#10;    if _ws_listener:&#10;        return _ws_listener.targets&#10;    universe = config._config.get('universe')&#10;    if isinstance(universe, list) and universe:&#10;        return universe&#10;    return [&#10;        'KRW-BTC',&#10;        'KRW-ETH',&#10;        'KRW-ADA',&#10;        'KRW-XRP',&#10;        'KRW-SOL',&#10;    ]&#10;&#10;&#10;@app.get('/ws/ticker_data')&#10;def ws_ticker_data():&#10;    if _redis_client is None:&#10;        raise HTTPException(status_code=503, detail='Redis cache unavailable; cannot read ticker data.')&#10;    targets = _ws_ticker_targets()&#10;    payloads: List[Dict[str, Any]] = []&#10;    for symbol in targets:&#10;        key = f'ws:ticker:{symbol}'&#10;        raw = _redis_client.get(key)&#10;        if not raw:&#10;            continue&#10;        try:&#10;            data = json.loads(raw)&#10;        except Exception:&#10;            continue&#10;        payloads.append({&#10;            'symbol': symbol,&#10;            'opening_price': data.get('opening_price'),&#10;            'high_price': data.get('high_price'),&#10;            'low_price': data.get('low_price'),&#10;            'trade_price': data.get('trade_price') or data.get('trade_price'),&#10;            'prev_closing_price': data.get('prev_closing_price'),&#10;            'change': data.get('change'),&#10;            'timestamp': data.get('trade_timestamp') or data.get('timestamp'),&#10;        })&#10;    return {'tickers': payloads}" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/server/config.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/server/config.py" />
              <option name="originalContent" value="import os&#10;import json&#10;from dotenv import load_dotenv&#10;from typing import Dict, Any&#10;from server.logger import log&#10;&#10;# --- 1. .env 파일에서 민감 정보 로드 ---&#10;# server 디렉토리 기준으로 .env 파일 경로 설정&#10;dotenv_path = os.path.join(os.path.dirname(__file__), '.env')&#10;if os.path.exists(dotenv_path):&#10;    load_dotenv(dotenv_path)&#10;    log.info(&quot;.env file loaded successfully.&quot;)&#10;else:&#10;    log.warning(&quot;server/.env file not found. Please create one with your API keys.&quot;)&#10;&#10;# 환경 변수에서 API 키 가져오기 (따옴표/공백 제거)&#10;def _read_env(key: str) -&gt; str | None:&#10;    val = os.getenv(key)&#10;    if val is None:&#10;        return None&#10;    val = val.strip()&#10;    if (val.startswith('&quot;') and val.endswith('&quot;')) or (val.startswith(&quot;'&quot;) and val.endswith(&quot;'&quot;)):&#10;        val = val[1:-1]&#10;    return val or None&#10;&#10;UPBIT_ACCESS_KEY = _read_env(&quot;UPBIT_ACCESS_KEY&quot;)&#10;UPBIT_SECRET_KEY = _read_env(&quot;UPBIT_SECRET_KEY&quot;)&#10;OPENAI_API_KEY = _read_env(&quot;OPENAI_API_KEY&quot;)&#10;GEMINI_API_KEY = _read_env(&quot;GEMINI_API_KEY&quot;)&#10;&#10;# --- 2. runtime/config.json 파일에서 설정 파라미터 로드 ---&#10;def _get_runtime_config_path():&#10;    project_root = os.path.dirname(os.path.dirname(__file__))&#10;    return os.path.join(project_root, 'runtime', 'config.json')&#10;&#10;&#10;def load_config() -&gt; Dict[str, Any]:&#10;    &quot;&quot;&quot;config.json 파일에서 설정을 로드하여 반환합니다.&quot;&quot;&quot;&#10;    config_path = _get_runtime_config_path()&#10;    try:&#10;        with open(config_path, 'r', encoding='utf-8') as f:&#10;            config_data = json.load(f)&#10;        log.info(&quot;runtime/config.json file loaded successfully.&quot;)&#10;        return config_data&#10;    except FileNotFoundError:&#10;        log.error(&quot;runtime/config.json not found! Please create a configuration file in runtime directory.&quot;)&#10;        return {}&#10;    except json.JSONDecodeError:&#10;        log.error(&quot;Error decoding runtime/config.json. Please check for syntax errors.&quot;)&#10;        return {}&#10;&#10;&#10;def save_config(new_config: Dict[str, Any]) -&gt; bool:&#10;    &quot;&quot;&quot;config.json 파일에 설정을 저장합니다. 안전을 위해 기존 파일을 백업합니다.&#10;&#10;    :param new_config: 저장할 설정 딕셔너리&#10;    :return: 저장 성공 여부&#10;    &quot;&quot;&quot;&#10;    config_path = _get_runtime_config_path()&#10;    backup_path = config_path + '.bak'&#10;    try:&#10;        # 기존 파일 백업&#10;        if os.path.exists(config_path):&#10;            os.replace(config_path, backup_path)&#10;            log.info(f&quot;Existing config.json backed up to {backup_path}&quot;)&#10;&#10;        with open(config_path, 'w', encoding='utf-8') as f:&#10;            json.dump(new_config, f, ensure_ascii=False, indent=2)&#10;        log.info(&quot;New configuration saved to runtime/config.json&quot;)&#10;        return True&#10;    except Exception as e:&#10;        log.error(f&quot;Failed to save runtime/config.json: {e}&quot;)&#10;        # 백업 복원 시도&#10;        if os.path.exists(backup_path):&#10;            os.replace(backup_path, config_path)&#10;            log.info(&quot;Restored original config.json from backup due to failure.&quot;)&#10;        return False&#10;&#10;&#10;# 즉시 로드하여 전역 설정 변수로 노출&#10;_config = load_config()&#10;&#10;&#10;def _sync_globals_from_config(cfg: Dict[str, Any]):&#10;    &quot;&quot;&quot;로드된 `_config` 딕셔너리의 값을 모듈 전역 변수로 동기화합니다.&#10;    이 함수는 `reload_config()` 호출 시 기존 전역 변수들이 최신 값으로 갱신되도록 보장합니다.&#10;    &quot;&quot;&quot;&#10;    global STRATEGY_NAME, MARKET, TIMEFRAME, CANDLE_COUNT, LOOP_INTERVAL_SEC&#10;    global MIN_ORDER_AMOUNT, TRADE_AMOUNT_KRW&#10;    global USE_KELLY_CRITERION, KELLY_WIN_RATE, KELLY_PAYOFF_RATIO, KELLY_FRACTION&#10;    global RSI_PERIOD, RSI_OVERSOLD, RSI_OVERBOUGHT&#10;    global VB_K_VALUE, DM_WINDOW&#10;    global ENSEMBLE_STRATEGY, OPENAI_MODEL, GEMINI_MODEL&#10;&#10;    STRATEGY_NAME = cfg.get(&quot;strategy_name&quot;, &quot;RSI&quot;)&#10;    MARKET = cfg.get(&quot;market&quot;, &quot;KRW-BTC&quot;)&#10;    TIMEFRAME = cfg.get(&quot;timeframe&quot;, &quot;minute5&quot;)&#10;    CANDLE_COUNT = cfg.get(&quot;candle_count&quot;, 200)&#10;    LOOP_INTERVAL_SEC = cfg.get(&quot;loop_interval_sec&quot;, 5)&#10;&#10;    _order_settings = cfg.get(&quot;order_settings&quot;, {})&#10;    MIN_ORDER_AMOUNT = _order_settings.get(&quot;min_order_amount&quot;, 5500)&#10;    TRADE_AMOUNT_KRW = _order_settings.get(&quot;trade_amount_krw&quot;, 6000)&#10;&#10;    USE_KELLY_CRITERION = cfg.get(&quot;use_kelly_criterion&quot;, False)&#10;    _kelly_settings = cfg.get(&quot;kelly_criterion&quot;, {})&#10;    KELLY_WIN_RATE = _kelly_settings.get(&quot;win_rate&quot;, 0.5)&#10;    KELLY_PAYOFF_RATIO = _kelly_settings.get(&quot;payoff_ratio&quot;, 1.0)&#10;    KELLY_FRACTION = _kelly_settings.get(&quot;fraction&quot;, 0.5)&#10;&#10;    _strategy_params = cfg.get(&quot;strategy_params&quot;, {})&#10;    _rsi_params = _strategy_params.get(&quot;RSI&quot;, {})&#10;    RSI_PERIOD = _rsi_params.get(&quot;period&quot;, 14)&#10;    RSI_OVERSOLD = _rsi_params.get(&quot;oversold&quot;, 30)&#10;    RSI_OVERBOUGHT = _rsi_params.get(&quot;overbought&quot;, 70)&#10;&#10;    _vb_params = _strategy_params.get(&quot;VolatilityBreakout&quot;, {})&#10;    VB_K_VALUE = _vb_params.get(&quot;k_value&quot;, 0.5)&#10;&#10;    _dm_params = _strategy_params.get(&quot;DualMomentum&quot;, {})&#10;    DM_WINDOW = _dm_params.get(&quot;window&quot;, 12)&#10;&#10;    _ai_ensemble_settings = cfg.get(&quot;ai_ensemble&quot;, {})&#10;    ENSEMBLE_STRATEGY = _ai_ensemble_settings.get(&quot;strategy&quot;, &quot;UNANIMOUS&quot;)&#10;    OPENAI_MODEL = _ai_ensemble_settings.get(&quot;openai_model&quot;, &quot;gpt-5.1-nano&quot;)&#10;    GEMINI_MODEL = _ai_ensemble_settings.get(&quot;gemini_model&quot;, &quot;gemini-2.5-flash&quot;)&#10;&#10;&#10;# 초기 로드 이후 전역 변수 동기화&#10;_sync_globals_from_config(_config)&#10;&#10;# expose some convenience getters&#10;def get_setting(key: str, default=None):&#10;    value = _config.get(key, default)&#10;    if value is None:&#10;        value = os.environ.get(key, default)&#10;    return value&#10;&#10;&#10;def reload_config():&#10;    global _config&#10;    _config = load_config()&#10;    # 로드된 config로 전역 변수 동기화&#10;    _sync_globals_from_config(_config)&#10;    log.info(&quot;Configuration reloaded.&quot;)&#10;    return _config&#10;&#10;&#10;# --- 기존 전역 변수화 (하위 모듈 호환성 유지) ---&#10;STRATEGY_NAME = _config.get(&quot;strategy_name&quot;, &quot;RSI&quot;)&#10;MARKET = _config.get(&quot;market&quot;, &quot;KRW-BTC&quot;)&#10;TIMEFRAME = _config.get(&quot;timeframe&quot;, &quot;minute5&quot;)&#10;CANDLE_COUNT = _config.get(&quot;candle_count&quot;, 200)&#10;LOOP_INTERVAL_SEC = _config.get(&quot;loop_interval_sec&quot;, 5)&#10;&#10;_order_settings = _config.get(&quot;order_settings&quot;, {})&#10;MIN_ORDER_AMOUNT = _order_settings.get(&quot;min_order_amount&quot;, 5500)&#10;TRADE_AMOUNT_KRW = _order_settings.get(&quot;trade_amount_krw&quot;, 6000)&#10;&#10;USE_KELLY_CRITERION = _config.get(&quot;use_kelly_criterion&quot;, False)&#10;_kelly_settings = _config.get(&quot;kelly_criterion&quot;, {})&#10;KELLY_WIN_RATE = _kelly_settings.get(&quot;win_rate&quot;, 0.5)&#10;KELLY_PAYOFF_RATIO = _kelly_settings.get(&quot;payoff_ratio&quot;, 1.0)&#10;KELLY_FRACTION = _kelly_settings.get(&quot;fraction&quot;, 0.5)&#10;&#10;_strategy_params = _config.get(&quot;strategy_params&quot;, {})&#10;_rsi_params = _strategy_params.get(&quot;RSI&quot;, {})&#10;RSI_PERIOD = _rsi_params.get(&quot;period&quot;, 14)&#10;RSI_OVERSOLD = _rsi_params.get(&quot;oversold&quot;, 30)&#10;RSI_OVERBOUGHT = _rsi_params.get(&quot;overbought&quot;, 70)&#10;&#10;_vb_params = _strategy_params.get(&quot;VolatilityBreakout&quot;, {})&#10;VB_K_VALUE = _vb_params.get(&quot;k_value&quot;, 0.5)&#10;&#10;_dm_params = _strategy_params.get(&quot;DualMomentum&quot;, {})&#10;DM_WINDOW = _dm_params.get(&quot;window&quot;, 12)&#10;&#10;_ai_ensemble_settings = _config.get(&quot;ai_ensemble&quot;, {})&#10;ENSEMBLE_STRATEGY = _ai_ensemble_settings.get(&quot;strategy&quot;, &quot;UNANIMOUS&quot;)&#10;OPENAI_MODEL = _ai_ensemble_settings.get(&quot;openai_model&quot;, &quot;gpt-5.1-nano&quot;)&#10;GEMINI_MODEL = _ai_ensemble_settings.get(&quot;gemini_model&quot;, &quot;gemini-2.5-flash&quot;)&#10;&#10;log.info(f&quot;Configuration loaded: Strategy='{STRATEGY_NAME}', Market='{MARKET}'&quot;)&#10;" />
              <option name="updatedContent" value="import os&#10;import json&#10;from dotenv import load_dotenv&#10;from typing import Dict, Any&#10;from server.logger import log&#10;&#10;# --- 1. .env 파일에서 민감 정보 로드 ---&#10;# server 디렉토리 기준으로 .env 파일 경로 설정&#10;dotenv_path = os.path.join(os.path.dirname(__file__), '.env')&#10;if os.path.exists(dotenv_path):&#10;    load_dotenv(dotenv_path)&#10;    log.info(&quot;.env file loaded successfully.&quot;)&#10;else:&#10;    log.warning(&quot;server/.env file not found. Please create one with your API keys.&quot;)&#10;&#10;# 환경 변수에서 API 키 가져오기 (따옴표/공백 제거)&#10;def _read_env(key: str) -&gt; str | None:&#10;    val = os.getenv(key)&#10;    if val is None:&#10;        return None&#10;    val = val.strip()&#10;    if (val.startswith('&quot;') and val.endswith('&quot;')) or (val.startswith(&quot;'&quot;) and val.endswith(&quot;'&quot;)):&#10;        val = val[1:-1]&#10;    return val or None&#10;&#10;UPBIT_ACCESS_KEY = _read_env(&quot;UPBIT_ACCESS_KEY&quot;)&#10;UPBIT_SECRET_KEY = _read_env(&quot;UPBIT_SECRET_KEY&quot;)&#10;OPENAI_API_KEY = _read_env(&quot;OPENAI_API_KEY&quot;)&#10;GEMINI_API_KEY = _read_env(&quot;GEMINI_API_KEY&quot;)&#10;&#10;# --- 2. runtime/config.json 파일에서 설정 파라미터 로드 ---&#10;def _get_runtime_config_path():&#10;    project_root = os.path.dirname(os.path.dirname(__file__))&#10;    return os.path.join(project_root, 'runtime', 'config.json')&#10;&#10;&#10;def load_config() -&gt; Dict[str, Any]:&#10;    &quot;&quot;&quot;config.json 파일에서 설정을 로드하여 반환합니다.&quot;&quot;&quot;&#10;    config_path = _get_runtime_config_path()&#10;    try:&#10;        with open(config_path, 'r', encoding='utf-8') as f:&#10;            config_data = json.load(f)&#10;        log.info(&quot;runtime/config.json file loaded successfully.&quot;)&#10;        return config_data&#10;    except FileNotFoundError:&#10;        log.error(&quot;runtime/config.json not found! Please create a configuration file in runtime directory.&quot;)&#10;        return {}&#10;    except json.JSONDecodeError:&#10;        log.error(&quot;Error decoding runtime/config.json. Please check for syntax errors.&quot;)&#10;        return {}&#10;&#10;&#10;def save_config(new_config: Dict[str, Any]) -&gt; bool:&#10;    &quot;&quot;&quot;config.json 파일에 설정을 저장합니다. 안전을 위해 기존 파일을 백업합니다.&#10;&#10;    :param new_config: 저장할 설정 딕셔너리&#10;    :return: 저장 성공 여부&#10;    &quot;&quot;&quot;&#10;    config_path = _get_runtime_config_path()&#10;    backup_path = config_path + '.bak'&#10;    try:&#10;        # 기존 파일 백업&#10;        if os.path.exists(config_path):&#10;            os.replace(config_path, backup_path)&#10;            log.info(f&quot;Existing config.json backed up to {backup_path}&quot;)&#10;&#10;        with open(config_path, 'w', encoding='utf-8') as f:&#10;            json.dump(new_config, f, ensure_ascii=False, indent=2)&#10;        log.info(&quot;New configuration saved to runtime/config.json&quot;)&#10;        return True&#10;    except Exception as e:&#10;        log.error(f&quot;Failed to save runtime/config.json: {e}&quot;)&#10;        # 백업 복원 시도&#10;        if os.path.exists(backup_path):&#10;            os.replace(backup_path, config_path)&#10;            log.info(&quot;Restored original config.json from backup due to failure.&quot;)&#10;        return False&#10;&#10;&#10;# 즉시 로드하여 전역 설정 변수로 노출&#10;_config = load_config()&#10;&#10;&#10;def _sync_globals_from_config(cfg: Dict[str, Any]):&#10;    &quot;&quot;&quot;로드된 `_config` 딕셔너리의 값을 모듈 전역 변수로 동기화합니다.&#10;    이 함수는 `reload_config()` 호출 시 기존 전역 변수들이 최신 값으로 갱신되도록 보장합니다.&#10;    &quot;&quot;&quot;&#10;    global STRATEGY_NAME, MARKET, TIMEFRAME, CANDLE_COUNT, LOOP_INTERVAL_SEC&#10;    global MIN_ORDER_AMOUNT, TRADE_AMOUNT_KRW&#10;    global USE_KELLY_CRITERION, KELLY_WIN_RATE, KELLY_PAYOFF_RATIO, KELLY_FRACTION&#10;    global RSI_PERIOD, RSI_OVERSOLD, RSI_OVERBOUGHT&#10;    global VB_K_VALUE, DM_WINDOW&#10;    global ENSEMBLE_STRATEGY, OPENAI_MODEL, GEMINI_MODEL&#10;&#10;    STRATEGY_NAME = cfg.get(&quot;strategy_name&quot;, &quot;RSI&quot;)&#10;    MARKET = cfg.get(&quot;market&quot;, &quot;KRW-BTC&quot;)&#10;    TIMEFRAME = cfg.get(&quot;timeframe&quot;, &quot;minute5&quot;)&#10;    CANDLE_COUNT = cfg.get(&quot;candle_count&quot;, 200)&#10;    LOOP_INTERVAL_SEC = cfg.get(&quot;loop_interval_sec&quot;, 5)&#10;&#10;    _order_settings = cfg.get(&quot;order_settings&quot;, {})&#10;    MIN_ORDER_AMOUNT = _order_settings.get(&quot;min_order_amount&quot;, 5500)&#10;    TRADE_AMOUNT_KRW = _order_settings.get(&quot;trade_amount_krw&quot;, 6000)&#10;&#10;    USE_KELLY_CRITERION = cfg.get(&quot;use_kelly_criterion&quot;, False)&#10;    _kelly_settings = cfg.get(&quot;kelly_criterion&quot;, {})&#10;    KELLY_WIN_RATE = _kelly_settings.get(&quot;win_rate&quot;, 0.5)&#10;    KELLY_PAYOFF_RATIO = _kelly_settings.get(&quot;payoff_ratio&quot;, 1.0)&#10;    KELLY_FRACTION = _kelly_settings.get(&quot;fraction&quot;, 0.5)&#10;&#10;    _strategy_params = cfg.get(&quot;strategy_params&quot;, {})&#10;    _rsi_params = _strategy_params.get(&quot;RSI&quot;, {})&#10;    RSI_PERIOD = _rsi_params.get(&quot;period&quot;, 14)&#10;    RSI_OVERSOLD = _rsi_params.get(&quot;oversold&quot;, 30)&#10;    RSI_OVERBOUGHT = _rsi_params.get(&quot;overbought&quot;, 70)&#10;&#10;    _vb_params = _strategy_params.get(&quot;VolatilityBreakout&quot;, {})&#10;    VB_K_VALUE = _vb_params.get(&quot;k_value&quot;, 0.5)&#10;&#10;    _dm_params = _strategy_params.get(&quot;DualMomentum&quot;, {})&#10;    DM_WINDOW = _dm_params.get(&quot;window&quot;, 12)&#10;&#10;    _ai_ensemble_settings = cfg.get(&quot;ai_ensemble&quot;, {})&#10;    ENSEMBLE_STRATEGY = _ai_ensemble_settings.get(&quot;strategy&quot;, &quot;UNANIMOUS&quot;)&#10;    OPENAI_MODEL = _ai_ensemble_settings.get(&quot;openai_model&quot;, &quot;gpt-5.1-nano&quot;)&#10;    GEMINI_MODEL = _ai_ensemble_settings.get(&quot;gemini_model&quot;, &quot;gemini-2.5-flash&quot;)&#10;&#10;&#10;# 초기 로드 이후 전역 변수 동기화&#10;_sync_globals_from_config(_config)&#10;&#10;# expose some convenience getters&#10;def get_setting(key: str, default=None):&#10;    value = _config.get(key, default)&#10;    if value is None:&#10;        value = os.environ.get(key, default)&#10;    return value&#10;&#10;&#10;def reload_config():&#10;    global _config&#10;    _config = load_config()&#10;    # 로드된 config로 전역 변수 동기화&#10;    _sync_globals_from_config(_config)&#10;    log.info(&quot;Configuration reloaded.&quot;)&#10;    return _config&#10;&#10;&#10;# --- 기존 전역 변수화 (하위 모듈 호환성 유지) ---&#10;STRATEGY_NAME = _config.get(&quot;strategy_name&quot;, &quot;RSI&quot;)&#10;MARKET = _config.get(&quot;market&quot;, &quot;KRW-BTC&quot;)&#10;TIMEFRAME = _config.get(&quot;timeframe&quot;, &quot;minute5&quot;)&#10;CANDLE_COUNT = _config.get(&quot;candle_count&quot;, 200)&#10;LOOP_INTERVAL_SEC = _config.get(&quot;loop_interval_sec&quot;, 5)&#10;&#10;_order_settings = _config.get(&quot;order_settings&quot;, {})&#10;MIN_ORDER_AMOUNT = _order_settings.get(&quot;min_order_amount&quot;, 5500)&#10;TRADE_AMOUNT_KRW = _order_settings.get(&quot;trade_amount_krw&quot;, 6000)&#10;&#10;USE_KELLY_CRITERION = _config.get(&quot;use_kelly_criterion&quot;, False)&#10;_kelly_settings = _config.get(&quot;kelly_criterion&quot;, {})&#10;KELLY_WIN_RATE = _kelly_settings.get(&quot;win_rate&quot;, 0.5)&#10;KELLY_PAYOFF_RATIO = _kelly_settings.get(&quot;payoff_ratio&quot;, 1.0)&#10;KELLY_FRACTION = _kelly_settings.get(&quot;fraction&quot;, 0.5)&#10;&#10;_strategy_params = _config.get(&quot;strategy_params&quot;, {})&#10;_rsi_params = _strategy_params.get(&quot;RSI&quot;, {})&#10;RSI_PERIOD = _rsi_params.get(&quot;period&quot;, 14)&#10;RSI_OVERSOLD = _rsi_params.get(&quot;oversold&quot;, 30)&#10;RSI_OVERBOUGHT = _rsi_params.get(&quot;overbought&quot;, 70)&#10;&#10;_vb_params = _strategy_params.get(&quot;VolatilityBreakout&quot;, {})&#10;VB_K_VALUE = _vb_params.get(&quot;k_value&quot;, 0.5)&#10;&#10;_dm_params = _strategy_params.get(&quot;DualMomentum&quot;, {})&#10;DM_WINDOW = _dm_params.get(&quot;window&quot;, 12)&#10;&#10;_ai_ensemble_settings = _config.get(&quot;ai_ensemble&quot;, {})&#10;ENSEMBLE_STRATEGY = _ai_ensemble_settings.get(&quot;strategy&quot;, &quot;UNANIMOUS&quot;)&#10;OPENAI_MODEL = _ai_ensemble_settings.get(&quot;openai_model&quot;, &quot;gpt-5.1-nano&quot;)&#10;GEMINI_MODEL = _ai_ensemble_settings.get(&quot;gemini_model&quot;, &quot;gemini-2.5-flash&quot;)&#10;&#10;log.info(f&quot;Configuration loaded: Strategy='{STRATEGY_NAME}', Market='{MARKET}'&quot;)" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/server/ws_listener.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/server/ws_listener.py" />
              <option name="originalContent" value="import json&#10;import os&#10;import threading&#10;import time&#10;import logging&#10;import uuid&#10;from collections import deque&#10;from datetime import datetime, timezone, timedelta&#10;from pathlib import Path&#10;from typing import Any, Dict, List, Optional&#10;&#10;import jwt&#10;import websocket  # websocket-client&#10;&#10;from server import config&#10;from server.logger import log, get_logger&#10;from server.config import get_setting&#10;&#10;UPBIT_WS_URL = &quot;wss://api.upbit.com/websocket/v1&quot;&#10;EXEC_HISTORY_DIR = Path(__file__).resolve().parents[1] / &quot;runtime&quot; / &quot;history&quot;&#10;EXEC_HISTORY_FILE = EXEC_HISTORY_DIR / &quot;exec_history.json&quot;&#10;EXEC_HISTORY_MAX = int(os.getenv(&quot;EXEC_HISTORY_MAX_ENTRIES&quot;, &quot;1024&quot;))&#10;EXEC_HISTORY_LOCK = threading.Lock()&#10;WS_STATS_FILE = EXEC_HISTORY_DIR / &quot;ws_stats.json&quot;&#10;KST = timezone(timedelta(hours=9))&#10;logger = get_logger(name='UpbitWSListener', log_file='ws_listener.log', level=logging.INFO)&#10;&#10;&#10;def _timeframe_to_seconds(timeframe: str) -&gt; int:&#10;    if not isinstance(timeframe, str):&#10;        return 60&#10;    tf = timeframe.lower()&#10;    if tf.startswith(&quot;minute&quot;):&#10;        try:&#10;            return max(int(tf.replace(&quot;minute&quot;, &quot;&quot;)) * 60, 60)&#10;        except ValueError:&#10;            return 60&#10;    if tf.startswith(&quot;hour&quot;):&#10;        try:&#10;            return max(int(tf.replace(&quot;hour&quot;, &quot;&quot;)) * 3600, 3600)&#10;        except ValueError:&#10;            return 3600&#10;    if tf.startswith(&quot;day&quot;):&#10;        return 86400&#10;    return 60&#10;&#10;&#10;def _ensure_exec_history_dir() -&gt; None:&#10;    EXEC_HISTORY_DIR.mkdir(parents=True, exist_ok=True)&#10;&#10;&#10;def _load_ws_stats_file() -&gt; Dict[str, Any]:&#10;    _ensure_exec_history_dir()&#10;    if not WS_STATS_FILE.exists():&#10;        return {'total_success': 0, 'total_failure': 0, 'history': []}&#10;    try:&#10;        with WS_STATS_FILE.open('r', encoding='utf-8') as fp:&#10;            return json.load(fp)&#10;    except Exception:&#10;        return {'total_success': 0, 'total_failure': 0, 'history': []}&#10;&#10;&#10;def summarize_ws_stats(raw_stats: Dict[str, Any], last_hour_secs: int = 3600, recent_limit: int = 10) -&gt; Dict[str, Any]:&#10;    totals = {&#10;        'total_success': int(raw_stats.get('total_success', 0)),&#10;        'total_failure': int(raw_stats.get('total_failure', 0)),&#10;    }&#10;    history = raw_stats.get('history') or []&#10;    now_ms = int(time.time() * 1000)&#10;    since_ms = now_ms - int(last_hour_secs * 1000) if last_hour_secs &gt; 0 else 0&#10;&#10;    def _filter_since(entries: List[Dict[str, Any]]) -&gt; List[Dict[str, Any]]:&#10;        if since_ms &lt;= 0:&#10;            return entries[:]&#10;        return [item for item in entries if item.get('ts', 0) &gt;= since_ms]&#10;&#10;    ticker_events = [item for item in history if (item.get('type') or '').lower() == 'ticker']&#10;    order_events = [item for item in history if (item.get('type') or '').lower() == 'order']&#10;&#10;    ticker_success = sum(1 for item in ticker_events if item.get('success'))&#10;    ticker_failure = len(ticker_events) - ticker_success&#10;    order_success = sum(1 for item in order_events if item.get('success'))&#10;    order_failure = len(order_events) - order_success&#10;&#10;    ticker_last_hour = _filter_since(ticker_events)&#10;    order_last_hour = _filter_since(order_events)&#10;&#10;    ticker_last_hour_success = sum(1 for item in ticker_last_hour if item.get('success'))&#10;    ticker_last_hour_failure = len(ticker_last_hour) - ticker_last_hour_success&#10;    order_last_hour_success = sum(1 for item in order_last_hour if item.get('success'))&#10;    order_last_hour_failure = len(order_last_hour) - order_last_hour_success&#10;&#10;    if recent_limit &gt; 0:&#10;        recent_ticker_events = ticker_events[-recent_limit:]&#10;    else:&#10;        recent_ticker_events = ticker_events[:]&#10;&#10;    return {&#10;        'total_success': totals['total_success'],&#10;        'total_failure': totals['total_failure'],&#10;        'ticker_success': ticker_success,&#10;        'ticker_failure': ticker_failure,&#10;        'order_success': order_success,&#10;        'order_failure': order_failure,&#10;        'last_hour_ticker_success': ticker_last_hour_success,&#10;        'last_hour_ticker_failure': ticker_last_hour_failure,&#10;        'last_hour_order_success': order_last_hour_success,&#10;        'last_hour_order_failure': order_last_hour_failure,&#10;        'recent_ticker_events': recent_ticker_events,&#10;    }&#10;&#10;&#10;def read_exec_history(limit: int = 200) -&gt; List[Dict[str, Any]]:&#10;    store = ExecHistoryStore()&#10;    return store.read_recent(limit)&#10;&#10;&#10;class ExecHistoryStore:&#10;    def __init__(self, path: Path = EXEC_HISTORY_FILE, max_entries: int = EXEC_HISTORY_MAX):&#10;        self.path = path&#10;        self.max_entries = max_entries&#10;        _ensure_exec_history_dir()&#10;&#10;    def _load(self) -&gt; List[Dict[str, Any]]:&#10;        if not self.path.exists():&#10;            return []&#10;        try:&#10;            with self.path.open(&quot;r&quot;, encoding=&quot;utf-8&quot;) as fp:&#10;                return json.load(fp)&#10;        except Exception as exc:&#10;            log.warning(f&quot;Failed to load exec history: {exc}&quot;)&#10;            return []&#10;&#10;    def _save(self, data: List[Dict[str, Any]]) -&gt; None:&#10;        try:&#10;            with self.path.open(&quot;w&quot;, encoding=&quot;utf-8&quot;) as fp:&#10;                json.dump(data, fp, ensure_ascii=False)&#10;        except Exception as exc:&#10;            log.warning(f&quot;Failed to write exec history: {exc}&quot;)&#10;&#10;    def record(self, entry: Dict[str, Any]) -&gt; None:&#10;        with EXEC_HISTORY_LOCK:&#10;            data = self._load()&#10;            data.append(entry)&#10;            if len(data) &gt; self.max_entries:&#10;                data = data[-self.max_entries :]&#10;            self._save(data)&#10;&#10;    def read_recent(self, limit: int = 200) -&gt; List[Dict[str, Any]]:&#10;        data = self._load()&#10;        if limit &lt;= 0:&#10;            return data[:]&#10;        return data[-limit:]&#10;&#10;&#10;class WebsocketListener:&#10;    def __init__(self, redis_client: Optional[Any] = None):&#10;        self.redis_client = redis_client&#10;        self._jwt_token = _generate_ws_token()&#10;        universe = get_setting(&quot;universe&quot;)&#10;        if isinstance(universe, list) and universe:&#10;            self.targets = universe&#10;        else:&#10;            # fallback sample list&#10;            self.targets = [&quot;KRW-BTC&quot;, &quot;KRW-ETH&quot;, &quot;KRW-ADA&quot;, &quot;KRW-XRP&quot;, &quot;KRW-SOL&quot;]&#10;        self.history_store = ExecHistoryStore()&#10;        self._stop_event = threading.Event()&#10;        self._thread: Optional[threading.Thread] = None&#10;        self._ws: Optional[websocket.WebSocketApp] = None&#10;        self._candle_state: Dict[str, Dict[str, Any]] = {}&#10;        self._candle_history_limit = int(os.getenv('WS_CANDLE_HISTORY_LIMIT', '240'))&#10;        self._last_acc_volume: Dict[str, float] = {}&#10;        self._entry_prices: Dict[str, float] = {}&#10;        self._timeframes = self._resolve_timeframes()&#10;        self._tf_state: Dict[str, Dict[str, Dict[str, Any]]] = {}&#10;        self._stats_history_limit = int(os.getenv('WS_STATS_HISTORY_LIMIT', '4000'))&#10;        self._stats_lock = threading.Lock()&#10;        stats = self._load_stats()&#10;        self._stats_totals = {&#10;            'success': stats.get('total_success', 0),&#10;            'failure': stats.get('total_failure', 0),&#10;        }&#10;        history_entries = stats.get('history', [])&#10;        self._stats_history: deque[Dict[str, Any]] = deque(history_entries[-self._stats_history_limit :], maxlen=self._stats_history_limit)&#10;&#10;    def _load_stats(self) -&gt; Dict[str, Any]:&#10;        if not WS_STATS_FILE.exists():&#10;            return {'total_success': 0, 'total_failure': 0, 'history': []}&#10;        try:&#10;            with WS_STATS_FILE.open('r', encoding='utf-8') as fp:&#10;                return json.load(fp)&#10;        except Exception:&#10;            return {'total_success': 0, 'total_failure': 0, 'history': []}&#10;&#10;    def _save_stats(self) -&gt; None:&#10;        try:&#10;            temp = WS_STATS_FILE.with_suffix('.tmp')&#10;            with temp.open('w', encoding='utf-8') as fp:&#10;                json.dump({&#10;                    'total_success': self._stats_totals['success'],&#10;                    'total_failure': self._stats_totals['failure'],&#10;                    'history': list(self._stats_history),&#10;                }, fp)&#10;            temp.replace(WS_STATS_FILE)&#10;        except Exception as exc:&#10;            log.warning(f'Failed to save websocket stats: {exc}')&#10;&#10;    def _register_reception(self, success: bool, payload: Dict[str, Any]) -&gt; None:&#10;        with self._stats_lock:&#10;            key = 'ticker' if payload.get('type') == 'ticker' else 'order'&#10;            ts = payload.get('trade_timestamp') or payload.get('timestamp') or int(time.time() * 1000)&#10;            entry = {&#10;                'ts': ts,&#10;                'type': payload.get('type'),&#10;                'symbol': payload.get('code') or payload.get('symbol'),&#10;                'success': success,&#10;            }&#10;            if success:&#10;                self._stats_totals['success'] += 1&#10;            else:&#10;                self._stats_totals['failure'] += 1&#10;            self._stats_history.append(entry)&#10;            self._save_stats()&#10;&#10;    def _payload_for_subscription(self) -&gt; str:&#10;        message = [&#10;            {&quot;ticket&quot;: self._jwt_token},&#10;            {&quot;type&quot;: &quot;MyOrder&quot;, &quot;codes&quot;: [&quot;KRW-&quot; + t.split('-')[-1] if not t.startswith('KRW-') else t for t in self.targets]},&#10;        ]&#10;        return json.dumps(message)&#10;&#10;    def _push_candle(self, ticker: str, timeframe: str, candle: Dict[str, Any]) -&gt; None:&#10;        if self.redis_client is None:&#10;            return&#10;        try:&#10;            key = f&quot;ws:candles:{timeframe}:{ticker}&quot;&#10;            candle = candle.copy()&#10;            ts = candle.get(&quot;timestamp&quot;)&#10;            if ts:&#10;                try:&#10;                    qualifier = datetime.fromtimestamp(ts / 1000.0, KST)&#10;                    candle[&quot;candle_date_time_kst&quot;] = qualifier.strftime(&quot;%Y-%m-%dT%H:%M:%S%z&quot;)&#10;                except Exception:&#10;                    pass&#10;            candle.setdefault(&quot;candle_acc_trade_volume&quot;, candle.get(&quot;volume&quot;, 0.0))&#10;            self.redis_client.lpush(key, json.dumps(candle))&#10;            self.redis_client.ltrim(key, 0, self._candle_history_limit - 1)&#10;        except Exception as exc:&#10;            log.warning(f&quot;Redis candle push failed: {exc}&quot;)&#10;&#10;    def _read_cached_candles(self, ticker: str, timeframe: str = 'minute1', limit: int = 200) -&gt; List[Dict[str, Any]]:&#10;        if self.redis_client is None:&#10;            return []&#10;        key = f&quot;ws:candles:{timeframe}:{ticker}&quot;&#10;        try:&#10;            raw = self.redis_client.lrange(key, 0, limit - 1)&#10;        except Exception:&#10;            return []&#10;        result = []&#10;        for raw_item in reversed(raw):&#10;            try:&#10;                payload = json.loads(raw_item)&#10;                result.append(payload)&#10;            except Exception:&#10;                continue&#10;        return result&#10;&#10;    def _aggregate_candle(self, payload: Dict[str, Any]) -&gt; None:&#10;        ticker = payload.get(&quot;code&quot;) or payload.get(&quot;symbol&quot;)&#10;        if not ticker:&#10;            return&#10;        ts = payload.get(&quot;trade_timestamp&quot;) or payload.get(&quot;timestamp&quot;) or int(time.time() * 1000)&#10;        try:&#10;            ts_val = float(ts)&#10;        except Exception:&#10;            ts_val = float(time.time() * 1000)&#10;        minute_ts = int(ts_val // 60000 * 60000)&#10;        price = float(payload.get(&quot;trade_price&quot;) or payload.get(&quot;price&quot;) or 0.0)&#10;        if price &lt;= 0:&#10;            return&#10;        state = self._candle_state.get(ticker)&#10;        if not state or state.get(&quot;minute&quot;) != minute_ts:&#10;            if state:&#10;                self._push_candle(ticker, 'minute1', {&#10;                    &quot;ticker&quot;: ticker,&#10;                    &quot;timestamp&quot;: state[&quot;minute&quot;],&#10;                    &quot;open&quot;: state[&quot;open&quot;],&#10;                    &quot;high&quot;: state[&quot;high&quot;],&#10;                    &quot;low&quot;: state[&quot;low&quot;],&#10;                    &quot;close&quot;: state[&quot;close&quot;],&#10;                    &quot;volume&quot;: state[&quot;volume&quot;],&#10;                })&#10;                self._emit_to_timeframes(ticker, state[&quot;minute&quot;], state)&#10;            self._candle_state[ticker] = {&#10;                &quot;minute&quot;: minute_ts,&#10;                &quot;open&quot;: price,&#10;                &quot;high&quot;: price,&#10;                &quot;low&quot;: price,&#10;                &quot;close&quot;: price,&#10;                &quot;volume&quot;: 0.0,&#10;            }&#10;            self._last_acc_volume[ticker] = float(payload.get(&quot;acc_trade_volume&quot;, 0) or 0)&#10;            return&#10;        if price &gt; state[&quot;high&quot;]:&#10;            state[&quot;high&quot;] = price&#10;        if price &lt; state[&quot;low&quot;]:&#10;            state[&quot;low&quot;] = price&#10;        state[&quot;close&quot;] = price&#10;        acc_vol = float(payload.get(&quot;acc_trade_volume&quot;, 0) or 0)&#10;        prev_acc = self._last_acc_volume.get(ticker, 0.0)&#10;        if acc_vol &gt;= prev_acc:&#10;            state[&quot;volume&quot;] += acc_vol - prev_acc&#10;        else:&#10;            state[&quot;volume&quot;] += acc_vol&#10;        self._last_acc_volume[ticker] = acc_vol&#10;&#10;    def _store_to_redis(self, payload: Dict[str, Any]) -&gt; None:&#10;        if self.redis_client is None:&#10;            return&#10;        try:&#10;            code = payload.get(&quot;code&quot;) or payload.get(&quot;symbol&quot;)&#10;            if not code:&#10;                return&#10;            key_base = f&quot;ws:{payload.get('type', 'unknown')}:{code}&quot;&#10;            self.redis_client.set(key_base, json.dumps(payload))&#10;            if payload.get(&quot;type&quot;) == &quot;trade&quot;:&#10;                list_key = f&quot;ws:trades:{code}&quot;&#10;                self.redis_client.lpush(list_key, json.dumps(payload))&#10;                self.redis_client.ltrim(list_key, 0, 200)&#10;            if payload.get(&quot;type&quot;) == &quot;ticker&quot;:&#10;                self._aggregate_candle(payload)&#10;        except Exception as exc:&#10;            log.warning(f&quot;Redis write failed for websocket payload: {exc}&quot;)&#10;&#10;    def _record_exec_history(self, payload: Dict[str, Any]) -&gt; None:&#10;        if payload.get(&quot;type&quot;) != &quot;order&quot;:&#10;            return&#10;        entry = {&#10;            &quot;ts&quot;: float(payload.get(&quot;timestamp&quot;, payload.get(&quot;trade_timestamp&quot;, time.time())) / 1000.0)&#10;            if payload.get(&quot;timestamp&quot;)&#10;            else time.time(),&#10;            &quot;symbol&quot;: payload.get(&quot;code&quot;) or payload.get(&quot;symbol&quot;),&#10;            &quot;price&quot;: payload.get(&quot;price&quot;) or payload.get(&quot;order_price&quot;) or 0,&#10;            &quot;size&quot;: payload.get(&quot;trade_volume&quot;, payload.get(&quot;volume&quot;) or 0),&#10;            &quot;side&quot;: payload.get(&quot;side&quot;) or payload.get(&quot;order_side&quot;) or payload.get(&quot;ask_bid&quot;),&#10;            &quot;order_id&quot;: payload.get(&quot;uuid&quot;) or payload.get(&quot;order_id&quot;),&#10;        }&#10;        side = (entry.get(&quot;side&quot;) or &quot;&quot;).lower()&#10;        symbol = entry.get(&quot;symbol&quot;)&#10;        avg_price = payload.get(&quot;avg_price&quot;) or payload.get(&quot;avg_buy_price&quot;) or payload.get(&quot;order_price&quot;) or payload.get(&quot;price&quot;)&#10;        try:&#10;            avg_price_val = float(avg_price) if avg_price is not None else 0.0&#10;        except Exception:&#10;            avg_price_val = 0.0&#10;&#10;        entry_price_value = 0.0&#10;        if side in (&quot;bid&quot;, &quot;buy&quot;, &quot;매수&quot;):&#10;            self._entry_prices[symbol] = avg_price_val or self._entry_prices.get(symbol, 0.0)&#10;        else:&#10;            entry_price_value = self._entry_prices.get(symbol, avg_price_val)&#10;        entry[&quot;entry_price&quot;] = entry_price_value or 0.0&#10;        if entry[&quot;symbol&quot;]:&#10;            self.history_store.record(entry)&#10;&#10;    def _on_message(self, _, message: str) -&gt; None:&#10;        try:&#10;            payloads = json.loads(message)&#10;            if isinstance(payloads, list):&#10;                for payload in payloads:&#10;                    self._handle_payload(payload)&#10;            elif isinstance(payloads, dict):&#10;                self._handle_payload(payloads)&#10;        except Exception as exc:&#10;            log.warning(f&quot;Failed to parse websocket message: {exc}&quot;)&#10;&#10;    def _handle_payload(self, payload: Dict[str, Any]) -&gt; None:&#10;        success = True&#10;        try:&#10;            self._store_to_redis(payload)&#10;            self._record_exec_history(payload)&#10;        except Exception as exc:&#10;            success = False&#10;            log.warning(f&quot;Websocket payload handling failed: {exc}&quot;)&#10;        finally:&#10;            self._register_reception(success, payload)&#10;&#10;    def _resolve_timeframes(self) -&gt; List[str]:&#10;        cfg_frames = get_setting('ws_timeframes')&#10;        frames: List[str] = []&#10;        if isinstance(cfg_frames, list):&#10;            for tf in cfg_frames:&#10;                if isinstance(tf, str) and tf.strip():&#10;                    frames.append(tf.strip())&#10;        primary = get_setting('timeframe') or 'minute5'&#10;        if primary not in frames:&#10;            frames.append(primary)&#10;        if 'minute1' not in frames:&#10;            frames.insert(0, 'minute1')&#10;        seen: List[str] = []&#10;        for tf in frames:&#10;            if tf not in seen:&#10;                seen.append(tf)&#10;        return seen&#10;&#10;    def _emit_to_timeframes(self, ticker: str, base_ts: float, candle: Dict[str, Any]) -&gt; None:&#10;        bucket_map = self._tf_state.setdefault(ticker, {})&#10;        for timeframe in self._timeframes:&#10;            if timeframe == 'minute1':&#10;                continue&#10;            duration = _timeframe_to_seconds(timeframe) * 1000&#10;            bucket_start = int(base_ts // duration) * duration&#10;            state = bucket_map.get(timeframe)&#10;            if not state or state.get('start') != bucket_start:&#10;                if state:&#10;                    self._push_candle(ticker, timeframe, state)&#10;                bucket_map[timeframe] = {&#10;                    'ticker': ticker,&#10;                    'timeframe': timeframe,&#10;                    'timestamp': bucket_start,&#10;                    'start': bucket_start,&#10;                    'open': candle.get('open'),&#10;                    'high': candle.get('high'),&#10;                    'low': candle.get('low'),&#10;                    'close': candle.get('close'),&#10;                    'volume': candle.get('volume', 0.0),&#10;                }&#10;            else:&#10;                state['high'] = max(state.get('high', 0.0), candle.get('high', 0.0))&#10;                state['low'] = min(state.get('low', state.get('high', 0.0)), candle.get('low', 0.0))&#10;                state['close'] = candle.get('close')&#10;                state['volume'] = state.get('volume', 0.0) + candle.get('volume', 0.0)&#10;&#10;    def _extract_message_payload(self, value: Any) -&gt; Optional[str]:&#10;        if value is None:&#10;            return None&#10;        if isinstance(value, dict):&#10;            return value.get('message') or value.get('errorMessage') or value.get('errorMsg')&#10;        if isinstance(value, str):&#10;            try:&#10;                parsed = json.loads(value)&#10;                if isinstance(parsed, dict):&#10;                    return parsed.get('message') or parsed.get('errorMessage') or parsed.get('errorMsg')&#10;            except json.JSONDecodeError:&#10;                return value&#10;        try:&#10;            return str(value)&#10;        except Exception:&#10;            return None&#10;&#10;    def _format_close_info(self, code: Any, msg: Any) -&gt; str:&#10;        parts: list[str] = []&#10;        if code is not None:&#10;            parts.append(f&quot;code={code}&quot;)&#10;        message = self._extract_message_payload(msg)&#10;        if message:&#10;            parts.append(f&quot;msg={message}&quot;)&#10;        elif msg is not None:&#10;            try:&#10;                decoded = msg.decode() if isinstance(msg, bytes) else str(msg)&#10;            except Exception:&#10;                decoded = str(msg)&#10;            parts.append(f&quot;msg={decoded}&quot;)&#10;        return &quot;, &quot;.join(parts) if parts else &quot;no details&quot;&#10;&#10;    def _on_error(self, _, error: Any) -&gt; None:&#10;        detail = self._extract_message_payload(error)&#10;        if detail:&#10;            logger.warning(f&quot;Websocket listener error: {detail}&quot;)&#10;        else:&#10;            logger.warning(f&quot;Websocket listener error: {error}&quot;)&#10;&#10;    def _on_close(self, _, close_status_code, close_msg) -&gt; None:&#10;        close_info = self._format_close_info(close_status_code, close_msg)&#10;        logger.info(f&quot;Websocket connection closed ({close_info})&quot;)&#10;&#10;    def _on_open(self, ws: websocket.WebSocketApp) -&gt; None:&#10;        self._ws = ws&#10;        try:&#10;            logger.info(f&quot;Sending subscription payload: {self._payload_for_subscription()}&quot;)&#10;            ws.send(self._payload_for_subscription())&#10;        except Exception as exc:&#10;            logger.warning(f&quot;Failed to send websocket subscription: {exc}&quot;)&#10;&#10;    def _run(self) -&gt; None:&#10;        while not self._stop_event.is_set():&#10;            if not self._jwt_token:&#10;                time.sleep(5)&#10;                continue&#10;            try:&#10;                headers = []&#10;                if self._jwt_token:&#10;                    headers.append(f&quot;Authorization: Bearer {self._jwt_token}&quot;)&#10;                ws_app = websocket.WebSocketApp(&#10;                    UPBIT_WS_URL,&#10;                    on_open=self._on_open,&#10;                    on_message=self._on_message,&#10;                    on_error=self._on_error,&#10;                    on_close=self._on_close,&#10;                    header=headers if headers else None,&#10;                 )&#10;                ws_app.run_forever(ping_interval=20, ping_timeout=10)&#10;            except Exception as exc:&#10;                logger.warning(f&quot;Websocket listener restart: {exc}&quot;)&#10;            time.sleep(2)&#10;&#10;    def start(self) -&gt; None:&#10;        if self._thread and self._thread.is_alive():&#10;            return&#10;        self._stop_event.clear()&#10;        self._thread = threading.Thread(target=self._run, daemon=True)&#10;        self._thread.start()&#10;        logger.info(&quot;Websocket listener started.&quot;)&#10;&#10;    def stop(self) -&gt; None:&#10;        self._stop_event.set()&#10;        if self._ws:&#10;            try:&#10;                self._ws.close()&#10;            except Exception:&#10;                pass&#10;        if self._thread:&#10;            self._thread.join(timeout=2)&#10;        logger.info(&quot;Websocket listener stopped.&quot;)&#10;&#10;&#10;def _get_universe_targets() -&gt; List[str]:&#10;    universe = get_setting('universe')&#10;    if isinstance(universe, list) and universe:&#10;        return universe&#10;    return [&quot;KRW-BTC&quot;, &quot;KRW-ETH&quot;, &quot;KRW-ADA&quot;, &quot;KRW-XRP&quot;, &quot;KRW-SOL&quot;]&#10;&#10;&#10;def _generate_ws_token() -&gt; Optional[str]:&#10;    access_key = config.UPBIT_ACCESS_KEY&#10;    secret_key = config.UPBIT_SECRET_KEY&#10;    if not access_key or not secret_key:&#10;        logger.warning('UPBIT_ACCESS_KEY/UPBIT_SECRET_KEY missing; MyOrder websocket authentication skipped.')&#10;        return None&#10;    payload = {'access_key': access_key, 'nonce': str(uuid.uuid4())}&#10;    try:&#10;        token = jwt.encode(payload, secret_key, algorithm='HS256')&#10;        return token.decode() if isinstance(token, bytes) else token&#10;    except Exception as exc:&#10;        logger.warning(f'Failed to create websocket JWT: {exc}')&#10;        return None&#10;" />
              <option name="updatedContent" value="import json&#10;import os&#10;import threading&#10;import time&#10;import logging&#10;import uuid&#10;from collections import deque&#10;from datetime import datetime, timezone, timedelta&#10;from pathlib import Path&#10;from typing import Any, Dict, List, Optional&#10;&#10;import jwt&#10;import websocket  # websocket-client&#10;&#10;from server import config&#10;from server.logger import log, get_logger&#10;from server.config import get_setting&#10;&#10;UPBIT_WS_URL = &quot;wss://api.upbit.com/websocket/v1&quot;&#10;EXEC_HISTORY_DIR = Path(__file__).resolve().parents[1] / &quot;runtime&quot; / &quot;history&quot;&#10;EXEC_HISTORY_FILE = EXEC_HISTORY_DIR / &quot;exec_history.json&quot;&#10;EXEC_HISTORY_MAX = int(os.getenv(&quot;EXEC_HISTORY_MAX_ENTRIES&quot;, &quot;1024&quot;))&#10;EXEC_HISTORY_LOCK = threading.Lock()&#10;WS_STATS_FILE = EXEC_HISTORY_DIR / &quot;ws_stats.json&quot;&#10;KST = timezone(timedelta(hours=9))&#10;logger = get_logger(name='UpbitWSListener', log_file='ws_listener.log', level=logging.INFO)&#10;&#10;&#10;def _timeframe_to_seconds(timeframe: str) -&gt; int:&#10;    if not isinstance(timeframe, str):&#10;        return 60&#10;    tf = timeframe.lower()&#10;    if tf.startswith(&quot;minute&quot;):&#10;        try:&#10;            return max(int(tf.replace(&quot;minute&quot;, &quot;&quot;)) * 60, 60)&#10;        except ValueError:&#10;            return 60&#10;    if tf.startswith(&quot;hour&quot;):&#10;        try:&#10;            return max(int(tf.replace(&quot;hour&quot;, &quot;&quot;)) * 3600, 3600)&#10;        except ValueError:&#10;            return 3600&#10;    if tf.startswith(&quot;day&quot;):&#10;        return 86400&#10;    return 60&#10;&#10;&#10;def _ensure_exec_history_dir() -&gt; None:&#10;    EXEC_HISTORY_DIR.mkdir(parents=True, exist_ok=True)&#10;&#10;&#10;def _load_ws_stats_file() -&gt; Dict[str, Any]:&#10;    _ensure_exec_history_dir()&#10;    if not WS_STATS_FILE.exists():&#10;        return {'total_success': 0, 'total_failure': 0, 'history': []}&#10;    try:&#10;        with WS_STATS_FILE.open('r', encoding='utf-8') as fp:&#10;            return json.load(fp)&#10;    except Exception:&#10;        return {'total_success': 0, 'total_failure': 0, 'history': []}&#10;&#10;&#10;def summarize_ws_stats(raw_stats: Dict[str, Any], last_hour_secs: int = 3600, recent_limit: int = 10) -&gt; Dict[str, Any]:&#10;    totals = {&#10;        'total_success': int(raw_stats.get('total_success', 0)),&#10;        'total_failure': int(raw_stats.get('total_failure', 0)),&#10;    }&#10;    history = raw_stats.get('history') or []&#10;    now_ms = int(time.time() * 1000)&#10;    since_ms = now_ms - int(last_hour_secs * 1000) if last_hour_secs &gt; 0 else 0&#10;&#10;    def _filter_since(entries: List[Dict[str, Any]]) -&gt; List[Dict[str, Any]]:&#10;        if since_ms &lt;= 0:&#10;            return entries[:]&#10;        return [item for item in entries if item.get('ts', 0) &gt;= since_ms]&#10;&#10;    ticker_events = [item for item in history if (item.get('type') or '').lower() == 'ticker']&#10;    order_events = [item for item in history if (item.get('type') or '').lower() == 'order']&#10;&#10;    ticker_success = sum(1 for item in ticker_events if item.get('success'))&#10;    ticker_failure = len(ticker_events) - ticker_success&#10;    order_success = sum(1 for item in order_events if item.get('success'))&#10;    order_failure = len(order_events) - order_success&#10;&#10;    ticker_last_hour = _filter_since(ticker_events)&#10;    order_last_hour = _filter_since(order_events)&#10;&#10;    ticker_last_hour_success = sum(1 for item in ticker_last_hour if item.get('success'))&#10;    ticker_last_hour_failure = len(ticker_last_hour) - ticker_last_hour_success&#10;    order_last_hour_success = sum(1 for item in order_last_hour if item.get('success'))&#10;    order_last_hour_failure = len(order_last_hour) - order_last_hour_success&#10;&#10;    if recent_limit &gt; 0:&#10;        recent_ticker_events = ticker_events[-recent_limit:]&#10;    else:&#10;        recent_ticker_events = ticker_events[:]&#10;&#10;    return {&#10;        'total_success': totals['total_success'],&#10;        'total_failure': totals['total_failure'],&#10;        'ticker_success': ticker_success,&#10;        'ticker_failure': ticker_failure,&#10;        'order_success': order_success,&#10;        'order_failure': order_failure,&#10;        'last_hour_ticker_success': ticker_last_hour_success,&#10;        'last_hour_ticker_failure': ticker_last_hour_failure,&#10;        'last_hour_order_success': order_last_hour_success,&#10;        'last_hour_order_failure': order_last_hour_failure,&#10;        'recent_ticker_events': recent_ticker_events,&#10;    }&#10;&#10;&#10;def read_exec_history(limit: int = 200) -&gt; List[Dict[str, Any]]:&#10;    store = ExecHistoryStore()&#10;    return store.read_recent(limit)&#10;&#10;&#10;class ExecHistoryStore:&#10;    def __init__(self, path: Path = EXEC_HISTORY_FILE, max_entries: int = EXEC_HISTORY_MAX):&#10;        self.path = path&#10;        self.max_entries = max_entries&#10;        _ensure_exec_history_dir()&#10;&#10;    def _load(self) -&gt; List[Dict[str, Any]]:&#10;        if not self.path.exists():&#10;            return []&#10;        try:&#10;            with self.path.open(&quot;r&quot;, encoding=&quot;utf-8&quot;) as fp:&#10;                return json.load(fp)&#10;        except Exception as exc:&#10;            log.warning(f&quot;Failed to load exec history: {exc}&quot;)&#10;            return []&#10;&#10;    def _save(self, data: List[Dict[str, Any]]) -&gt; None:&#10;        try:&#10;            with self.path.open(&quot;w&quot;, encoding=&quot;utf-8&quot;) as fp:&#10;                json.dump(data, fp, ensure_ascii=False)&#10;        except Exception as exc:&#10;            log.warning(f&quot;Failed to write exec history: {exc}&quot;)&#10;&#10;    def record(self, entry: Dict[str, Any]) -&gt; None:&#10;        with EXEC_HISTORY_LOCK:&#10;            data = self._load()&#10;            data.append(entry)&#10;            if len(data) &gt; self.max_entries:&#10;                data = data[-self.max_entries :]&#10;            self._save(data)&#10;&#10;    def read_recent(self, limit: int = 200) -&gt; List[Dict[str, Any]]:&#10;        data = self._load()&#10;        if limit &lt;= 0:&#10;            return data[:]&#10;        return data[-limit:]&#10;&#10;&#10;class WebsocketListener:&#10;    def __init__(self, redis_client: Optional[Any] = None):&#10;        self.redis_client = redis_client&#10;        self._jwt_token = _generate_ws_token()&#10;        universe = get_setting(&quot;universe&quot;)&#10;        if isinstance(universe, list) and universe:&#10;            self.targets = universe&#10;        else:&#10;            # fallback sample list&#10;            self.targets = [&quot;KRW-BTC&quot;, &quot;KRW-ETH&quot;, &quot;KRW-ADA&quot;, &quot;KRW-XRP&quot;, &quot;KRW-SOL&quot;]&#10;        self.history_store = ExecHistoryStore()&#10;        self._stop_event = threading.Event()&#10;        self._thread: Optional[threading.Thread] = None&#10;        self._ws: Optional[websocket.WebSocketApp] = None&#10;        self._candle_state: Dict[str, Dict[str, Any]] = {}&#10;        self._candle_history_limit = int(os.getenv('WS_CANDLE_HISTORY_LIMIT', '240'))&#10;        self._last_acc_volume: Dict[str, float] = {}&#10;        self._entry_prices: Dict[str, float] = {}&#10;        self._timeframes = self._resolve_timeframes()&#10;        self._tf_state: Dict[str, Dict[str, Dict[str, Any]]] = {}&#10;        self._stats_history_limit = int(os.getenv('WS_STATS_HISTORY_LIMIT', '4000'))&#10;        self._stats_lock = threading.Lock()&#10;        stats = self._load_stats()&#10;        self._stats_totals = {&#10;            'success': stats.get('total_success', 0),&#10;            'failure': stats.get('total_failure', 0),&#10;        }&#10;        history_entries = stats.get('history', [])&#10;        self._stats_history: deque[Dict[str, Any]] = deque(history_entries[-self._stats_history_limit :], maxlen=self._stats_history_limit)&#10;&#10;    def _load_stats(self) -&gt; Dict[str, Any]:&#10;        if not WS_STATS_FILE.exists():&#10;            return {'total_success': 0, 'total_failure': 0, 'history': []}&#10;        try:&#10;            with WS_STATS_FILE.open('r', encoding='utf-8') as fp:&#10;                return json.load(fp)&#10;        except Exception:&#10;            return {'total_success': 0, 'total_failure': 0, 'history': []}&#10;&#10;    def _save_stats(self) -&gt; None:&#10;        try:&#10;            temp = WS_STATS_FILE.with_suffix('.tmp')&#10;            with temp.open('w', encoding='utf-8') as fp:&#10;                json.dump({&#10;                    'total_success': self._stats_totals['success'],&#10;                    'total_failure': self._stats_totals['failure'],&#10;                    'history': list(self._stats_history),&#10;                }, fp)&#10;            temp.replace(WS_STATS_FILE)&#10;        except Exception as exc:&#10;            log.warning(f'Failed to save websocket stats: {exc}')&#10;&#10;    def _register_reception(self, success: bool, payload: Dict[str, Any]) -&gt; None:&#10;        with self._stats_lock:&#10;            key = 'ticker' if payload.get('type') == 'ticker' else 'order'&#10;            ts = payload.get('trade_timestamp') or payload.get('timestamp') or int(time.time() * 1000)&#10;            entry = {&#10;                'ts': ts,&#10;                'type': payload.get('type'),&#10;                'symbol': payload.get('code') or payload.get('symbol'),&#10;                'success': success,&#10;            }&#10;            if success:&#10;                self._stats_totals['success'] += 1&#10;            else:&#10;                self._stats_totals['failure'] += 1&#10;            self._stats_history.append(entry)&#10;            self._save_stats()&#10;&#10;    def _payload_for_subscription(self) -&gt; str:&#10;        message = [&#10;            {&quot;ticket&quot;: self._jwt_token},&#10;            {&quot;type&quot;: &quot;MyOrder&quot;, &quot;codes&quot;: [&quot;KRW-&quot; + t.split('-')[-1] if not t.startswith('KRW-') else t for t in self.targets]},&#10;        ]&#10;        return json.dumps(message)&#10;&#10;    def _push_candle(self, ticker: str, timeframe: str, candle: Dict[str, Any]) -&gt; None:&#10;        if self.redis_client is None:&#10;            return&#10;        try:&#10;            key = f&quot;ws:candles:{timeframe}:{ticker}&quot;&#10;            candle = candle.copy()&#10;            ts = candle.get(&quot;timestamp&quot;)&#10;            if ts:&#10;                try:&#10;                    qualifier = datetime.fromtimestamp(ts / 1000.0, KST)&#10;                    candle[&quot;candle_date_time_kst&quot;] = qualifier.strftime(&quot;%Y-%m-%dT%H:%M:%S%z&quot;)&#10;                except Exception:&#10;                    pass&#10;            candle.setdefault(&quot;candle_acc_trade_volume&quot;, candle.get(&quot;volume&quot;, 0.0))&#10;            self.redis_client.lpush(key, json.dumps(candle))&#10;            self.redis_client.ltrim(key, 0, self._candle_history_limit - 1)&#10;        except Exception as exc:&#10;            log.warning(f&quot;Redis candle push failed: {exc}&quot;)&#10;&#10;    def _read_cached_candles(self, ticker: str, timeframe: str = 'minute1', limit: int = 200) -&gt; List[Dict[str, Any]]:&#10;        if self.redis_client is None:&#10;            return []&#10;        key = f&quot;ws:candles:{timeframe}:{ticker}&quot;&#10;        try:&#10;            raw = self.redis_client.lrange(key, 0, limit - 1)&#10;        except Exception:&#10;            return []&#10;        result = []&#10;        for raw_item in reversed(raw):&#10;            try:&#10;                payload = json.loads(raw_item)&#10;                result.append(payload)&#10;            except Exception:&#10;                continue&#10;        return result&#10;&#10;    def _aggregate_candle(self, payload: Dict[str, Any]) -&gt; None:&#10;        ticker = payload.get(&quot;code&quot;) or payload.get(&quot;symbol&quot;)&#10;        if not ticker:&#10;            return&#10;        ts = payload.get(&quot;trade_timestamp&quot;) or payload.get(&quot;timestamp&quot;) or int(time.time() * 1000)&#10;        try:&#10;            ts_val = float(ts)&#10;        except Exception:&#10;            ts_val = float(time.time() * 1000)&#10;        minute_ts = int(ts_val // 60000 * 60000)&#10;        price = float(payload.get(&quot;trade_price&quot;) or payload.get(&quot;price&quot;) or 0.0)&#10;        if price &lt;= 0:&#10;            return&#10;        state = self._candle_state.get(ticker)&#10;        if not state or state.get(&quot;minute&quot;) != minute_ts:&#10;            if state:&#10;                self._push_candle(ticker, 'minute1', {&#10;                    &quot;ticker&quot;: ticker,&#10;                    &quot;timestamp&quot;: state[&quot;minute&quot;],&#10;                    &quot;open&quot;: state[&quot;open&quot;],&#10;                    &quot;high&quot;: state[&quot;high&quot;],&#10;                    &quot;low&quot;: state[&quot;low&quot;],&#10;                    &quot;close&quot;: state[&quot;close&quot;],&#10;                    &quot;volume&quot;: state[&quot;volume&quot;],&#10;                })&#10;                self._emit_to_timeframes(ticker, state[&quot;minute&quot;], state)&#10;            self._candle_state[ticker] = {&#10;                &quot;minute&quot;: minute_ts,&#10;                &quot;open&quot;: price,&#10;                &quot;high&quot;: price,&#10;                &quot;low&quot;: price,&#10;                &quot;close&quot;: price,&#10;                &quot;volume&quot;: 0.0,&#10;            }&#10;            self._last_acc_volume[ticker] = float(payload.get(&quot;acc_trade_volume&quot;, 0) or 0)&#10;            return&#10;        if price &gt; state[&quot;high&quot;]:&#10;            state[&quot;high&quot;] = price&#10;        if price &lt; state[&quot;low&quot;]:&#10;            state[&quot;low&quot;] = price&#10;        state[&quot;close&quot;] = price&#10;        acc_vol = float(payload.get(&quot;acc_trade_volume&quot;, 0) or 0)&#10;        prev_acc = self._last_acc_volume.get(ticker, 0.0)&#10;        if acc_vol &gt;= prev_acc:&#10;            state[&quot;volume&quot;] += acc_vol - prev_acc&#10;        else:&#10;            state[&quot;volume&quot;] += acc_vol&#10;        self._last_acc_volume[ticker] = acc_vol&#10;&#10;    def _store_to_redis(self, payload: Dict[str, Any]) -&gt; None:&#10;        if self.redis_client is None:&#10;            return&#10;        try:&#10;            code = payload.get(&quot;code&quot;) or payload.get(&quot;symbol&quot;)&#10;            if not code:&#10;                return&#10;            key_base = f&quot;ws:{payload.get('type', 'unknown')}:{code}&quot;&#10;            self.redis_client.set(key_base, json.dumps(payload))&#10;            if payload.get(&quot;type&quot;) == &quot;trade&quot;:&#10;                list_key = f&quot;ws:trades:{code}&quot;&#10;                self.redis_client.lpush(list_key, json.dumps(payload))&#10;                self.redis_client.ltrim(list_key, 0, 200)&#10;            if payload.get(&quot;type&quot;) == &quot;ticker&quot;:&#10;                self._aggregate_candle(payload)&#10;        except Exception as exc:&#10;            log.warning(f&quot;Redis write failed for websocket payload: {exc}&quot;)&#10;&#10;    def _record_exec_history(self, payload: Dict[str, Any]) -&gt; None:&#10;        if payload.get(&quot;type&quot;) != &quot;order&quot;:&#10;            return&#10;        entry = {&#10;            &quot;ts&quot;: float(payload.get(&quot;timestamp&quot;, payload.get(&quot;trade_timestamp&quot;, time.time())) / 1000.0)&#10;            if payload.get(&quot;timestamp&quot;)&#10;            else time.time(),&#10;            &quot;symbol&quot;: payload.get(&quot;code&quot;) or payload.get(&quot;symbol&quot;),&#10;            &quot;price&quot;: payload.get(&quot;price&quot;) or payload.get(&quot;order_price&quot;) or 0,&#10;            &quot;size&quot;: payload.get(&quot;trade_volume&quot;, payload.get(&quot;volume&quot;) or 0),&#10;            &quot;side&quot;: payload.get(&quot;side&quot;) or payload.get(&quot;order_side&quot;) or payload.get(&quot;ask_bid&quot;),&#10;            &quot;order_id&quot;: payload.get(&quot;uuid&quot;) or payload.get(&quot;order_id&quot;),&#10;        }&#10;        side = (entry.get(&quot;side&quot;) or &quot;&quot;).lower()&#10;        symbol = entry.get(&quot;symbol&quot;)&#10;        avg_price = payload.get(&quot;avg_price&quot;) or payload.get(&quot;avg_buy_price&quot;) or payload.get(&quot;order_price&quot;) or payload.get(&quot;price&quot;)&#10;        try:&#10;            avg_price_val = float(avg_price) if avg_price is not None else 0.0&#10;        except Exception:&#10;            avg_price_val = 0.0&#10;&#10;        entry_price_value = 0.0&#10;        if side in (&quot;bid&quot;, &quot;buy&quot;, &quot;매수&quot;):&#10;            self._entry_prices[symbol] = avg_price_val or self._entry_prices.get(symbol, 0.0)&#10;        else:&#10;            entry_price_value = self._entry_prices.get(symbol, avg_price_val)&#10;        entry[&quot;entry_price&quot;] = entry_price_value or 0.0&#10;        if entry[&quot;symbol&quot;]:&#10;            self.history_store.record(entry)&#10;&#10;    def _on_message(self, _, message: str) -&gt; None:&#10;        try:&#10;            payloads = json.loads(message)&#10;            if isinstance(payloads, list):&#10;                for payload in payloads:&#10;                    self._handle_payload(payload)&#10;            elif isinstance(payloads, dict):&#10;                self._handle_payload(payloads)&#10;        except Exception as exc:&#10;            log.warning(f&quot;Failed to parse websocket message: {exc}&quot;)&#10;&#10;    def _handle_payload(self, payload: Dict[str, Any]) -&gt; None:&#10;        success = True&#10;        try:&#10;            self._store_to_redis(payload)&#10;            self._record_exec_history(payload)&#10;        except Exception as exc:&#10;            success = False&#10;            log.warning(f&quot;Websocket payload handling failed: {exc}&quot;)&#10;        finally:&#10;            self._register_reception(success, payload)&#10;&#10;    def _resolve_timeframes(self) -&gt; List[str]:&#10;        cfg_frames = get_setting('ws_timeframes')&#10;        frames: List[str] = []&#10;        if isinstance(cfg_frames, list):&#10;            for tf in cfg_frames:&#10;                if isinstance(tf, str) and tf.strip():&#10;                    frames.append(tf.strip())&#10;        primary = get_setting('timeframe') or 'minute5'&#10;        if primary not in frames:&#10;            frames.append(primary)&#10;        if 'minute1' not in frames:&#10;            frames.insert(0, 'minute1')&#10;        seen: List[str] = []&#10;        for tf in frames:&#10;            if tf not in seen:&#10;                seen.append(tf)&#10;        return seen&#10;&#10;    def _emit_to_timeframes(self, ticker: str, base_ts: float, candle: Dict[str, Any]) -&gt; None:&#10;        bucket_map = self._tf_state.setdefault(ticker, {})&#10;        for timeframe in self._timeframes:&#10;            if timeframe == 'minute1':&#10;                continue&#10;            duration = _timeframe_to_seconds(timeframe) * 1000&#10;            bucket_start = int(base_ts // duration) * duration&#10;            state = bucket_map.get(timeframe)&#10;            if not state or state.get('start') != bucket_start:&#10;                if state:&#10;                    self._push_candle(ticker, timeframe, state)&#10;                bucket_map[timeframe] = {&#10;                    'ticker': ticker,&#10;                    'timeframe': timeframe,&#10;                    'timestamp': bucket_start,&#10;                    'start': bucket_start,&#10;                    'open': candle.get('open'),&#10;                    'high': candle.get('high'),&#10;                    'low': candle.get('low'),&#10;                    'close': candle.get('close'),&#10;                    'volume': candle.get('volume', 0.0),&#10;                }&#10;            else:&#10;                state['high'] = max(state.get('high', 0.0), candle.get('high', 0.0))&#10;                state['low'] = min(state.get('low', state.get('high', 0.0)), candle.get('low', 0.0))&#10;                state['close'] = candle.get('close')&#10;                state['volume'] = state.get('volume', 0.0) + candle.get('volume', 0.0)&#10;&#10;    def _extract_message_payload(self, value: Any) -&gt; Optional[str]:&#10;        if value is None:&#10;            return None&#10;        if isinstance(value, dict):&#10;            return value.get('message') or value.get('errorMessage') or value.get('errorMsg')&#10;        if isinstance(value, str):&#10;            try:&#10;                parsed = json.loads(value)&#10;                if isinstance(parsed, dict):&#10;                    return parsed.get('message') or parsed.get('errorMessage') or parsed.get('errorMsg')&#10;            except json.JSONDecodeError:&#10;                return value&#10;        try:&#10;            return str(value)&#10;        except Exception:&#10;            return None&#10;&#10;    def _format_close_info(self, code: Any, msg: Any) -&gt; str:&#10;        parts: list[str] = []&#10;        if code is not None:&#10;            parts.append(f&quot;code={code}&quot;)&#10;        message = self._extract_message_payload(msg)&#10;        if message:&#10;            parts.append(f&quot;msg={message}&quot;)&#10;        elif msg is not None:&#10;            try:&#10;                decoded = msg.decode() if isinstance(msg, bytes) else str(msg)&#10;            except Exception:&#10;                decoded = str(msg)&#10;            parts.append(f&quot;msg={decoded}&quot;)&#10;        return &quot;, &quot;.join(parts) if parts else &quot;no details&quot;&#10;&#10;    def _on_error(self, _, error: Any) -&gt; None:&#10;        detail = self._extract_message_payload(error)&#10;        if detail:&#10;            logger.warning(f&quot;Websocket listener error: {detail}&quot;)&#10;        else:&#10;            logger.warning(f&quot;Websocket listener error: {error}&quot;)&#10;&#10;    def _on_close(self, _, close_status_code, close_msg) -&gt; None:&#10;        close_info = self._format_close_info(close_status_code, close_msg)&#10;        logger.info(f&quot;Websocket connection closed ({close_info})&quot;)&#10;&#10;    def _on_open(self, ws: websocket.WebSocketApp) -&gt; None:&#10;        self._ws = ws&#10;        try:&#10;            logger.info(f&quot;Sending subscription payload: {self._payload_for_subscription()}&quot;)&#10;            ws.send(self._payload_for_subscription())&#10;        except Exception as exc:&#10;            logger.warning(f&quot;Failed to send websocket subscription: {exc}&quot;)&#10;&#10;    def _run(self) -&gt; None:&#10;        while not self._stop_event.is_set():&#10;            if not self._jwt_token:&#10;                time.sleep(5)&#10;                continue&#10;            try:&#10;                headers = []&#10;                if self._jwt_token:&#10;                    headers.append(f&quot;Authorization: Bearer {self._jwt_token}&quot;)&#10;                ws_app = websocket.WebSocketApp(&#10;                    UPBIT_WS_URL,&#10;                    on_open=self._on_open,&#10;                    on_message=self._on_message,&#10;                    on_error=self._on_error,&#10;                    on_close=self._on_close,&#10;                    header=headers if headers else None,&#10;                 )&#10;                ws_app.run_forever(ping_interval=20, ping_timeout=10)&#10;            except Exception as exc:&#10;                logger.warning(f&quot;Websocket listener restart: {exc}&quot;)&#10;            time.sleep(2)&#10;&#10;    def start(self) -&gt; None:&#10;        if self._thread and self._thread.is_alive():&#10;            return&#10;        self._stop_event.clear()&#10;        self._thread = threading.Thread(target=self._run, daemon=True)&#10;        self._thread.start()&#10;        logger.info(&quot;Websocket listener started.&quot;)&#10;&#10;    def stop(self) -&gt; None:&#10;        self._stop_event.set()&#10;        if self._ws:&#10;            try:&#10;                self._ws.close()&#10;            except Exception:&#10;                pass&#10;        if self._thread:&#10;            self._thread.join(timeout=2)&#10;        logger.info(&quot;Websocket listener stopped.&quot;)&#10;&#10;&#10;def _get_universe_targets() -&gt; List[str]:&#10;    universe = get_setting('universe')&#10;    if isinstance(universe, list) and universe:&#10;        return universe&#10;    return [&quot;KRW-BTC&quot;, &quot;KRW-ETH&quot;, &quot;KRW-ADA&quot;, &quot;KRW-XRP&quot;, &quot;KRW-SOL&quot;]&#10;&#10;&#10;def _generate_ws_token() -&gt; Optional[str]:&#10;    access_key = config.UPBIT_ACCESS_KEY&#10;    secret_key = config.UPBIT_SECRET_KEY&#10;    if not access_key or not secret_key:&#10;        logger.warning('UPBIT_ACCESS_KEY/UPBIT_SECRET_KEY missing; MyOrder websocket authentication skipped.')&#10;        return None&#10;    payload = {'access_key': access_key, 'nonce': str(uuid.uuid4())}&#10;    try:&#10;        token = jwt.encode(payload, secret_key, algorithm='HS256')&#10;        return token.decode() if isinstance(token, bytes) else token&#10;    except Exception as exc:&#10;        logger.warning(f'Failed to create websocket JWT: {exc}')&#10;        return None&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/server/ws_listener_private.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/server/ws_listener_private.py" />
              <option name="originalContent" value="import json&#10;from typing import Any, Dict, List, Optional&#10;import time&#10;import uuid&#10;&#10;import jwt&#10;&#10;from server.config import get_setting&#10;from server.ws_listener_base import BaseWebsocketListener&#10;&#10;&#10;class PrivateWebsocketListener(BaseWebsocketListener):&#10;    def __init__(self, redis_client: Optional[Any] = None):&#10;        super().__init__(&#10;            redis_client=redis_client,&#10;            log_name='UpbitWSPrivate',&#10;            log_file='ws_listener_private.log',&#10;            ws_url='wss://api.upbit.com/websocket/v1/private',&#10;        )&#10;        self._jwt_token: Optional[str] = None&#10;&#10;    def _generate_token(self) -&gt; Optional[str]:&#10;        access_key = get_setting('UPBIT_ACCESS_KEY')&#10;        secret_key = get_setting('UPBIT_SECRET_KEY')&#10;        if not access_key or not secret_key:&#10;            self.logger.warning('Private websocket token missing in configuration')&#10;            return None&#10;        payload = {&#10;            'access_key': access_key,&#10;            'nonce': str(uuid.uuid4()),&#10;        }&#10;        try:&#10;            token = jwt.encode(payload, secret_key, algorithm='HS256')&#10;            if isinstance(token, bytes):&#10;                token = token.decode('utf-8')&#10;            return token&#10;        except Exception as exc:&#10;            self.logger.warning(f'Failed to generate websocket token: {exc}')&#10;            return None&#10;&#10;    def _pre_run(self) -&gt; bool:&#10;        self._jwt_token = self._generate_token()&#10;        if not self._jwt_token:&#10;            self.logger.warning('Private websocket has no JWT yet; retrying soon')&#10;            return False&#10;        return True&#10;&#10;    def subscription_payload(self) -&gt; str:&#10;        message = [&#10;            {'ticket': 'upbit-ws-private'},&#10;            {'type': 'myOrder', 'codes': self._targets},&#10;        ]&#10;        return json.dumps(message)&#10;&#10;    def auth_headers(self) -&gt; List[str]:&#10;        if not self._jwt_token:&#10;            return []&#10;        return [&#10;            f'Authorization: Bearer {self._jwt_token}',&#10;        ]&#10;&#10;    def on_payload(self, payload: Dict[str, Any]) -&gt; None:&#10;        if payload.get('type') != 'myOrder':&#10;            return&#10;        self._record_exec_history(payload)&#10;" />
              <option name="updatedContent" value="import json&#10;from typing import Any, Dict, List, Optional&#10;import time&#10;import uuid&#10;&#10;import jwt&#10;&#10;from server.config import get_setting&#10;from server.ws_listener_base import BaseWebsocketListener&#10;&#10;&#10;class PrivateWebsocketListener(BaseWebsocketListener):&#10;    def __init__(self, redis_client: Optional[Any] = None):&#10;        super().__init__(&#10;            redis_client=redis_client,&#10;            log_name='UpbitWSPrivate',&#10;            log_file='ws_listener_private.log',&#10;            ws_url='wss://api.upbit.com/websocket/v1/private',&#10;        )&#10;        self._jwt_token: Optional[str] = None&#10;&#10;    def _generate_token(self) -&gt; Optional[str]:&#10;        access_key = get_setting('UPBIT_ACCESS_KEY')&#10;        secret_key = get_setting('UPBIT_SECRET_KEY')&#10;        if not access_key or not secret_key:&#10;            self.logger.warning('Private websocket token missing in configuration')&#10;            return None&#10;        payload = {&#10;            'access_key': access_key,&#10;            'nonce': str(uuid.uuid4()),&#10;        }&#10;        try:&#10;            token = jwt.encode(payload, secret_key, algorithm='HS256')&#10;            if isinstance(token, bytes):&#10;                token = token.decode('utf-8')&#10;            return token&#10;        except Exception as exc:&#10;            self.logger.warning(f'Failed to generate websocket token: {exc}')&#10;            return None&#10;&#10;    def _pre_run(self) -&gt; bool:&#10;        self._jwt_token = self._generate_token()&#10;        if not self._jwt_token:&#10;            self.logger.warning('Private websocket has no JWT yet; retrying soon')&#10;            return False&#10;        return True&#10;&#10;    def subscription_payload(self) -&gt; str:&#10;        message = [&#10;            {'ticket': 'upbit-ws-private'},&#10;            {'type': 'myOrder', 'codes': self._targets},&#10;        ]&#10;        return json.dumps(message)&#10;&#10;    def auth_headers(self) -&gt; List[str]:&#10;        if not self._jwt_token:&#10;            return []&#10;        return [&#10;            f'Authorization: Bearer {self._jwt_token}',&#10;        ]&#10;&#10;    def on_payload(self, payload: Dict[str, Any]) -&gt; None:&#10;        if payload.get('type') != 'myOrder':&#10;            return&#10;        self._record_exec_history(payload)" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/server/ws_listener_public.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/server/ws_listener_public.py" />
              <option name="originalContent" value="import json&#10;import threading&#10;import time&#10;import websocket  # websocket-client&#10;from typing import Any, Dict, List, Optional&#10;from server.ws_listener_base import BaseWebsocketListener&#10;&#10;&#10;class TickerWebsocketListener(BaseWebsocketListener):&#10;    def __init__(self, redis_client: Optional[Any] = None):&#10;        super().__init__(redis_client=redis_client, log_name='UpbitWSPublic', log_file='ws_listener_public.log')&#10;&#10;    def subscription_payload(self) -&gt; str:&#10;        codes = self._targets&#10;        message = [&#10;            {&quot;ticket&quot;: &quot;upbit-ws-public&quot;},&#10;            {&quot;type&quot;: &quot;ticker&quot;, &quot;codes&quot;: codes, &quot;isOnlyRealtime&quot;: False},&#10;        ]&#10;        return json.dumps(message)&#10;&#10;    def auth_headers(self) -&gt; List[str]:&#10;        return []&#10;&#10;    def on_payload(self, payload: Dict[str, Any]) -&gt; None:&#10;        if payload.get('type') != 'ticker':&#10;            raise ValueError('Unexpected payload type for public listener')&#10;        self._aggregate_candle(payload)&#10;" />
              <option name="updatedContent" value="import json&#10;import threading&#10;import time&#10;import websocket  # websocket-client&#10;from typing import Any, Dict, List, Optional&#10;from server.ws_listener_base import BaseWebsocketListener&#10;&#10;&#10;class TickerWebsocketListener(BaseWebsocketListener):&#10;    def __init__(self, redis_client: Optional[Any] = None):&#10;        super().__init__(redis_client=redis_client, log_name='UpbitWSPublic', log_file='ws_listener_public.log')&#10;&#10;    def subscription_payload(self) -&gt; str:&#10;        codes = self._targets&#10;        message = [&#10;            {&quot;ticket&quot;: &quot;upbit-ws-public&quot;},&#10;            {&quot;type&quot;: &quot;ticker&quot;, &quot;codes&quot;: codes, &quot;isOnlyRealtime&quot;: False},&#10;        ]&#10;        return json.dumps(message)&#10;&#10;    def auth_headers(self) -&gt; List[str]:&#10;        return []&#10;&#10;    def on_payload(self, payload: Dict[str, Any]) -&gt; None:&#10;        if payload.get('type') != 'ticker':&#10;            raise ValueError('Unexpected payload type for public listener')&#10;        self._aggregate_candle(payload)" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>