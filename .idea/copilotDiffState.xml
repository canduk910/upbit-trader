<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/Dockerfile.backend">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/Dockerfile.backend" />
              <option name="originalContent" value="# Backend Dockerfile for Upbit Trader&#10;FROM python:3.11-slim&#10;&#10;# Install basic dependencies&#10;RUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \&#10;    build-essential \&#10;    gcc \&#10;    curl \&#10;    &amp;&amp; rm -rf /var/lib/apt/lists/*&#10;&#10;WORKDIR /app&#10;COPY requirements.txt /app/&#10;RUN pip install --no-cache-dir -r requirements.txt&#10;&#10;# Copy project&#10;COPY . /app&#10;&#10;# Add reusable entrypoint&#10;COPY scripts/docker-entrypoint.sh /usr/local/bin/docker-entrypoint.sh&#10;RUN chmod +x /usr/local/bin/docker-entrypoint.sh&#10;ENTRYPOINT [&quot;docker-entrypoint.sh&quot;]&#10;&#10;ENV PYTHONUNBUFFERED=1&#10;ENV PYTHONPATH=/app&#10;ENV REDIS_URL=redis://redis:6379/0&#10;&#10;EXPOSE 8000&#10;CMD [&quot;uvicorn&quot;, &quot;server.api:app&quot;, &quot;--host&quot;, &quot;0.0.0.0&quot;, &quot;--port&quot;, &quot;8000&quot;]&#10;" />
              <option name="updatedContent" value="# Backend Dockerfile for Upbit Trader&#10;FROM python:3.11-slim&#10;&#10;# Install basic dependencies&#10;RUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \&#10;    build-essential \&#10;    gcc \&#10;    curl \&#10;    &amp;&amp; rm -rf /var/lib/apt/lists/*&#10;&#10;WORKDIR /app&#10;COPY requirements.txt /app/&#10;RUN pip install --no-cache-dir -r requirements.txt&#10;&#10;# Copy project&#10;COPY . /app&#10;&#10;# Add reusable entrypoint&#10;COPY scripts/docker-entrypoint.sh /usr/local/bin/docker-entrypoint.sh&#10;RUN chmod +x /usr/local/bin/docker-entrypoint.sh&#10;ENTRYPOINT [&quot;docker-entrypoint.sh&quot;]&#10;&#10;ENV PYTHONUNBUFFERED=1&#10;ENV PYTHONPATH=/app&#10;ENV REDIS_URL=redis://redis:6379/0&#10;&#10;EXPOSE 8000&#10;CMD [&quot;uvicorn&quot;, &quot;server.api:app&quot;, &quot;--host&quot;, &quot;0.0.0.0&quot;, &quot;--port&quot;, &quot;8000&quot;]" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/docker-compose.override.yml">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/docker-compose.override.yml" />
              <option name="originalContent" value="services:&#10;  backend:&#10;    env_file:&#10;      - server/.env&#10;    volumes:&#10;      - ./:/app:cached&#10;      - ./logs:/app/logs&#10;      - ./runtime:/app/runtime&#10;    command: sh -c &quot;uvicorn server.api:app --app-dir /app --host 0.0.0.0 --port 8000 --reload --reload-dir /app/server&quot;&#10;    environment:&#10;      - REDIS_URL=redis://redis:6379/0&#10;    ports:&#10;      - &quot;8000:8000&quot;&#10;&#10;  ui:&#10;    env_file:&#10;      - server/.env&#10;    volumes:&#10;      - ./:/app:cached&#10;      - ./logs:/app/logs&#10;      - ./runtime:/app/runtime&#10;    command: sh -c &quot;streamlit run ui/ui_dashboard.py --server.port 8501 --server.address 0.0.0.0&quot;&#10;    ports:&#10;      - &quot;8501:8501&quot;&#10;&#10;  bot:&#10;    env_file:&#10;      - server/.env&#10;    volumes:&#10;      - ./:/app:cached&#10;      - ./logs:/app/logs&#10;      - ./runtime:/app/runtime&#10;    command: sh -c &quot;python -m server.bot&quot;&#10;&#10;  ws_listener_public:&#10;    env_file:&#10;      - server/.env&#10;    build:&#10;      context: .&#10;      dockerfile: Dockerfile.backend&#10;    container_name: upbit-trader-ws-listener-public-dev&#10;    working_dir: /app&#10;    volumes:&#10;      - ./:/app:cached&#10;      - ./logs:/app/logs&#10;      - ./runtime:/app/runtime&#10;    command: python -m server.ws_listener_public&#10;    environment:&#10;      - PYTHONUNBUFFERED=1&#10;      - PYTHONPATH=/app&#10;      - REDIS_URL=redis://redis:6379/0&#10;&#10;  ws_listener_private:&#10;    env_file:&#10;      - server/.env&#10;    build:&#10;      context: .&#10;      dockerfile: Dockerfile.backend&#10;    container_name: upbit-trader-ws-listener-private-dev&#10;    working_dir: /app&#10;    volumes:&#10;      - ./:/app:cached&#10;      - ./logs:/app/logs&#10;      - ./runtime:/app/runtime&#10;    command: python -m server.ws_listener_private&#10;    environment:&#10;      - PYTHONUNBUFFERED=1&#10;      - PYTHONPATH=/app&#10;      - REDIS_URL=redis://redis:6379/0&#10;" />
              <option name="updatedContent" value="services:&#10;  backend:&#10;    env_file:&#10;      - server/.env&#10;    volumes:&#10;      - ./:/app:cached&#10;      - ./logs:/app/logs&#10;      - ./runtime:/app/runtime&#10;    command: sh -c &quot;uvicorn server.api:app --app-dir /app --host 0.0.0.0 --port 8000 --reload --reload-dir /app/server&quot;&#10;    environment:&#10;      - REDIS_URL=redis://redis:6379/0&#10;    ports:&#10;      - &quot;8000:8000&quot;&#10;&#10;  ui:&#10;    env_file:&#10;      - server/.env&#10;    volumes:&#10;      - ./:/app:cached&#10;      - ./logs:/app/logs&#10;      - ./runtime:/app/runtime&#10;    command: sh -c &quot;streamlit run ui/ui_dashboard.py --server.port 8501 --server.address 0.0.0.0&quot;&#10;    ports:&#10;      - &quot;8501:8501&quot;&#10;&#10;  bot:&#10;    env_file:&#10;      - server/.env&#10;    volumes:&#10;      - ./:/app:cached&#10;      - ./logs:/app/logs&#10;      - ./runtime:/app/runtime&#10;    command: sh -c &quot;python -m server.bot&quot;&#10;&#10;  ws_listener_public:&#10;    env_file:&#10;      - server/.env&#10;    build:&#10;      context: .&#10;      dockerfile: Dockerfile.backend&#10;    container_name: upbit-trader-ws-listener-public-dev&#10;    working_dir: /app&#10;    volumes:&#10;      - ./:/app:cached&#10;      - ./logs:/app/logs&#10;      - ./runtime:/app/runtime&#10;    command: python -m server.ws_listener_public&#10;    environment:&#10;      - PYTHONUNBUFFERED=1&#10;      - PYTHONPATH=/app&#10;      - REDIS_URL=redis://redis:6379/0&#10;&#10;  ws_listener_private:&#10;    env_file:&#10;      - server/.env&#10;    build:&#10;      context: .&#10;      dockerfile: Dockerfile.backend&#10;    container_name: upbit-trader-ws-listener-private-dev&#10;    working_dir: /app&#10;    volumes:&#10;      - ./:/app:cached&#10;      - ./logs:/app/logs&#10;      - ./runtime:/app/runtime&#10;    command: python -m server.ws_listener_private&#10;    environment:&#10;      - PYTHONUNBUFFERED=1&#10;      - PYTHONPATH=/app&#10;      - REDIS_URL=redis://redis:6379/0" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/server/ai_analyst.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/server/ai_analyst.py" />
              <option name="originalContent" value="import json&#10;import concurrent.futures&#10;import server.config as config&#10;from server.logger import log&#10;from server.history import ai_history_store&#10;from datetime import datetime, timezone, timedelta&#10;import math&#10;&#10;# OpenAI SDK&#10;# Defensive imports&#10;try:&#10;    import openai&#10;except Exception:&#10;    openai = None&#10;&#10;# Gemini SDK&#10;# Defensive imports&#10;try:&#10;    import google.generativeai as genai&#10;except Exception:&#10;    genai = None&#10;&#10;# AI 자문 앙상블 분석기 클래스&#10;# OpenAI와 Gemini 모델을 병렬로 호출하여 TradingContext에 대한 TradingDecision을 생성&#10;# 두 모델의 출력을 결합하여 최종 매매 결정을 내림&#10;# OpenAI 또는 Gemini SDK가 설치되지 않았거나 API 키가 제공되지 않은 경우에도&#10;# 모듈이 정상적으로 임포트되며 분석기는 안전한 동작('HOLD' 반환)으로 대체됨&#10;class EnsembleAnalyzer:&#10;&#10;    # 초기화 메서드&#10;    def __init__(self):&#10;        # 멤버 변수 초기화&#10;        self.openai_client = None&#10;        self.openai_model = None&#10;        self.gemini_model = None&#10;        self._openai_fallback_tried = False&#10;&#10;        # 1. OpenAI 초기화 (가능한 경우)&#10;        if openai is None:&#10;            log.warning(&quot;OpenAI SDK not installed; AI ensemble disabled for OpenAI.&quot;)&#10;        else:&#10;            try:&#10;                if not getattr(config, 'OPENAI_API_KEY', None):&#10;                    log.warning('OPENAI_API_KEY missing in config; OpenAI disabled.')&#10;                else:&#10;                    # 우선: OpenAI client 인스턴스 생성 시도&#10;                    # 참고: openai.OpenAI()는 openai 패키지 버전 0.27.0 이상에서 지원&#10;                    # 그 이하 버전에서는 openai.api_key 설정 방식으로 동작&#10;                    # 따라서 두 방식을 모두 시도&#10;                    try:&#10;                        self.openai_client = openai.OpenAI(api_key=config.OPENAI_API_KEY) # 클라이언트 인스턴스&#10;                    except Exception:&#10;                        try:&#10;                            openai.api_key = config.OPENAI_API_KEY # 전역 설정&#10;                            self.openai_client = openai # 패키지 자체를 클라이언트로 사용&#10;                        except Exception as e:&#10;                            log.warning(f'Failed to init OpenAI client: {e}')&#10;                    self.openai_model = getattr(config, 'OPENAI_MODEL', None) or self._default_openai_model()&#10;&#10;            except Exception as e:&#10;                log.warning(f'Failed to init OpenAI client: {e}')&#10;&#10;        # 2. Gemini 초기화 (가능한 경우)&#10;        if genai is None:&#10;            log.warning(&quot;Gemini SDK not installed; AI ensemble disabled for Gemini.&quot;)&#10;        else:&#10;            try:&#10;                if not getattr(config, 'GEMINI_API_KEY', None):&#10;                    log.warning('GEMINI_API_KEY missing in config; Gemini disabled.')&#10;                else:&#10;                    # Gemini 클라이언트 구성&#10;                    genai.configure(api_key=config.GEMINI_API_KEY) # 전역 구성&#10;                    self.gemini_model = genai.GenerativeModel(getattr(config, 'GEMINI_MODEL', None)) # 모델 인스턴스&#10;            except Exception as e:&#10;                log.warning(f'Failed to init Gemini client: {e}')&#10;&#10;    def _default_openai_model(self):&#10;        return 'o4-mini'&#10;&#10;    def _next_openai_fallback(self, current_model: str | None):&#10;        preferred = [&#10;            getattr(config, 'OPENAI_FALLBACK_MODEL', None),&#10;            'gpt-5-mini',&#10;            'gpt-5-nano',&#10;        ]&#10;        for cand in preferred:&#10;            if cand and cand != current_model:&#10;                return cand&#10;        return None&#10;&#10;    # 시스템 프롬프트 생성 메서드&#10;    # OpenAI 및 Gemini에 동일한 시스템 프롬프트 사용&#10;    # 생성된 시스템 프롬프트는 업비트 현물 계좌 운용 퀀트 트레이더 AI 역할을 정의&#10;    # TradingContext 입력 데이터 구조와 TradingDecision 출력 스키마를 상세히 명시&#10;    # 또한, 매매 판단 원칙과 제약조건을 구체적으로 기술&#10;    # 반환값: (str) 시스템 프롬프트 텍스트&#10;    def _get_system_prompt(self):&#10;        return &quot;&quot;&quot;&#10;        너는 업비트(UPBIT) 현물 계좌를 운용하는 퀀트/시스템 트레이더 AI다.&#10;&#10;        [환경]&#10;        - 거래소: 업비트(UPBIT)&#10;        - 상품: 현물(Spot)만, 마진·선물·레버리지·공매도 없음&#10;        - 통화단위: KRW 기준, 모든 금액은 KRW라고 가정한다.&#10;&#10;        [입력 데이터: TradingContext JSON]&#10;        - meta: 거래소, 마켓 타입, 기준 시각, 전략 이름, 루프 주기 등 메타정보&#10;        - constraints: 1회 주문 최대 금액, 최소 주문 금액, 레버리지/공매도 불가 여부 등 제약조건&#10;        - account: 총자산, 가용 현금, 보유 포지션 목록, 미체결 주문 목록&#10;        - markets[]:&#10;          - symbol: 예) &quot;KRW-BTC&quot;&#10;          - base / quote: 베이스·쿼트 자산&#10;          - day_change_pct, day_volume_krw: 일간 등락률과 거래대금(있을 경우)&#10;          - timeframes[&lt;타임프레임&gt;]:&#10;              - last_candle: 시가/고가/저가/종가/거래량&#10;              - indicators: RSI, 볼린저밴드, 이동평균, MACD 등 기술지표와 최근 종가 시퀀스&#10;          - orderbook: 최상위 매수/매도 호가 및 잔량 정보(있을 경우)&#10;          - position: 해당 심볼에 대한 보유 수량·평단가·평가금액 등 (있을 경우)&#10;&#10;        [출력: TradingDecision JSON ONLY]&#10;        항상 아래 스키마를 따르는 하나의 JSON 객체만 반환한다.&#10;        JSON 바깥에 자연어 문장, 코드블록, 설명 텍스트를 절대 추가하지 마라.&#10;&#10;        {&#10;          &quot;decisions&quot;: [&#10;            {&#10;              &quot;symbol&quot;: &quot;KRW-BTC&quot;,&#10;              &quot;timeframe&quot;: &quot;&lt;분석에 주로 사용한 타임프레임 문자열&gt;&quot;,&#10;              &quot;action&quot;: &quot;BUY&quot; | &quot;SELL&quot; | &quot;HOLD&quot;,&#10;              &quot;confidence&quot;: 0.0,&#10;              &quot;size_krw&quot;: 0.0,&#10;              &quot;reasoning&quot;: {&#10;                &quot;technical_factors&quot;: [&quot;요인1&quot;, &quot;요인2&quot;],&#10;                &quot;orderbook_factors&quot;: [&quot;요인1&quot;],&#10;                &quot;risk_factors&quot;: [&quot;손절·변동성·과도한 집중 등의 위험&quot;],&#10;                &quot;summary&quot;: &quot;최종 판단을 한두 문장으로 요약&quot;&#10;              },&#10;              &quot;risk_management&quot;: {&#10;                &quot;stop_loss&quot;: &quot;예: 15분봉 종가 기준 -3% 하락 시 전량 손절&quot;,&#10;                &quot;take_profit&quot;: &quot;예: 단기 저항선 또는 +5~8% 구간에서 분할 매도&quot;,&#10;                &quot;notes&quot;: &quot;추가로 주의해야 할 사항&quot;&#10;              },&#10;              &quot;price_plan&quot;: {&#10;                &quot;entry_price&quot;: 0.0,&#10;                &quot;stop_loss_price&quot;: 0.0,&#10;                &quot;take_profit_price&quot;: 0.0,&#10;                &quot;market_factor&quot;: 0.0&#10;              }&#10;            }&#10;          ],&#10;          &quot;portfolio_comment&quot;: &quot;현재 계좌 전체 관점에서의 리스크, 현금비중, 분산상태 코멘트&quot;,&#10;          &quot;risk_flags&quot;: [&#10;            {&quot;type&quot;: &quot;MAX_DRAWDOWN&quot;, &quot;severity&quot;: &quot;LOW|MEDIUM|HIGH&quot;, &quot;message&quot;: &quot;...&quot;}&#10;          ]&#10;        }&#10;&#10;        [추가 지침]&#10;        - 각 decision.price_plan의 수치는 반드시 숫자로만 채워라.&#10;        - entry_price, stop_loss_price, take_profit_price는 KRW 단위이며 최근 시세와 일관되게 산출한다.&#10;        - market_factor는 0.0~1.0 범위에서 현재 시장의 공격적/보수적 정도를 나타내는 실수다.&#10;        - stop_loss_price는 entry_price보다 낮아야 하며, take_profit_price는 entry_price보다 높아야 한다.&#10;        - price_plan 정보를 반드시 포함시켜 downstream 시스템이 직접 활용할 수 있게 한다.&#10;&#10;        [판단 원칙]&#10;        1. 업비트 현물 계좌 특성을 지켜라.&#10;           - 레버리지, 공매도, 공매수/공매도 스왑 등은 절대 제안하지 않는다.&#10;           - 보유 중인 수량보다 큰 매도, 마이너스 수량이 되는 주문은 금지.&#10;        2. 제약조건(constraints)을 항상 존중한다.&#10;           - size_krw는 min_order_krw 이상이어야 하며 per_trade_max_krw를 넘지 않는다.&#10;           - 계좌의 available_krw를 넘는 매수는 제안하지 않는다.&#10;        3. &quot;HOLD&quot;는 다음과 같은 경우 기본 선택이다.&#10;           - 추세가 애매하거나 지표가 서로 상충될 때&#10;           - 스프레드·호가 잔량이 비정상적으로 왜곡돼 있을 때&#10;           - 방금 직전에 매매가 일어났고 충분한 새로운 정보가 쌓이지 않았을 때&#10;        4. 이미 포지션이 있을 때:&#10;           - 뚜렷한 추세 전환·과열/과매도 신호·리스크 급증 시에만 SELL을 제안한다.&#10;           - 단순한 단기 노이즈, 작은 조정에는 HOLD를 권장한다.&#10;        5. 항상 계좌 전체 리스크를 고려해 보수적으로 의사결정을 내린다.&#10;        &quot;&quot;&quot;&#10;&#10;    # 사용자 프롬프트 생성 메서드&#10;    # TradingContext 딕셔너리를 JSON 문자열로 직렬화하여 포함&#10;    # 생성된 사용자 프롬프트는 시스템 프롬프트와 함께 AI 모델에 전달됨&#10;    # TradingContext 딕셔너리를 JSON 문자열로 직렬화하여 포함&#10;    # 반환값: (str) 사용자 프롬프트 텍스트&#10;    def _get_user_prompt(self, trading_context: dict):&#10;        &quot;&quot;&quot;TradingContext dict를 그대로 JSON 문자열로 직렬화해서 보낸다.&quot;&quot;&quot;&#10;        try:&#10;            context_json = json.dumps(trading_context, ensure_ascii=False)&#10;        except Exception as e:&#10;            log.error(f&quot;Failed to serialize trading_context for AI: {e}&quot;)&#10;            context_json = json.dumps({&quot;error&quot;: &quot;serialization_failed&quot;})&#10;&#10;        return f&quot;&quot;&quot;&#10;        아래는 현재 업비트 계좌 상태와 시세/기술지표/호가 정보로 구성된 TradingContext JSON이다.&#10;        &#10;        이 데이터를 바탕으로, 시스템 프롬프트의 규칙과 출력 형식을 엄격히 지키면서&#10;        매 종목에 대한 매매 판단과 주문/리스크 관리 계획을 포함하는 TradingDecision JSON을 생성해라.&#10;        &#10;        반드시 JSON만 출력하고, JSON 바깥에 다른 문장은 쓰지 마라.&#10;        &#10;        TradingContext:&#10;        {context_json}&#10;        &quot;&quot;&quot;&#10;&#10;    # OpenAI에게 질문 메서드&#10;    # TradingDecision JSON 스키마 기준&#10;    # 반환값: (dict) {&quot;source&quot;: &quot;OpenAI&quot;, &quot;decision&quot;: &quot;...&quot;, &quot;reason&quot;: &quot;...&quot;}&#10;    def _ask_openai(self, system_prompt, user_prompt):&#10;        if not self.openai_client or not self.openai_model:&#10;            log.warning('OpenAI client or model not initialized; skipping request.')&#10;            return {&quot;source&quot;: &quot;OpenAI&quot;, &quot;decision&quot;: &quot;ERROR&quot;, &quot;reason&quot;: &quot;client_not_initialized&quot;}&#10;        try:&#10;            # OpenAI ChatCompletion API 호출&#10;            response = self.openai_client.chat.completions.create(&#10;                model=self.openai_model,                            # 모델 이름&#10;                messages=[&#10;                    {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: system_prompt},&#10;                    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: user_prompt}&#10;                ],                                                  # 메시지 목록&#10;                response_format={&quot;type&quot;: &quot;json_object&quot;}             # 응답 형식 지정&#10;            )&#10;            raw = response.choices[0].message.content # 응답 원문&#10;            result = json.loads(raw) # JSON 파싱&#10;&#10;            decision = &quot;HOLD&quot;&#10;            reason = &quot;&quot;&#10;            target_symbol = getattr(config, &quot;MARKET&quot;, None) # 타겟 심볼 설정&#10;&#10;            # 새 스키마 호환: {&quot;decisions&quot;: [ ... ]}&#10;            decisions = result.get(&quot;decisions&quot;)&#10;            if isinstance(decisions, list) and decisions:&#10;                if target_symbol:&#10;                    target = None&#10;                    for d in decisions:&#10;                        if d.get(&quot;symbol&quot;) == target_symbol:&#10;                            target = d&#10;                            break&#10;                    if target is None:&#10;                        target = decisions[0]&#10;                else:&#10;                    target = decisions[0]&#10;&#10;                # 매매 결정 및 이유 추출&#10;                action = str(target.get(&quot;action&quot;, &quot;HOLD&quot;)).upper()&#10;                decision = action if action in [&quot;BUY&quot;, &quot;SELL&quot;, &quot;HOLD&quot;] else &quot;HOLD&quot;&#10;&#10;                reasoning = target.get(&quot;reasoning&quot;, {})     # 이유 딕셔너리&#10;                summary = reasoning.get(&quot;summary&quot;)          # 요약&#10;                tech = reasoning.get(&quot;technical_factors&quot;)   # 기술적 요인&#10;                risk = reasoning.get(&quot;risk_factors&quot;)        # 리스크 요인&#10;&#10;                parts = []&#10;                # 이유 구성&#10;                if summary:&#10;                    parts.append(str(summary))&#10;                if tech:&#10;                    if isinstance(tech, list):&#10;                        parts.append(&quot;기술적 요인: &quot; + &quot;, &quot;.join(map(str, tech)))&#10;                    else:&#10;                        parts.append(&quot;기술적 요인: &quot; + str(tech))&#10;                if risk:&#10;                    if isinstance(risk, list):&#10;                        parts.append(&quot;리스크 요인: &quot; + &quot;, &quot;.join(map(str, risk)))&#10;                    else:&#10;                        parts.append(&quot;리스크 요인: &quot; + str(risk))&#10;                reason = &quot; | &quot;.join(parts)&#10;            else:&#10;                # 구 스키마 호환: {&quot;decision&quot;: &quot;...&quot;, &quot;reason&quot;: &quot;...&quot;}&#10;                decision = str(result.get(&quot;decision&quot;, &quot;hold&quot;)).upper()&#10;                if decision not in [&quot;BUY&quot;, &quot;SELL&quot;, &quot;HOLD&quot;]:&#10;                    decision = &quot;HOLD&quot;&#10;                reason = str(result.get(&quot;reason&quot;, &quot;&quot;))&#10;&#10;            return {&#10;                &quot;source&quot;: &quot;OpenAI&quot;,&#10;                &quot;decision&quot;: decision,&#10;                &quot;reason&quot;: reason,&#10;                &quot;model&quot;: self.openai_model,&#10;                &quot;raw&quot;: result,&#10;                &quot;raw_text&quot;: raw,&#10;            }&#10;        except Exception as e:&#10;            err_msg = str(e)&#10;            log.error(f&quot;OpenAI Error: {err_msg}&quot;)&#10;            if ('model_not_found' in err_msg.lower() or 'does not exist' in err_msg.lower()) and not self._openai_fallback_tried:&#10;                fallback = self._next_openai_fallback(self.openai_model)&#10;                if fallback:&#10;                    log.warning(f&quot;OpenAI model '{self.openai_model}' unavailable. Falling back to '{fallback}'.&quot;)&#10;                    self.openai_model = fallback&#10;                    self._openai_fallback_tried = True&#10;                    return self._ask_openai(system_prompt, user_prompt)&#10;            return {&quot;source&quot;: &quot;OpenAI&quot;, &quot;decision&quot;: &quot;ERROR&quot;, &quot;reason&quot;: err_msg, &quot;model&quot;: self.openai_model}&#10;&#10;    # Gemini에게 질문 메서드&#10;    # TradingDecision JSON 스키마 기준&#10;    # 반환값: (dict) {&quot;source&quot;: &quot;Gemini&quot;, &quot;decision&quot;: &quot;...&quot;, &quot;reason&quot;: &quot;...&quot;}&#10;    # 질문 메서드&#10;    def _ask_gemini(self, system_prompt, user_prompt):&#10;        try:&#10;            # Gemini 모델에 프롬프트 전달&#10;            full_prompt = system_prompt + &quot;\n\n&quot; + user_prompt&#10;&#10;            # Gemini 콘텐츠 생성 API 호출&#10;            # 응답 형식을 JSON으로 지정&#10;            response = self.gemini_model.generate_content(&#10;                full_prompt,&#10;                generation_config={&quot;response_mime_type&quot;: &quot;application/json&quot;}&#10;            )&#10;            raw = response.text&#10;            result = json.loads(raw)&#10;&#10;            decision = &quot;HOLD&quot;&#10;            reason = &quot;&quot;&#10;            target_symbol = getattr(config, &quot;MARKET&quot;, None)&#10;&#10;            # 새 스키마 호환: {&quot;decisions&quot;: [ ... ]}&#10;            decisions = result.get(&quot;decisions&quot;)&#10;            if isinstance(decisions, list) and decisions:&#10;                if target_symbol:&#10;                    target = None&#10;                    for d in decisions:&#10;                        if d.get(&quot;symbol&quot;) == target_symbol:&#10;                            target = d&#10;                            break&#10;                    if target is None:&#10;                        target = decisions[0]&#10;                else:&#10;                    target = decisions[0]&#10;&#10;                # 매매 결정 및 이유 추출&#10;                action = str(target.get(&quot;action&quot;, &quot;HOLD&quot;)).upper()&#10;                decision = action if action in [&quot;BUY&quot;, &quot;SELL&quot;, &quot;HOLD&quot;] else &quot;HOLD&quot;&#10;&#10;                reasoning = target.get(&quot;reasoning&quot;, {})     # 이유 딕셔너리&#10;                summary = reasoning.get(&quot;summary&quot;)          # 요약&#10;                tech = reasoning.get(&quot;technical_factors&quot;)   # 기술적 요인&#10;                risk = reasoning.get(&quot;risk_factors&quot;)        # 리스크 요인&#10;&#10;                parts = []&#10;                if summary:&#10;                    parts.append(str(summary))&#10;                if tech:&#10;                    if isinstance(tech, list):&#10;                        parts.append(&quot;기술적 요인: &quot; + &quot;, &quot;.join(map(str, tech)))&#10;                    else:&#10;                        parts.append(&quot;기술적 요인: &quot; + str(tech))&#10;                if risk:&#10;                    if isinstance(risk, list):&#10;                        parts.append(&quot;리스크 요인: &quot; + &quot;, &quot;.join(map(str, risk)))&#10;                    else:&#10;                        parts.append(&quot;리스크 요인: &quot; + str(risk))&#10;                reason = &quot; | &quot;.join(parts)&#10;            else:&#10;                decision = str(result.get(&quot;decision&quot;, &quot;hold&quot;)).upper()&#10;                if decision not in [&quot;BUY&quot;, &quot;SELL&quot;, &quot;HOLD&quot;]:&#10;                    decision = &quot;HOLD&quot;&#10;                reason = str(result.get(&quot;reason&quot;, &quot;&quot;))&#10;&#10;            return {&#10;                &quot;source&quot;: &quot;Gemini&quot;,&#10;                &quot;decision&quot;: decision,&#10;                &quot;reason&quot;: reason,&#10;                &quot;model&quot;: getattr(self.gemini_model, 'model_name', None),&#10;                &quot;raw&quot;: result,&#10;                &quot;raw_text&quot;: raw,&#10;            }&#10;        except Exception as e:&#10;            log.error(f&quot;Gemini Error: {e}&quot;)&#10;            return {&quot;source&quot;: &quot;Gemini&quot;, &quot;decision&quot;: &quot;ERROR&quot;, &quot;reason&quot;: str(e)}&#10;&#10;    def _augment_with_historical_klines(self, trading_context: dict, max_bars: int = 100):&#10;        &quot;&quot;&quot;Ensure trading context markets[0]['klines'] contains recent candles.&quot;&quot;&quot;&#10;        markets = trading_context.get('markets') or []&#10;        if not markets:&#10;            return trading_context&#10;        market = markets[0]&#10;        klines = market.get('klines') or []&#10;        if isinstance(klines, dict):&#10;            klines = klines.get('candles') or klines.get('history') or []&#10;        if isinstance(klines, str):&#10;            try:&#10;                klines = json.loads(klines)&#10;            except Exception:&#10;                klines = []&#10;        if len(klines) &lt; max_bars:&#10;            fallback = market.get('timeframes', {})&#10;            for tf in fallback.values():&#10;                candidates = tf.get('candles') or tf.get('history') or tf.get('klines')&#10;                if candidates:&#10;                    klines = candidates[-max_bars:]&#10;                    break&#10;        market['klines'] = klines[-max_bars:]&#10;        trading_context['markets'][0] = market&#10;        return trading_context&#10;&#10;    def _extract_confidence(self, result: dict) -&gt; float:&#10;        raw = result.get('raw') if isinstance(result, dict) else None&#10;        if isinstance(raw, str):&#10;            try:&#10;                raw = json.loads(raw)&#10;            except Exception:&#10;                raw = None&#10;        if isinstance(raw, dict):&#10;            decisions = raw.get('decisions')&#10;            if isinstance(decisions, list) and decisions:&#10;                try:&#10;                    conf = float(decisions[0].get('confidence'))&#10;                    if 0 &lt;= conf &lt;= 1:&#10;                        return conf&#10;                except Exception:&#10;                    pass&#10;        try:&#10;            conf = float(result.get('confidence'))&#10;            if 0 &lt;= conf &lt;= 1:&#10;                return conf&#10;        except Exception:&#10;            pass&#10;        return 0.5&#10;&#10;    def _safe_float(self, value):&#10;        try:&#10;            f_val = float(value)&#10;            if f_val == float('inf') or f_val == float('-inf'):&#10;                return None&#10;            return f_val&#10;        except Exception:&#10;            return None&#10;&#10;    def _extract_price_plan(self, result: dict) -&gt; dict | None:&#10;        raw = result.get('raw') if isinstance(result, dict) else None&#10;        if isinstance(raw, str):&#10;            try:&#10;                raw = json.loads(raw)&#10;            except Exception:&#10;                raw = None&#10;        if not isinstance(raw, dict):&#10;            return None&#10;        decisions = raw.get('decisions')&#10;        if not (isinstance(decisions, list) and decisions):&#10;            return None&#10;        target_symbol = getattr(config, 'MARKET', None)&#10;        target = None&#10;        if target_symbol:&#10;            for item in decisions:&#10;                if item.get('symbol') == target_symbol:&#10;                    target = item&#10;                    break&#10;        if target is None:&#10;            target = decisions[0]&#10;        plan = target.get('price_plan') if isinstance(target, dict) else None&#10;        return plan if isinstance(plan, dict) else None&#10;&#10;    def _last_close_from_context(self, trading_context: dict, klines: list | None) -&gt; float:&#10;        markets = trading_context.get('markets') or []&#10;        if markets:&#10;            timeframes = (markets[0].get('timeframes') or {})&#10;            if timeframes:&#10;                tf_key = next(iter(timeframes.keys()), None)&#10;                if tf_key:&#10;                    last_candle = (timeframes[tf_key] or {}).get('last_candle') or {}&#10;                    try:&#10;                        last_close = float(last_candle.get('close') or 0)&#10;                        if last_close &gt; 0:&#10;                            return last_close&#10;                    except Exception:&#10;                        pass&#10;        if klines:&#10;            try:&#10;                last_close = float(klines[-1].get('trade_price') or 0)&#10;                if last_close &gt; 0:&#10;                    return last_close&#10;            except Exception:&#10;                pass&#10;        return float(getattr(config, 'FALLBACK_ENTRY_PRICE', 10000.0))&#10;&#10;    def _derive_price_plan(self, trading_context: dict, klines: list | None, openai_result: dict, gemini_result: dict) -&gt; dict:&#10;        last_close = self._last_close_from_context(trading_context, klines)&#10;        plans = [self._extract_price_plan(openai_result), self._extract_price_plan(gemini_result)]&#10;        plans = [p for p in plans if p]&#10;&#10;        entry_candidates = []&#10;        stop_candidates = []&#10;        take_candidates = []&#10;        factor_candidates = []&#10;&#10;        for plan in plans:&#10;            entry_val = self._safe_float(plan.get('entry_price'))&#10;            stop_val = self._safe_float(plan.get('stop_loss_price'))&#10;            take_val = self._safe_float(plan.get('take_profit_price'))&#10;            factor_val = self._safe_float(plan.get('market_factor'))&#10;&#10;            if entry_val and entry_val &gt; 0:&#10;                entry_candidates.append(entry_val)&#10;            if stop_val and stop_val &gt; 0:&#10;                stop_candidates.append(stop_val)&#10;            if take_val and take_val &gt; 0:&#10;                take_candidates.append(take_val)&#10;            if factor_val is not None:&#10;                factor_candidates.append(max(0.0, min(1.0, factor_val)))&#10;&#10;        if entry_candidates:&#10;            entry_price = sum(entry_candidates) / len(entry_candidates)&#10;        else:&#10;            entry_price = last_close&#10;&#10;        prices = []&#10;        for item in klines or []:&#10;            try:&#10;                prices.append(float(item.get('trade_price') or 0))&#10;            except Exception:&#10;                continue&#10;        if len(prices) &lt; 2:&#10;            prices = [entry_price * 0.99, entry_price]&#10;        recent = prices[-30:]&#10;        diffs = []&#10;        for prev, curr in zip(recent[:-1], recent[1:]):&#10;            if prev:&#10;                diffs.append(abs(curr - prev) / prev)&#10;        avg_move_pct = sum(diffs) / len(diffs) if diffs else 0.01&#10;        avg_move_pct = max(0.003, min(0.05, avg_move_pct * 1.5))&#10;&#10;        if stop_candidates:&#10;            stop_loss_price = max(stop_candidates)&#10;        else:&#10;            stop_loss_price = max(1.0, entry_price * (1 - avg_move_pct))&#10;&#10;        if take_candidates:&#10;            take_profit_price = min(take_candidates)&#10;        else:&#10;            take_profit_price = entry_price * (1 + avg_move_pct * 1.8)&#10;&#10;        stop_loss_price = min(stop_loss_price, entry_price * 0.999)&#10;        take_profit_price = max(take_profit_price, entry_price * 1.001)&#10;&#10;        if factor_candidates:&#10;            market_factor = sum(factor_candidates) / len(factor_candidates)&#10;        else:&#10;            openai_conf = self._extract_confidence(openai_result)&#10;            gemini_conf = self._extract_confidence(gemini_result)&#10;            market_factor = max(0.0, min(1.0, (openai_conf + gemini_conf) / 2))&#10;&#10;        return {&#10;            'entry_price': entry_price,&#10;            'stop_loss_price': stop_loss_price,&#10;            'take_profit_price': take_profit_price,&#10;            'market_factor': market_factor,&#10;        }&#10;&#10;    # 분석 메서드 (앙상블)&#10;    # TradingContext 딕셔너리를 두 AI 모델에 병렬로 전달&#10;    # 각 모델의 결과를 수집하여 앙상블 전략에 따라 최종 매매 결정 생성&#10;    # 반환값: (str) 최종 매매 결정 ('BUY', 'SELL', 'HOLD')&#10;    def analyze(self, trading_context: dict):&#10;        # 최근 100개 캔들 보강&#10;        trading_context = self._augment_with_historical_klines(trading_context, 100)&#10;        # 시스템 및 사용자 프롬프트 생성&#10;        system_prompt = self._get_system_prompt()&#10;        user_prompt = self._get_user_prompt(trading_context)&#10;&#10;        log.info(f&quot;Asking both OpenAI &amp; Gemini simultaneously...&quot;)&#10;&#10;        # 병렬로 두 AI 모델에 질문&#10;        with concurrent.futures.ThreadPoolExecutor() as executor:&#10;            future_openai = executor.submit(self._ask_openai, system_prompt, user_prompt) # OpenAI 질문&#10;            future_gemini = executor.submit(self._ask_gemini, system_prompt, user_prompt) # Gemini 질문&#10;&#10;            result_openai = future_openai.result()&#10;            result_gemini = future_gemini.result()&#10;&#10;        decision_openai = result_openai['decision']&#10;        decision_gemini = result_gemini['decision']&#10;&#10;        log.info(f&quot;[OpenAI] {decision_openai} ({result_openai['reason']})&quot;)&#10;        log.info(f&quot;[Gemini] {decision_gemini} ({result_gemini['reason']})&quot;)&#10;&#10;        final_decision = 'HOLD'&#10;        final_reason = []&#10;&#10;        # 오류 감지 시 기본 HOLD&#10;        if decision_openai == 'ERROR' or decision_gemini == 'ERROR':&#10;            log.warning(&#10;                f&quot;AI error detected. Fallback to HOLD. OpenAI={decision_openai}, Gemini={decision_gemini}&quot;&#10;            )&#10;            final_reason.append(&quot;AI error fallback&quot;)&#10;            result_payload = {&#10;                'decision': 'HOLD',&#10;                'reason': 'AI error fallback',&#10;                'openai': result_openai,&#10;                'gemini': result_gemini,&#10;                'context': trading_context,&#10;                'klines': trading_context.get('markets', [{}])[0].get('klines') if trading_context.get('markets') else None,&#10;            }&#10;            ai_history_store.record(result_payload)&#10;            return result_payload&#10;&#10;        def _ensemble_strategy(action: str) -&gt; str:&#10;            strategy_map = {&#10;                'BUY': getattr(config, 'AI_ENS_BS', config.ENSEMBLE_STRATEGY).upper(),&#10;                'SELL': getattr(config, 'AI_ENS_SS', config.ENSEMBLE_STRATEGY).upper(),&#10;            }&#10;            return strategy_map.get(action, 'UNANIMOUS') or 'UNANIMOUS'&#10;&#10;        def _combo(action: str) -&gt; bool:&#10;            if action not in ('BUY', 'SELL'):&#10;                return False&#10;            strategy = _ensemble_strategy(action)&#10;            votes = [decision_openai == action, decision_gemini == action]&#10;            conf_values = [self._extract_confidence(result_openai), self._extract_confidence(result_gemini)]&#10;            avg_conf = sum(conf_values) / len(conf_values) if conf_values else 0&#10;            threshold = getattr(config, 'AI_ENS_AT', 0.5)&#10;            num_votes = sum(votes)&#10;            total_models = len(votes)&#10;            if strategy == 'UNANIMOUS':&#10;                return all(votes)&#10;            if strategy == 'AVERAGE':&#10;                return avg_conf &gt;= threshold&#10;            if strategy == 'MAJORITY':&#10;                # 과반수 이상이면 통과 (2개 모델 중 1개 이상이면 OK)&#10;                # ceil(total/2) = 과반수 기준&#10;                majority_threshold = (total_models + 1) // 2  # 2개면 1개 필요, 3개면 2개 필요&#10;                return num_votes &gt;= majority_threshold&#10;            return False&#10;&#10;        if _combo('BUY'):&#10;            final_decision = 'BUY'&#10;            final_reason.append('AI ensemble BUY confirmation')&#10;        elif _combo('SELL'):&#10;            final_decision = 'SELL'&#10;            final_reason.append('AI ensemble SELL confirmation')&#10;        else:&#10;            final_reason.append('AI ensemble HOLD (no consensus)')&#10;&#10;        final_reason.append(f&quot;Final decision {final_decision}&quot;)&#10;        primary_market = None&#10;        try:&#10;            markets = trading_context.get('markets', [])&#10;            if markets:&#10;                primary_market = markets[0]&#10;        except Exception:&#10;            primary_market = None&#10;&#10;        market_klines = (primary_market or {}).get('klines') if primary_market else None&#10;        price_plan = self._derive_price_plan(trading_context, market_klines, result_openai, result_gemini)&#10;&#10;        result_payload = {&#10;            'decision': final_decision,&#10;            'reason': ' | '.join(final_reason) if final_reason else '',&#10;            'openai': result_openai,&#10;            'gemini': result_gemini,&#10;            'context': trading_context,&#10;            'klines': market_klines,&#10;            'price_plan': price_plan,&#10;        }&#10;        ai_history_store.record(result_payload)&#10;        return result_payload&#10;" />
              <option name="updatedContent" value="import json&#10;import concurrent.futures&#10;import server.config as config&#10;from server.logger import log&#10;from server.history import ai_history_store&#10;from datetime import datetime, timezone, timedelta&#10;import math&#10;&#10;# OpenAI SDK&#10;# Defensive imports&#10;try:&#10;    import openai&#10;except Exception:&#10;    openai = None&#10;&#10;# Gemini SDK&#10;# Defensive imports&#10;try:&#10;    import google.generativeai as genai&#10;except Exception:&#10;    genai = None&#10;&#10;# AI 자문 앙상블 분석기 클래스&#10;# OpenAI와 Gemini 모델을 병렬로 호출하여 TradingContext에 대한 TradingDecision을 생성&#10;# 두 모델의 출력을 결합하여 최종 매매 결정을 내림&#10;# OpenAI 또는 Gemini SDK가 설치되지 않았거나 API 키가 제공되지 않은 경우에도&#10;# 모듈이 정상적으로 임포트되며 분석기는 안전한 동작('HOLD' 반환)으로 대체됨&#10;class EnsembleAnalyzer:&#10;&#10;    # 초기화 메서드&#10;    def __init__(self):&#10;        # 멤버 변수 초기화&#10;        self.openai_client = None&#10;        self.openai_model = None&#10;        self.gemini_model = None&#10;        self._openai_fallback_tried = False&#10;&#10;        # 1. OpenAI 초기화 (가능한 경우)&#10;        if openai is None:&#10;            log.warning(&quot;OpenAI SDK not installed; AI ensemble disabled for OpenAI.&quot;)&#10;        else:&#10;            try:&#10;                if not getattr(config, 'OPENAI_API_KEY', None):&#10;                    log.warning('OPENAI_API_KEY missing in config; OpenAI disabled.')&#10;                else:&#10;                    # 우선: OpenAI client 인스턴스 생성 시도&#10;                    # 참고: openai.OpenAI()는 openai 패키지 버전 0.27.0 이상에서 지원&#10;                    # 그 이하 버전에서는 openai.api_key 설정 방식으로 동작&#10;                    # 따라서 두 방식을 모두 시도&#10;                    try:&#10;                        self.openai_client = openai.OpenAI(api_key=config.OPENAI_API_KEY) # 클라이언트 인스턴스&#10;                    except Exception:&#10;                        try:&#10;                            openai.api_key = config.OPENAI_API_KEY # 전역 설정&#10;                            self.openai_client = openai # 패키지 자체를 클라이언트로 사용&#10;                        except Exception as e:&#10;                            log.warning(f'Failed to init OpenAI client: {e}')&#10;                    self.openai_model = getattr(config, 'OPENAI_MODEL', None) or self._default_openai_model()&#10;&#10;            except Exception as e:&#10;                log.warning(f'Failed to init OpenAI client: {e}')&#10;&#10;        # 2. Gemini 초기화 (가능한 경우)&#10;        if genai is None:&#10;            log.warning(&quot;Gemini SDK not installed; AI ensemble disabled for Gemini.&quot;)&#10;        else:&#10;            try:&#10;                if not getattr(config, 'GEMINI_API_KEY', None):&#10;                    log.warning('GEMINI_API_KEY missing in config; Gemini disabled.')&#10;                else:&#10;                    # Gemini 클라이언트 구성&#10;                    genai.configure(api_key=config.GEMINI_API_KEY) # 전역 구성&#10;                    self.gemini_model = genai.GenerativeModel(getattr(config, 'GEMINI_MODEL', None)) # 모델 인스턴스&#10;            except Exception as e:&#10;                log.warning(f'Failed to init Gemini client: {e}')&#10;&#10;    def _default_openai_model(self):&#10;        return 'o4-mini'&#10;&#10;    def _next_openai_fallback(self, current_model: str | None):&#10;        preferred = [&#10;            getattr(config, 'OPENAI_FALLBACK_MODEL', None),&#10;            'gpt-5-mini',&#10;            'gpt-5-nano',&#10;        ]&#10;        for cand in preferred:&#10;            if cand and cand != current_model:&#10;                return cand&#10;        return None&#10;&#10;    # 시스템 프롬프트 생성 메서드&#10;    # OpenAI 및 Gemini에 동일한 시스템 프롬프트 사용&#10;    # 생성된 시스템 프롬프트는 업비트 현물 계좌 운용 퀀트 트레이더 AI 역할을 정의&#10;    # TradingContext 입력 데이터 구조와 TradingDecision 출력 스키마를 상세히 명시&#10;    # 또한, 매매 판단 원칙과 제약조건을 구체적으로 기술&#10;    # 반환값: (str) 시스템 프롬프트 텍스트&#10;    def _get_system_prompt(self):&#10;        return &quot;&quot;&quot;&#10;        너는 업비트(UPBIT) 현물 계좌를 운용하는 퀀트/시스템 트레이더 AI다.&#10;&#10;        [환경]&#10;        - 거래소: 업비트(UPBIT)&#10;        - 상품: 현물(Spot)만, 마진·선물·레버리지·공매도 없음&#10;        - 통화단위: KRW 기준, 모든 금액은 KRW라고 가정한다.&#10;&#10;        [입력 데이터: TradingContext JSON]&#10;        - meta: 거래소, 마켓 타입, 기준 시각, 전략 이름, 루프 주기 등 메타정보&#10;        - constraints: 1회 주문 최대 금액, 최소 주문 금액, 레버리지/공매도 불가 여부 등 제약조건&#10;        - account: 총자산, 가용 현금, 보유 포지션 목록, 미체결 주문 목록&#10;        - markets[]:&#10;          - symbol: 예) &quot;KRW-BTC&quot;&#10;          - base / quote: 베이스·쿼트 자산&#10;          - day_change_pct, day_volume_krw: 일간 등락률과 거래대금(있을 경우)&#10;          - timeframes[&lt;타임프레임&gt;]:&#10;              - last_candle: 시가/고가/저가/종가/거래량&#10;              - indicators: RSI, 볼린저밴드, 이동평균, MACD 등 기술지표와 최근 종가 시퀀스&#10;          - orderbook: 최상위 매수/매도 호가 및 잔량 정보(있을 경우)&#10;          - position: 해당 심볼에 대한 보유 수량·평단가·평가금액 등 (있을 경우)&#10;&#10;        [출력: TradingDecision JSON ONLY]&#10;        항상 아래 스키마를 따르는 하나의 JSON 객체만 반환한다.&#10;        JSON 바깥에 자연어 문장, 코드블록, 설명 텍스트를 절대 추가하지 마라.&#10;&#10;        {&#10;          &quot;decisions&quot;: [&#10;            {&#10;              &quot;symbol&quot;: &quot;KRW-BTC&quot;,&#10;              &quot;timeframe&quot;: &quot;&lt;분석에 주로 사용한 타임프레임 문자열&gt;&quot;,&#10;              &quot;action&quot;: &quot;BUY&quot; | &quot;SELL&quot; | &quot;HOLD&quot;,&#10;              &quot;confidence&quot;: 0.0,&#10;              &quot;size_krw&quot;: 0.0,&#10;              &quot;reasoning&quot;: {&#10;                &quot;technical_factors&quot;: [&quot;요인1&quot;, &quot;요인2&quot;],&#10;                &quot;orderbook_factors&quot;: [&quot;요인1&quot;],&#10;                &quot;risk_factors&quot;: [&quot;손절·변동성·과도한 집중 등의 위험&quot;],&#10;                &quot;summary&quot;: &quot;최종 판단을 한두 문장으로 요약&quot;&#10;              },&#10;              &quot;risk_management&quot;: {&#10;                &quot;stop_loss&quot;: &quot;예: 15분봉 종가 기준 -3% 하락 시 전량 손절&quot;,&#10;                &quot;take_profit&quot;: &quot;예: 단기 저항선 또는 +5~8% 구간에서 분할 매도&quot;,&#10;                &quot;notes&quot;: &quot;추가로 주의해야 할 사항&quot;&#10;              },&#10;              &quot;price_plan&quot;: {&#10;                &quot;entry_price&quot;: 0.0,&#10;                &quot;stop_loss_price&quot;: 0.0,&#10;                &quot;take_profit_price&quot;: 0.0,&#10;                &quot;market_factor&quot;: 0.0&#10;              }&#10;            }&#10;          ],&#10;          &quot;portfolio_comment&quot;: &quot;현재 계좌 전체 관점에서의 리스크, 현금비중, 분산상태 코멘트&quot;,&#10;          &quot;risk_flags&quot;: [&#10;            {&quot;type&quot;: &quot;MAX_DRAWDOWN&quot;, &quot;severity&quot;: &quot;LOW|MEDIUM|HIGH&quot;, &quot;message&quot;: &quot;...&quot;}&#10;          ]&#10;        }&#10;&#10;        [추가 지침]&#10;        - 각 decision.price_plan의 수치는 반드시 숫자로만 채워라.&#10;        - entry_price, stop_loss_price, take_profit_price는 KRW 단위이며 최근 시세와 일관되게 산출한다.&#10;        - market_factor는 0.0~1.0 범위에서 현재 시장의 공격적/보수적 정도를 나타내는 실수다.&#10;        - stop_loss_price는 entry_price보다 낮아야 하며, take_profit_price는 entry_price보다 높아야 한다.&#10;        - price_plan 정보를 반드시 포함시켜 downstream 시스템이 직접 활용할 수 있게 한다.&#10;&#10;        [판단 원칙]&#10;        1. 업비트 현물 계좌 특성을 지켜라.&#10;           - 레버리지, 공매도, 공매수/공매도 스왑 등은 절대 제안하지 않는다.&#10;           - 보유 중인 수량보다 큰 매도, 마이너스 수량이 되는 주문은 금지.&#10;        2. 제약조건(constraints)을 항상 존중한다.&#10;           - size_krw는 min_order_krw 이상이어야 하며 per_trade_max_krw를 넘지 않는다.&#10;           - 계좌의 available_krw를 넘는 매수는 제안하지 않는다.&#10;        3. &quot;HOLD&quot;는 다음과 같은 경우 기본 선택이다.&#10;           - 추세가 애매하거나 지표가 서로 상충될 때&#10;           - 스프레드·호가 잔량이 비정상적으로 왜곡돼 있을 때&#10;           - 방금 직전에 매매가 일어났고 충분한 새로운 정보가 쌓이지 않았을 때&#10;        4. 이미 포지션이 있을 때:&#10;           - 뚜렷한 추세 전환·과열/과매도 신호·리스크 급증 시에만 SELL을 제안한다.&#10;           - 단순한 단기 노이즈, 작은 조정에는 HOLD를 권장한다.&#10;        5. 항상 계좌 전체 리스크를 고려해 보수적으로 의사결정을 내린다.&#10;        &quot;&quot;&quot;&#10;&#10;    # 사용자 프롬프트 생성 메서드&#10;    # TradingContext 딕셔너리를 JSON 문자열로 직렬화하여 포함&#10;    # 생성된 사용자 프롬프트는 시스템 프롬프트와 함께 AI 모델에 전달됨&#10;    # TradingContext 딕셔너리를 JSON 문자열로 직렬화하여 포함&#10;    # 반환값: (str) 사용자 프롬프트 텍스트&#10;    def _get_user_prompt(self, trading_context: dict):&#10;        &quot;&quot;&quot;TradingContext dict를 그대로 JSON 문자열로 직렬화해서 보낸다.&quot;&quot;&quot;&#10;        try:&#10;            context_json = json.dumps(trading_context, ensure_ascii=False)&#10;        except Exception as e:&#10;            log.error(f&quot;Failed to serialize trading_context for AI: {e}&quot;)&#10;            context_json = json.dumps({&quot;error&quot;: &quot;serialization_failed&quot;})&#10;&#10;        return f&quot;&quot;&quot;&#10;        아래는 현재 업비트 계좌 상태와 시세/기술지표/호가 정보로 구성된 TradingContext JSON이다.&#10;        &#10;        이 데이터를 바탕으로, 시스템 프롬프트의 규칙과 출력 형식을 엄격히 지키면서&#10;        매 종목에 대한 매매 판단과 주문/리스크 관리 계획을 포함하는 TradingDecision JSON을 생성해라.&#10;        &#10;        반드시 JSON만 출력하고, JSON 바깥에 다른 문장은 쓰지 마라.&#10;        &#10;        TradingContext:&#10;        {context_json}&#10;        &quot;&quot;&quot;&#10;&#10;    # OpenAI에게 질문 메서드&#10;    # TradingDecision JSON 스키마 기준&#10;    # 반환값: (dict) {&quot;source&quot;: &quot;OpenAI&quot;, &quot;decision&quot;: &quot;...&quot;, &quot;reason&quot;: &quot;...&quot;}&#10;    def _ask_openai(self, system_prompt, user_prompt):&#10;        if not self.openai_client or not self.openai_model:&#10;            log.warning('OpenAI client or model not initialized; skipping request.')&#10;            return {&quot;source&quot;: &quot;OpenAI&quot;, &quot;decision&quot;: &quot;ERROR&quot;, &quot;reason&quot;: &quot;client_not_initialized&quot;}&#10;        try:&#10;            # OpenAI ChatCompletion API 호출&#10;            response = self.openai_client.chat.completions.create(&#10;                model=self.openai_model,                            # 모델 이름&#10;                messages=[&#10;                    {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: system_prompt},&#10;                    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: user_prompt}&#10;                ],                                                  # 메시지 목록&#10;                response_format={&quot;type&quot;: &quot;json_object&quot;}             # 응답 형식 지정&#10;            )&#10;            raw = response.choices[0].message.content # 응답 원문&#10;            result = json.loads(raw) # JSON 파싱&#10;&#10;            decision = &quot;HOLD&quot;&#10;            reason = &quot;&quot;&#10;            target_symbol = getattr(config, &quot;MARKET&quot;, None) # 타겟 심볼 설정&#10;&#10;            # 새 스키마 호환: {&quot;decisions&quot;: [ ... ]}&#10;            decisions = result.get(&quot;decisions&quot;)&#10;            if isinstance(decisions, list) and decisions:&#10;                if target_symbol:&#10;                    target = None&#10;                    for d in decisions:&#10;                        if d.get(&quot;symbol&quot;) == target_symbol:&#10;                            target = d&#10;                            break&#10;                    if target is None:&#10;                        target = decisions[0]&#10;                else:&#10;                    target = decisions[0]&#10;&#10;                # 매매 결정 및 이유 추출&#10;                action = str(target.get(&quot;action&quot;, &quot;HOLD&quot;)).upper()&#10;                decision = action if action in [&quot;BUY&quot;, &quot;SELL&quot;, &quot;HOLD&quot;] else &quot;HOLD&quot;&#10;&#10;                reasoning = target.get(&quot;reasoning&quot;, {})     # 이유 딕셔너리&#10;                summary = reasoning.get(&quot;summary&quot;)          # 요약&#10;                tech = reasoning.get(&quot;technical_factors&quot;)   # 기술적 요인&#10;                risk = reasoning.get(&quot;risk_factors&quot;)        # 리스크 요인&#10;&#10;                parts = []&#10;                # 이유 구성&#10;                if summary:&#10;                    parts.append(str(summary))&#10;                if tech:&#10;                    if isinstance(tech, list):&#10;                        parts.append(&quot;기술적 요인: &quot; + &quot;, &quot;.join(map(str, tech)))&#10;                    else:&#10;                        parts.append(&quot;기술적 요인: &quot; + str(tech))&#10;                if risk:&#10;                    if isinstance(risk, list):&#10;                        parts.append(&quot;리스크 요인: &quot; + &quot;, &quot;.join(map(str, risk)))&#10;                    else:&#10;                        parts.append(&quot;리스크 요인: &quot; + str(risk))&#10;                reason = &quot; | &quot;.join(parts)&#10;            else:&#10;                # 구 스키마 호환: {&quot;decision&quot;: &quot;...&quot;, &quot;reason&quot;: &quot;...&quot;}&#10;                decision = str(result.get(&quot;decision&quot;, &quot;hold&quot;)).upper()&#10;                if decision not in [&quot;BUY&quot;, &quot;SELL&quot;, &quot;HOLD&quot;]:&#10;                    decision = &quot;HOLD&quot;&#10;                reason = str(result.get(&quot;reason&quot;, &quot;&quot;))&#10;&#10;            return {&#10;                &quot;source&quot;: &quot;OpenAI&quot;,&#10;                &quot;decision&quot;: decision,&#10;                &quot;reason&quot;: reason,&#10;                &quot;model&quot;: self.openai_model,&#10;                &quot;raw&quot;: result,&#10;                &quot;raw_text&quot;: raw,&#10;            }&#10;        except Exception as e:&#10;            err_msg = str(e)&#10;            log.error(f&quot;OpenAI Error: {err_msg}&quot;)&#10;            if ('model_not_found' in err_msg.lower() or 'does not exist' in err_msg.lower()) and not self._openai_fallback_tried:&#10;                fallback = self._next_openai_fallback(self.openai_model)&#10;                if fallback:&#10;                    log.warning(f&quot;OpenAI model '{self.openai_model}' unavailable. Falling back to '{fallback}'.&quot;)&#10;                    self.openai_model = fallback&#10;                    self._openai_fallback_tried = True&#10;                    return self._ask_openai(system_prompt, user_prompt)&#10;            return {&quot;source&quot;: &quot;OpenAI&quot;, &quot;decision&quot;: &quot;ERROR&quot;, &quot;reason&quot;: err_msg, &quot;model&quot;: self.openai_model}&#10;&#10;    # Gemini에게 질문 메서드&#10;    # TradingDecision JSON 스키마 기준&#10;    # 반환값: (dict) {&quot;source&quot;: &quot;Gemini&quot;, &quot;decision&quot;: &quot;...&quot;, &quot;reason&quot;: &quot;...&quot;}&#10;    # 질문 메서드&#10;    def _ask_gemini(self, system_prompt, user_prompt):&#10;        try:&#10;            # Gemini 모델에 프롬프트 전달&#10;            full_prompt = system_prompt + &quot;\n\n&quot; + user_prompt&#10;&#10;            # Gemini 콘텐츠 생성 API 호출&#10;            # 응답 형식을 JSON으로 지정&#10;            response = self.gemini_model.generate_content(&#10;                full_prompt,&#10;                generation_config={&quot;response_mime_type&quot;: &quot;application/json&quot;}&#10;            )&#10;            raw = response.text&#10;            result = json.loads(raw)&#10;&#10;            decision = &quot;HOLD&quot;&#10;            reason = &quot;&quot;&#10;            target_symbol = getattr(config, &quot;MARKET&quot;, None)&#10;&#10;            # 새 스키마 호환: {&quot;decisions&quot;: [ ... ]}&#10;            decisions = result.get(&quot;decisions&quot;)&#10;            if isinstance(decisions, list) and decisions:&#10;                if target_symbol:&#10;                    target = None&#10;                    for d in decisions:&#10;                        if d.get(&quot;symbol&quot;) == target_symbol:&#10;                            target = d&#10;                            break&#10;                    if target is None:&#10;                        target = decisions[0]&#10;                else:&#10;                    target = decisions[0]&#10;&#10;                # 매매 결정 및 이유 추출&#10;                action = str(target.get(&quot;action&quot;, &quot;HOLD&quot;)).upper()&#10;                decision = action if action in [&quot;BUY&quot;, &quot;SELL&quot;, &quot;HOLD&quot;] else &quot;HOLD&quot;&#10;&#10;                reasoning = target.get(&quot;reasoning&quot;, {})     # 이유 딕셔너리&#10;                summary = reasoning.get(&quot;summary&quot;)          # 요약&#10;                tech = reasoning.get(&quot;technical_factors&quot;)   # 기술적 요인&#10;                risk = reasoning.get(&quot;risk_factors&quot;)        # 리스크 요인&#10;&#10;                parts = []&#10;                if summary:&#10;                    parts.append(str(summary))&#10;                if tech:&#10;                    if isinstance(tech, list):&#10;                        parts.append(&quot;기술적 요인: &quot; + &quot;, &quot;.join(map(str, tech)))&#10;                    else:&#10;                        parts.append(&quot;기술적 요인: &quot; + str(tech))&#10;                if risk:&#10;                    if isinstance(risk, list):&#10;                        parts.append(&quot;리스크 요인: &quot; + &quot;, &quot;.join(map(str, risk)))&#10;                    else:&#10;                        parts.append(&quot;리스크 요인: &quot; + str(risk))&#10;                reason = &quot; | &quot;.join(parts)&#10;            else:&#10;                decision = str(result.get(&quot;decision&quot;, &quot;hold&quot;)).upper()&#10;                if decision not in [&quot;BUY&quot;, &quot;SELL&quot;, &quot;HOLD&quot;]:&#10;                    decision = &quot;HOLD&quot;&#10;                reason = str(result.get(&quot;reason&quot;, &quot;&quot;))&#10;&#10;            return {&#10;                &quot;source&quot;: &quot;Gemini&quot;,&#10;                &quot;decision&quot;: decision,&#10;                &quot;reason&quot;: reason,&#10;                &quot;model&quot;: getattr(self.gemini_model, 'model_name', None),&#10;                &quot;raw&quot;: result,&#10;                &quot;raw_text&quot;: raw,&#10;            }&#10;        except Exception as e:&#10;            log.error(f&quot;Gemini Error: {e}&quot;)&#10;            return {&quot;source&quot;: &quot;Gemini&quot;, &quot;decision&quot;: &quot;ERROR&quot;, &quot;reason&quot;: str(e)}&#10;&#10;    def _augment_with_historical_klines(self, trading_context: dict, max_bars: int = 100):&#10;        &quot;&quot;&quot;Ensure trading context markets[0]['klines'] contains recent candles.&quot;&quot;&quot;&#10;        markets = trading_context.get('markets') or []&#10;        if not markets:&#10;            return trading_context&#10;        market = markets[0]&#10;        klines = market.get('klines') or []&#10;        if isinstance(klines, dict):&#10;            klines = klines.get('candles') or klines.get('history') or []&#10;        if isinstance(klines, str):&#10;            try:&#10;                klines = json.loads(klines)&#10;            except Exception:&#10;                klines = []&#10;        if len(klines) &lt; max_bars:&#10;            fallback = market.get('timeframes', {})&#10;            for tf in fallback.values():&#10;                candidates = tf.get('candles') or tf.get('history') or tf.get('klines')&#10;                if candidates:&#10;                    klines = candidates[-max_bars:]&#10;                    break&#10;        market['klines'] = klines[-max_bars:]&#10;        trading_context['markets'][0] = market&#10;        return trading_context&#10;&#10;    def _extract_confidence(self, result: dict) -&gt; float:&#10;        raw = result.get('raw') if isinstance(result, dict) else None&#10;        if isinstance(raw, str):&#10;            try:&#10;                raw = json.loads(raw)&#10;            except Exception:&#10;                raw = None&#10;        if isinstance(raw, dict):&#10;            decisions = raw.get('decisions')&#10;            if isinstance(decisions, list) and decisions:&#10;                try:&#10;                    conf = float(decisions[0].get('confidence'))&#10;                    if 0 &lt;= conf &lt;= 1:&#10;                        return conf&#10;                except Exception:&#10;                    pass&#10;        try:&#10;            conf = float(result.get('confidence'))&#10;            if 0 &lt;= conf &lt;= 1:&#10;                return conf&#10;        except Exception:&#10;            pass&#10;        return 0.5&#10;&#10;    def _safe_float(self, value):&#10;        try:&#10;            f_val = float(value)&#10;            if f_val == float('inf') or f_val == float('-inf'):&#10;                return None&#10;            return f_val&#10;        except Exception:&#10;            return None&#10;&#10;    def _extract_price_plan(self, result: dict) -&gt; dict | None:&#10;        raw = result.get('raw') if isinstance(result, dict) else None&#10;        if isinstance(raw, str):&#10;            try:&#10;                raw = json.loads(raw)&#10;            except Exception:&#10;                raw = None&#10;        if not isinstance(raw, dict):&#10;            return None&#10;        decisions = raw.get('decisions')&#10;        if not (isinstance(decisions, list) and decisions):&#10;            return None&#10;        target_symbol = getattr(config, 'MARKET', None)&#10;        target = None&#10;        if target_symbol:&#10;            for item in decisions:&#10;                if item.get('symbol') == target_symbol:&#10;                    target = item&#10;                    break&#10;        if target is None:&#10;            target = decisions[0]&#10;        plan = target.get('price_plan') if isinstance(target, dict) else None&#10;        return plan if isinstance(plan, dict) else None&#10;&#10;    def _last_close_from_context(self, trading_context: dict, klines: list | None) -&gt; float:&#10;        markets = trading_context.get('markets') or []&#10;        if markets:&#10;            timeframes = (markets[0].get('timeframes') or {})&#10;            if timeframes:&#10;                tf_key = next(iter(timeframes.keys()), None)&#10;                if tf_key:&#10;                    last_candle = (timeframes[tf_key] or {}).get('last_candle') or {}&#10;                    try:&#10;                        last_close = float(last_candle.get('close') or 0)&#10;                        if last_close &gt; 0:&#10;                            return last_close&#10;                    except Exception:&#10;                        pass&#10;        if klines:&#10;            try:&#10;                last_close = float(klines[-1].get('trade_price') or 0)&#10;                if last_close &gt; 0:&#10;                    return last_close&#10;            except Exception:&#10;                pass&#10;        return float(getattr(config, 'FALLBACK_ENTRY_PRICE', 10000.0))&#10;&#10;    def _derive_price_plan(self, trading_context: dict, klines: list | None, openai_result: dict, gemini_result: dict) -&gt; dict:&#10;        last_close = self._last_close_from_context(trading_context, klines)&#10;        plans = [self._extract_price_plan(openai_result), self._extract_price_plan(gemini_result)]&#10;        plans = [p for p in plans if p]&#10;&#10;        entry_candidates = []&#10;        stop_candidates = []&#10;        take_candidates = []&#10;        factor_candidates = []&#10;&#10;        for plan in plans:&#10;            entry_val = self._safe_float(plan.get('entry_price'))&#10;            stop_val = self._safe_float(plan.get('stop_loss_price'))&#10;            take_val = self._safe_float(plan.get('take_profit_price'))&#10;            factor_val = self._safe_float(plan.get('market_factor'))&#10;&#10;            if entry_val and entry_val &gt; 0:&#10;                entry_candidates.append(entry_val)&#10;            if stop_val and stop_val &gt; 0:&#10;                stop_candidates.append(stop_val)&#10;            if take_val and take_val &gt; 0:&#10;                take_candidates.append(take_val)&#10;            if factor_val is not None:&#10;                factor_candidates.append(max(0.0, min(1.0, factor_val)))&#10;&#10;        if entry_candidates:&#10;            entry_price = sum(entry_candidates) / len(entry_candidates)&#10;        else:&#10;            entry_price = last_close&#10;&#10;        prices = []&#10;        for item in klines or []:&#10;            try:&#10;                prices.append(float(item.get('trade_price') or 0))&#10;            except Exception:&#10;                continue&#10;        if len(prices) &lt; 2:&#10;            prices = [entry_price * 0.99, entry_price]&#10;        recent = prices[-30:]&#10;        diffs = []&#10;        for prev, curr in zip(recent[:-1], recent[1:]):&#10;            if prev:&#10;                diffs.append(abs(curr - prev) / prev)&#10;        avg_move_pct = sum(diffs) / len(diffs) if diffs else 0.01&#10;        avg_move_pct = max(0.003, min(0.05, avg_move_pct * 1.5))&#10;&#10;        if stop_candidates:&#10;            stop_loss_price = max(stop_candidates)&#10;        else:&#10;            stop_loss_price = max(1.0, entry_price * (1 - avg_move_pct))&#10;&#10;        if take_candidates:&#10;            take_profit_price = min(take_candidates)&#10;        else:&#10;            take_profit_price = entry_price * (1 + avg_move_pct * 1.8)&#10;&#10;        stop_loss_price = min(stop_loss_price, entry_price * 0.999)&#10;        take_profit_price = max(take_profit_price, entry_price * 1.001)&#10;&#10;        if factor_candidates:&#10;            market_factor = sum(factor_candidates) / len(factor_candidates)&#10;        else:&#10;            openai_conf = self._extract_confidence(openai_result)&#10;            gemini_conf = self._extract_confidence(gemini_result)&#10;            market_factor = max(0.0, min(1.0, (openai_conf + gemini_conf) / 2))&#10;&#10;        return {&#10;            'entry_price': entry_price,&#10;            'stop_loss_price': stop_loss_price,&#10;            'take_profit_price': take_profit_price,&#10;            'market_factor': market_factor,&#10;        }&#10;&#10;    # 분석 메서드 (앙상블)&#10;    # TradingContext 딕셔너리를 두 AI 모델에 병렬로 전달&#10;    # 각 모델의 결과를 수집하여 앙상블 전략에 따라 최종 매매 결정 생성&#10;    # 반환값: (str) 최종 매매 결정 ('BUY', 'SELL', 'HOLD')&#10;    def analyze(self, trading_context: dict):&#10;        # 최근 100개 캔들 보강&#10;        trading_context = self._augment_with_historical_klines(trading_context, 100)&#10;        # 시스템 및 사용자 프롬프트 생성&#10;        system_prompt = self._get_system_prompt()&#10;        user_prompt = self._get_user_prompt(trading_context)&#10;&#10;        log.info(f&quot;Asking both OpenAI &amp; Gemini simultaneously...&quot;)&#10;&#10;        # 병렬로 두 AI 모델에 질문&#10;        with concurrent.futures.ThreadPoolExecutor() as executor:&#10;            future_openai = executor.submit(self._ask_openai, system_prompt, user_prompt) # OpenAI 질문&#10;            future_gemini = executor.submit(self._ask_gemini, system_prompt, user_prompt) # Gemini 질문&#10;&#10;            result_openai = future_openai.result()&#10;            result_gemini = future_gemini.result()&#10;&#10;        decision_openai = result_openai['decision']&#10;        decision_gemini = result_gemini['decision']&#10;&#10;        log.info(f&quot;[OpenAI] {decision_openai} ({result_openai['reason']})&quot;)&#10;        log.info(f&quot;[Gemini] {decision_gemini} ({result_gemini['reason']})&quot;)&#10;&#10;        final_decision = 'HOLD'&#10;        final_reason = []&#10;&#10;        # 오류 감지 시 기본 HOLD&#10;        if decision_openai == 'ERROR' or decision_gemini == 'ERROR':&#10;            log.warning(&#10;                f&quot;AI error detected. Fallback to HOLD. OpenAI={decision_openai}, Gemini={decision_gemini}&quot;&#10;            )&#10;            final_reason.append(&quot;AI error fallback&quot;)&#10;            result_payload = {&#10;                'decision': 'HOLD',&#10;                'reason': 'AI error fallback',&#10;                'openai': result_openai,&#10;                'gemini': result_gemini,&#10;                'context': trading_context,&#10;                'klines': trading_context.get('markets', [{}])[0].get('klines') if trading_context.get('markets') else None,&#10;            }&#10;            ai_history_store.record(result_payload)&#10;            return result_payload&#10;&#10;        def _ensemble_strategy(action: str) -&gt; str:&#10;            strategy_map = {&#10;                'BUY': getattr(config, 'AI_ENS_BS', config.ENSEMBLE_STRATEGY).upper(),&#10;                'SELL': getattr(config, 'AI_ENS_SS', config.ENSEMBLE_STRATEGY).upper(),&#10;            }&#10;            return strategy_map.get(action, 'UNANIMOUS') or 'UNANIMOUS'&#10;&#10;        def _combo(action: str) -&gt; bool:&#10;            if action not in ('BUY', 'SELL'):&#10;                return False&#10;            strategy = _ensemble_strategy(action)&#10;            votes = [decision_openai == action, decision_gemini == action]&#10;            conf_values = [self._extract_confidence(result_openai), self._extract_confidence(result_gemini)]&#10;            avg_conf = sum(conf_values) / len(conf_values) if conf_values else 0&#10;            threshold = getattr(config, 'AI_ENS_AT', 0.5)&#10;            num_votes = sum(votes)&#10;            total_models = len(votes)&#10;            if strategy == 'UNANIMOUS':&#10;                return all(votes)&#10;            if strategy == 'AVERAGE':&#10;                return avg_conf &gt;= threshold&#10;            if strategy == 'MAJORITY':&#10;                # 과반수 이상이면 통과 (2개 모델 중 1개 이상이면 OK)&#10;                # ceil(total/2) = 과반수 기준&#10;                majority_threshold = (total_models + 1) // 2  # 2개면 1개 필요, 3개면 2개 필요&#10;                return num_votes &gt;= majority_threshold&#10;            return False&#10;&#10;        if _combo('BUY'):&#10;            final_decision = 'BUY'&#10;            final_reason.append('AI ensemble BUY confirmation')&#10;        elif _combo('SELL'):&#10;            final_decision = 'SELL'&#10;            final_reason.append('AI ensemble SELL confirmation')&#10;        else:&#10;            final_reason.append('AI ensemble HOLD (no consensus)')&#10;&#10;        final_reason.append(f&quot;Final decision {final_decision}&quot;)&#10;        primary_market = None&#10;        try:&#10;            markets = trading_context.get('markets', [])&#10;            if markets:&#10;                primary_market = markets[0]&#10;        except Exception:&#10;            primary_market = None&#10;&#10;        market_klines = (primary_market or {}).get('klines') if primary_market else None&#10;        price_plan = self._derive_price_plan(trading_context, market_klines, result_openai, result_gemini)&#10;&#10;        result_payload = {&#10;            'decision': final_decision,&#10;            'reason': ' | '.join(final_reason) if final_reason else '',&#10;            'openai': result_openai,&#10;            'gemini': result_gemini,&#10;            'context': trading_context,&#10;            'klines': market_klines,&#10;            'price_plan': price_plan,&#10;        }&#10;        ai_history_store.record(result_payload)&#10;        return result_payload&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/server/api.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/server/api.py" />
              <option name="originalContent" value="from fastapi import FastAPI, HTTPException # web framework&#10;from contextlib import asynccontextmanager # for lifespan management&#10;from pydantic import BaseModel # data validation, settings management&#10;from typing import Any, Dict, List, Optional # type hints&#10;import threading&#10;import time&#10;import os&#10;&#10;# 시간대 설정&#10;os.environ.setdefault('TZ', 'Asia/Seoul')&#10;try:&#10;    time.tzset()&#10;except Exception:&#10;    pass&#10;&#10;# 외부라이브러리 임포트&#10;import redis # Redis 클라이언트&#10;import json&#10;from concurrent.futures import ThreadPoolExecutor, as_completed # for parallel prefetching&#10;&#10;# 내부API 모듈 임포트&#10;from server import config               # 런타임 설정 관리&#10;from server.upbit_api import UpbitAPI   # 업비트 API 연동&#10;from server.logger import log           # 로깅 설정&#10;from server.history import history_store&#10;from server.history import order_history_store&#10;from server.history import ai_history_store&#10;from server.ws_listener_base import (&#10;    load_ws_stats,&#10;    summarize_ws_stats,&#10;    read_exec_history,&#10;)&#10;from server.ws_listener_private import PrivateWebsocketListener&#10;from server.ws_listener_public import PublicWebsocketlistener&#10;&#10;# Token Bucket 구현 for prefetch&#10;# 간단한 토큰 버킷(rate limiter) 구현&#10;# rate: 초당 토큰 생성 속도&#10;# capacity: 버킷 최대 토큰 수&#10;# consume(tokens, timeout): 지정된 토큰 수를 소비 시도, 타임아웃 내에 성공 여부 반환&#10;# 스레드 안전 구현&#10;# 사용 예시:&#10;# tb = TokenBucket(rate=5, capacity=10)  # 초당 5토큰, 최대 10토큰&#10;# if tb.consume(tokens=1, timeout=2.0):&#10;#     print(&quot;Token acquired&quot;)&#10;# else:&#10;#     print(&quot;Failed to acquire token within timeout&quot;)&#10;class TokenBucket:&#10;    def __init__(self, rate: float, capacity: float):&#10;        self.rate = float(rate)         # 토큰 생성 속도 (초당)&#10;        self.capacity = float(capacity) # 버킷 최대 용량&#10;        self._tokens = float(capacity)  # 현재 토큰 수&#10;        self._last = time.time()        # 마지막 토큰 갱신 시각&#10;        self._lock = threading.Lock()   # 스레드 안전을 위한 락&#10;&#10;    # 토큰 소비 메서드&#10;    # tokens: 소비할 토큰 수&#10;    # timeout: 최대 대기 시간 (초)&#10;    # 반환값: 성공 시 True, 실패 시 False&#10;    def consume(self, tokens: float = 1.0, timeout: float = 5.0) -&gt; bool:&#10;        end = time.time() + float(timeout)&#10;        while time.time() &lt; end:&#10;            with self._lock:&#10;                now = time.time()&#10;                elapsed = max(0.0, now - self._last)&#10;                self._tokens = min(self.capacity, self._tokens + elapsed * self.rate)&#10;                self._last = now&#10;                if self._tokens &gt;= tokens:&#10;                    self._tokens -= tokens&#10;                    return True&#10;            time.sleep(0.01)&#10;        return False&#10;&#10;&#10;# 세마포어 및 토큰 버킷 초기화 (스케줄러 시작 시)&#10;_prefetch_token_bucket: Optional[TokenBucket] = None&#10;_prefetch_semaphore: Optional[threading.BoundedSemaphore] = None&#10;&#10;# 기본 klines 캐시 TTL (초)&#10;# 환경변수 'KLINES_CACHE_TTL'로 설정 가능, 기본값 600초&#10;# 예: os.environ['KLINES_CACHE_TTL'] = '600'&#10;# (기본값 600초로 설정하여 중복 Upbit 요청 감소, 실시간성은 다소 희생, 값이 클수록 캐시 지속시간 증가)&#10;_KLINES_CACHE_TTL = int(os.getenv('KLINES_CACHE_TTL', str(600)))  # default 600s&#10;&#10;# Balances cache TTL (seconds)&#10;_BALANCES_CACHE_TTL = int(os.getenv('BALANCES_CACHE_TTL', '15'))&#10;&#10;# FastAPI 앱 생성 및 수명 주기 관리&#10;@asynccontextmanager&#10;async def lifespan(app: FastAPI): # 수명 주기 관리&#10;    # start prefetch scheduler on startup&#10;    try:&#10;        # read interval from config, default 30s&#10;        # if invalid, fallback to 30s&#10;        # prefetch interval 설정&#10;        # 기본값 30초&#10;        # 환경변수나 config.json의 'prefetch_interval_sec' 키로 설정 가능&#10;        interval = int(config._config.get('prefetch_interval_sec', 30))&#10;    except Exception:&#10;        interval = 30&#10;&#10;    # 스케쥴러 시작&#10;    start_prefetch_scheduler(interval=interval)&#10;    try:&#10;        start_ws_listener()&#10;        start_ticker_listener()&#10;    except Exception as exc:&#10;        log.warning(f'Failed to start websocket listener on startup: {exc}')&#10;    try:&#10;        yield&#10;    finally:&#10;        # 스케쥴러 중지&#10;        stop_prefetch_scheduler()&#10;        stop_ws_listener()&#10;        stop_ticker_listener()&#10;&#10;app = FastAPI(title=&quot;Upbit Trader Runtime API&quot;, lifespan=lifespan) # FastAPI 앱 생성&#10;&#10;# 데이터 모델 정의&#10;class ConfigPayload(BaseModel):&#10;    config: Dict[str, Any]&#10;&#10;# 배치 klines 요청 모델&#10;class KlinesBatchRequest(BaseModel):&#10;    tickers: List[str]&#10;    timeframe: Optional[str] = 'minute15'&#10;    count: Optional[int] = 100&#10;&#10;# 포지션 모델 정의&#10;class Position(BaseModel):&#10;    ticker: str&#10;    amount: float&#10;    avg_price: float&#10;    current_price: float&#10;    pnl: float&#10;&#10;# --- Background Prefetch Scheduler 및 캐시 관리 ---&#10;# 전역 상태 변수들&#10;# Prefetch 스레드 및 제어 변수&#10;# Simple in-memory watcher state (explicit typing to satisfy linters)&#10;_watcher: Dict[str, Any] = {&#10;    'running': False,&#10;    'thread': None,&#10;    'stop_event': None,&#10;}&#10;&#10;# 캐시 딕셔너리&#10;# Simple in-memory cache for batch klines: { key: (timestamp, data) }&#10;_klines_cache: Dict[str, Any] = {}&#10;&#10;&#10;# 레디스(Redis) 클라이언트 초기화&#10;# Redis setup (optional). Use local redis://localhost:6379 if REDIS_URL not set&#10;# 환경변수 'REDIS_URL'로 Redis URL 설정 가능&#10;REDIS_URL = os.getenv('REDIS_URL', 'redis://localhost:6379/0')&#10;_redis_client = None&#10;try:&#10;    # Redis 클라이언트 생성 및 연결 테스트&#10;    _redis_client = redis.from_url(REDIS_URL, decode_responses=True)&#10;    # ping 테스트&#10;    _redis_client.ping()&#10;    log.info(f'Redis cache connected: {REDIS_URL}')&#10;except Exception as e:&#10;    _redis_client = None&#10;    log.warning(f'Redis not available ({REDIS_URL}): {e}. Falling back to in-memory cache')&#10;&#10;# 캐시 설정 함수&#10;# key: 캐시 키&#10;# value: 캐시 값&#10;# ttl: 캐시 만료 시간 (초)&#10;# 기본 TTL은 _KLINES_CACHE_TTL 사용&#10;# Redis 사용 가능 시 Redis에 저장, 아니면 메모리 내 딕셔너리에 저장&#10;# 캐시 조회 시 만료 시간 확인&#10;# 반환값: (타임스탬프, 값) 또는 None&#10;def _cache_set(key: str, value: Any, ttl: int = _KLINES_CACHE_TTL):&#10;    &quot;&quot;&quot;Set cache in Redis if available, else in-memory.&quot;&quot;&quot;&#10;    now = time.time()&#10;    if _redis_client:&#10;        try:&#10;            # store JSON string&#10;            import json as _json&#10;            payload = {'ts': now, 'value': value}&#10;            _redis_client.setex(key, ttl, _json.dumps(payload)) # set with expiry&#10;            return&#10;        except Exception:&#10;            pass&#10;    _klines_cache[key] = (now, value) # store in-memory&#10;&#10;# 캐시 조회 함수&#10;# key: 캐시 키&#10;# ttl: 캐시 만료 시간 (초)&#10;# 기본 TTL은 _KLINES_CACHE_TTL 사용&#10;# 반환값: (타임스탬프, 값) 또는 None&#10;def _cache_get(key: str, ttl: int = _KLINES_CACHE_TTL):&#10;    &quot;&quot;&quot;Get cache value. Return (timestamp, value) or None.&quot;&quot;&quot;&#10;    if _redis_client:&#10;        try:&#10;            import json as _json&#10;            s = _redis_client.get(key) # get JSON string&#10;            if not s:&#10;                return None&#10;            obj = _json.loads(s) # parse JSON&#10;            if time.time() - obj.get('ts', 0) &gt; ttl:&#10;                return None&#10;            return (obj.get('ts'), obj.get('value')) # return (timestamp, value)&#10;        except Exception:&#10;            return None&#10;    return _klines_cache.get(key) # return (timestamp, value) or None&#10;&#10;# Websocket listener state&#10;_ws_listener: Optional[PrivateWebsocketListener] = None&#10;_ticker_listener: Optional[PublicWebsocketlistener] = None&#10;&#10;def start_ws_listener() -&gt; None:&#10;    global _ws_listener&#10;    if _ws_listener and _ws_listener._thread and _ws_listener._thread.is_alive():&#10;        return&#10;    _ws_listener = PrivateWebsocketListener(redis_client=_redis_client)&#10;    _ws_listener.start()&#10;&#10;&#10;def start_ticker_listener() -&gt; None:&#10;    global _ticker_listener&#10;    if _ticker_listener and _ticker_listener._thread and _ticker_listener._thread.is_alive():&#10;        return&#10;    _ticker_listener = PublicWebsocketlistener(redis_client=_redis_client)&#10;    _ticker_listener.start()&#10;&#10;&#10;def stop_ws_listener() -&gt; None:&#10;    global _ws_listener&#10;    if _ws_listener:&#10;        _ws_listener.stop()&#10;&#10;&#10;def stop_ticker_listener() -&gt; None:&#10;    global _ticker_listener&#10;    if _ticker_listener:&#10;        _ticker_listener.stop()&#10;&#10;# Rate-limited Upbit klines fetcher&#10;# ticker_local: 업비트 로컬 티커명 (예: KRW-BTC)&#10;# timeframe: 캔들 시간대 (예: 'minute15')&#10;# count: 조회할 캔들 개수&#10;# 반환값: UpbitAPI.get_klines() 결과&#10;# 전역 토큰 버킷 및 세마포어를 사용하여 호출 제한 및 동시성 제어&#10;# 토큰 획득 및 세마포어 획득 시 타임아웃 처리&#10;# 예외 발생 시 호출 실패&#10;# 반환값: UpbitAPI.get_klines() 결과&#10;def _rate_limited_get_klines(ticker_local: str, timeframe: str, count: int):&#10;    # 전역 토큰 버킷 및 세마포어 사용&#10;    global _prefetch_token_bucket, _prefetch_semaphore&#10;&#10;    # 세마포어 및 토큰 획득 시도&#10;    # 타임아웃은 config의 'prefetch_token_wait_timeout' 키로 설정 가능, 기본 10초&#10;    # 실제 Upbit 호출 수행&#10;    # 예외 발생 시 호출 실패&#10;    acquired = False&#10;    try:&#10;        # 세마포어 획득 시도&#10;        if _prefetch_semaphore is not None:&#10;            # 세마포어 획득 (대기 시간 설정 기본값 10초)&#10;            acquired = _prefetch_semaphore.acquire(timeout=10)&#10;            if not acquired:&#10;                raise RuntimeError('prefetch_semaphore_timeout')&#10;&#10;        # 토큰 획득 시도&#10;        if _prefetch_token_bucket is not None:&#10;            # 토큰 대기 시간 설정&#10;            # 기본값 10초 (즉시 호출 선호), config의 'prefetch_token_wait_timeout' 키로 설정 가능&#10;            try:&#10;                token_wait = float(config._config.get('prefetch_token_wait_timeout', 10.0))&#10;            except Exception:&#10;                token_wait = 10.0&#10;            ok = _prefetch_token_bucket.consume(tokens=1.0, timeout=token_wait)&#10;            if not ok:&#10;                raise RuntimeError('rate_limited')&#10;        # 업비트 공용 API 호출 수행&#10;        # 반환값: UpbitAPI.get_klines() 결과&#10;        # 참고: UpbitAPI 인스턴스는 전역 _upbit_public 사용&#10;        # 이 인스턴스는 API 키를 사용하지 않음&#10;        return _upbit_public.get_klines(ticker_local, timeframe, count=count)&#10;    finally:&#10;        if acquired and _prefetch_semaphore is not None:&#10;            try:&#10;                _prefetch_semaphore.release() # 세마포어 해제&#10;            except Exception:&#10;                pass&#10;&#10;&#10;# 업비트 공용 API 인스턴스&#10;_upbit_public = UpbitAPI()&#10;&#10;# 업비트 인증(Private) API 인스턴스&#10;try:&#10;    access = getattr(config, 'UPBIT_ACCESS_KEY', None)&#10;    secret = getattr(config, 'UPBIT_SECRET_KEY', None)&#10;    if access and secret:&#10;        _upbit_private = UpbitAPI(access_key=access, secret_key=secret)&#10;        log.info('Upbit private API initialized with provided keys')&#10;    else:&#10;        _upbit_private = None&#10;        log.warning('Upbit API keys not provided: private endpoints will be unavailable')&#10;except Exception as e:&#10;    _upbit_private = None&#10;    log.warning(f'Failed to initialize Upbit private API: {e}')&#10;&#10;# 스케쥴러 스레드 및 제어 변수&#10;_prefetch_thread: Optional[threading.Thread] = None&#10;_prefetch_stop = threading.Event()&#10;_prefetch_index = 0&#10;&#10;# 루프 함수 - 주기적으로 universe의 티커들에 대해 klines를 미리 가져와 캐시에 저장&#10;# interval: 루프 주기 (초)&#10;# 기본값 30초&#10;def _prefetch_loop(interval: int = 30):&#10;    log.info('Prefetch scheduler started')&#10;    effective_interval = interval&#10;    while not _prefetch_stop.is_set():&#10;        try:&#10;            # 설정 읽기&#10;            cfg = config._config&#10;            # 티커 유니버스&#10;            universe = cfg.get('universe', [])&#10;            # 실행 중 설정 체크 (런타임 config에서 재정의 허용)&#10;            cfg_count = int(cfg.get('prefetch_count', 200))&#10;            # Redis 미사용 시 보수적으로 설정, upper bound 허용&#10;            if _redis_client is None:&#10;                # When Redis is missing, be conservative but allow a configurable upper bound&#10;                # Redis 미사용 시 최대값 설정, 기본 120, config의 'prefetch_no_redis_max_count' 키로 설정 가능&#10;                try:&#10;                    no_redis_max = int(cfg.get('prefetch_no_redis_max_count', 120))&#10;                except Exception:&#10;                    no_redis_max = 120&#10;                count = min(cfg_count, no_redis_max)&#10;                per_ticker_sleep = float(cfg.get('prefetch_sleep_sec', 1.0))&#10;                log.info('Redis not available: using conservative prefetch settings (count=%s, sleep=%.2f)', count, per_ticker_sleep)&#10;            else:&#10;                count = cfg_count&#10;                per_ticker_sleep = float(cfg.get('prefetch_sleep_sec', 0.2))&#10;&#10;            # Redis 미사용 시 최소 간격 보장&#10;            effective_interval = interval&#10;            if _redis_client is None:&#10;                effective_interval = max(interval, int(cfg.get('prefetch_min_interval_sec', 60)))&#10;            if universe:&#10;                # staggered batch processing to avoid bursts&#10;                batch_size = int(cfg.get('prefetch_batch_size', 5))     # batch size per run&#10;                parallelism = int(cfg.get('prefetch_parallelism', 3))   # max parallel fetches per batch&#10;                global _prefetch_index&#10;                n = len(universe)&#10;                if n == 0:&#10;                    pass&#10;                else:&#10;                    start = _prefetch_index % n # start index&#10;                    end = start + batch_size    # end index (exclusive)&#10;                    indices = list(range(start, min(end, n)))&#10;                    # wrap-around if needed&#10;                    if end &gt; n:&#10;                        indices += list(range(0, end - n))&#10;                    tickers_to_process = [universe[i] for i in indices]&#10;                    # advance index for next run&#10;                    _prefetch_index = (start + len(tickers_to_process)) % max(n,1)&#10;&#10;                    # helper to fetch and cache single ticker&#10;                    def _prefetch_single(ticker_local: str):&#10;                        try:&#10;                            key_local = f&quot;{ticker_local}|minute15|{count}&quot;&#10;                            cached_local = _cache_get(key_local)&#10;                            if cached_local and (time.time() - cached_local[0]) &lt; _KLINES_CACHE_TTL:&#10;                                return (ticker_local, True, 'cached')&#10;                            # use rate-limited fetch so prefetch respects global rate/concurrency limits&#10;                            klines_local = _rate_limited_get_klines(ticker_local, 'minute15', count=count)&#10;                            _cache_set(key_local, klines_local, ttl=_KLINES_CACHE_TTL)&#10;                            return (ticker_local, True, 'fetched')&#10;                        except Exception as exc:&#10;                            log.error(f'Prefetch ticker error for {ticker_local}: {exc}')&#10;                            return (ticker_local, False, str(exc))&#10;&#10;                    # run in ThreadPoolExecutor with limited parallelism&#10;                    with ThreadPoolExecutor(max_workers=min(parallelism, len(tickers_to_process))) as executor:&#10;                        futures = {executor.submit(_prefetch_single, t): t for t in tickers_to_process}&#10;                        for fut in as_completed(futures):&#10;                            try:&#10;                                ticker_res, ok, msg = fut.result()&#10;                                log.debug(f'Prefetch result: {ticker_res} ok={ok} info={msg}')&#10;                            except Exception as e:&#10;                                log.error(f'Prefetch future error: {e}')&#10;                    # after parallel batch, small pause to avoid immediate repeated calls&#10;                    time.sleep(per_ticker_sleep)&#10;        except Exception as e:&#10;            log.error(f'Prefetch error: {e}')&#10;        # wait using effective interval (recompute per loop)&#10;        try:&#10;            _prefetch_stop.wait(effective_interval)&#10;        except UnboundLocalError:&#10;            _prefetch_stop.wait(interval)&#10;    log.info('Prefetch scheduler stopped')&#10;&#10;# 스케쥴러 시작 함수&#10;# interval: 루프 주기 (초)&#10;# 기본값 30초&#10;def start_prefetch_scheduler(interval: int = 30):&#10;    global _prefetch_thread, _prefetch_stop&#10;    if _prefetch_thread is not None and _prefetch_thread.is_alive():&#10;        return&#10;    _prefetch_stop.clear()&#10;    # Redis 미사용 시 기본 간격 증가&#10;    # Upbit 호출 부담 축소를 위한 조치&#10;    # 기본 최소 60초&#10;    if _redis_client is None:&#10;        interval = max(interval, 60)&#10;        log.info('Redis not connected: starting prefetch with interval %s seconds', interval)&#10;    # Redis 미사용 시 기본 배치 크기 축소&#10;    if _redis_client is None:&#10;        try:&#10;            # 배치사이즈 기본 3으로 축소, config에 없으면 설정&#10;            if 'prefetch_batch_size' not in config._config:&#10;                config._config['prefetch_batch_size'] = 3&#10;        except Exception:&#10;            pass&#10;    # 프리페치 레이트 리미터 및 세마포어 초기화&#10;    # 설정값 읽기 및 기본값 적용&#10;    global _prefetch_token_bucket, _prefetch_semaphore # 전역 변수&#10;    try:&#10;        # 초당 5토큰&#10;        rate = int(config._config.get('prefetch_rate_per_sec', 5))&#10;    except Exception:&#10;        rate = 5&#10;    try:&#10;        # 용량은 rate와 같게&#10;        capacity = int(config._config.get('prefetch_rate_capacity', max(1, rate)))&#10;    except Exception:&#10;        capacity = max(1, rate)&#10;    try:&#10;        # 동시 3개&#10;        max_concurrent = int(config._config.get('prefetch_max_concurrent', 3))&#10;    except Exception:&#10;        max_concurrent = 3&#10;    try:&#10;        # 토큰 버킷 및 세마포어 초기화&#10;        _prefetch_token_bucket = TokenBucket(rate=float(rate), capacity=float(capacity))&#10;        _prefetch_semaphore = threading.BoundedSemaphore(max_concurrent)&#10;        log.info(f'Prefetch rate limiter initialized: rate={rate}/s, capacity={capacity}, max_concurrent={max_concurrent}')&#10;    except Exception as e:&#10;        _prefetch_token_bucket = None&#10;        _prefetch_semaphore = None&#10;        log.warning(f'Failed to initialize prefetch rate limiter: {e}')&#10;    _prefetch_thread = threading.Thread(target=_prefetch_loop, args=(interval,), daemon=True)&#10;    _prefetch_thread.start()&#10;&#10;# 스케쥴러 중지 함수&#10;# 스케쥴러 스레드 종료 대기 (최대 2초)&#10;# 기본값 30초&#10;def stop_prefetch_scheduler():&#10;    global _prefetch_thread, _prefetch_stop&#10;    _prefetch_stop.set()&#10;    if _prefetch_thread is not None:&#10;        _prefetch_thread.join(timeout=2)&#10;    _prefetch_thread = None&#10;&#10;&#10;@app.get(&quot;/health&quot;) # 헬스체크 엔드포인트&#10;def health():&#10;    return {&quot;status&quot;: &quot;ok&quot;}&#10;&#10;&#10;@app.get('/debug/status') # 디버그 상태 엔드포인트&#10;def debug_status():&#10;    &quot;&quot;&quot;Return diagnostic info: pyupbit presence, redis connection, prefetch thread state, universe size.&quot;&quot;&quot;&#10;    try:&#10;        import server.upbit_api as upbit_api&#10;        has_pyupbit = bool(getattr(upbit_api, '_HAS_PYUPBIT', False))&#10;    except Exception:&#10;        has_pyupbit = False&#10;&#10;    redis_up = False&#10;    try:&#10;        redis_up = _redis_client is not None&#10;    except Exception:&#10;        redis_up = False&#10;&#10;    prefetch_running = False&#10;    try:&#10;        prefetch_running = (_prefetch_thread is not None and _prefetch_thread.is_alive())&#10;    except Exception:&#10;        prefetch_running = False&#10;&#10;    universe_len = 0&#10;    try:&#10;        universe_len = len(config._config.get('universe', []))&#10;    except Exception:&#10;        universe_len = 0&#10;&#10;    return {&#10;        'pyupbit': has_pyupbit,&#10;        'redis': redis_up,&#10;        'prefetch_running': prefetch_running,&#10;        'prefetch_index': _prefetch_index,&#10;        'universe_len': universe_len,&#10;    }&#10;&#10;&#10;@app.get(&quot;/config&quot;) # 설정 조회 엔드포인트&#10;def get_config():&#10;    cfg = config._config&#10;    return {&quot;config&quot;: cfg}&#10;&#10;&#10;@app.post(&quot;/config&quot;) # 설정 저장 엔드포인트&#10;def post_config(payload: ConfigPayload):&#10;    new_cfg = payload.config&#10;    # 기본적인 검증: 반드시 strategy_name과 market이 있어야 함&#10;    if not isinstance(new_cfg, dict) or 'strategy_name' not in new_cfg or 'market' not in new_cfg:&#10;        raise HTTPException(status_code=400, detail=&quot;Invalid config payload. 'strategy_name' and 'market' required.&quot;)&#10;&#10;    success = config.save_config(new_cfg)&#10;    if not success:&#10;        raise HTTPException(status_code=500, detail=&quot;Failed to save configuration&quot;)&#10;&#10;    # 저장 후 재로딩&#10;    config.reload_config()&#10;    return {&quot;status&quot;: &quot;saved&quot;}&#10;&#10;&#10;@app.post(&quot;/reload&quot;) # 설정 재로딩 엔드포인트&#10;def reload_config():&#10;    config.reload_config()&#10;    return {&quot;status&quot;: &quot;reloaded&quot;}&#10;&#10;&#10;# --- Screening endpoints ---&#10;# 변동성 상위 N개 티커 조회&#10;# market_prefix: 마켓 접두사 (기본값 &quot;KRW&quot;)&#10;# top_n: 상위 N개 (기본값 10)&#10;# timeframe: 변동성 계산에 사용할 시간대 (기본값 &quot;minute15&quot;)&#10;# 반환값: 변동성 상위 N개 티커 리스트&#10;# 변동성 계산은 (최고가 - 최저가) / 평균 종가 방식 사용&#10;# Upbit의 공용 kline 엔드포인트 사용&#10;# config.json의 'universe' 키에 티커 리스트가 없으면 기본 샘플 리스트 사용, 폴백 처리&#10;# 반환값: {&quot;top&quot;: [ {&quot;ticker&quot;: 티커명, &quot;volatility&quot;: 변동성}, ... ] }&#10;# 캐시 사용으로 중복 Upbit 호출 최소화&#10;# 캐시 TTL은 _KLINES_CACHE_TTL 사용&#10;# 예외 발생 시 해당 티커는 건너뜀&#10;@app.get(&quot;/screen/volatility_top&quot;) # 변동성 상위 티커 조회 엔드포인트&#10;def volatility_top(market_prefix: str = &quot;KRW&quot;, top_n: int = 10, timeframe: str = &quot;minute15&quot;):&#10;    cfg = config._config # 설정 읽기&#10;    universe = cfg.get('universe', []) # 유니버스 읽기&#10;    if not universe:&#10;        # 폴백: 기본 샘플 유니버스&#10;        universe = [f&quot;{market_prefix}-BTC&quot;, f&quot;{market_prefix}-ETH&quot;, f&quot;{market_prefix}-XRP&quot;, f&quot;{market_prefix}-ADA&quot;, f&quot;{market_prefix}-DOGE&quot;, f&quot;{market_prefix}-SOL&quot;, f&quot;{market_prefix}-DOT&quot;, f&quot;{market_prefix}-MATIC&quot;, f&quot;{market_prefix}-BCH&quot;, f&quot;{market_prefix}-LTC&quot;]&#10;&#10;    results = []&#10;    # Try to use internal cache to avoid hammering Upbit when checking multiple tickers&#10;    now = time.time()&#10;    for ticker in universe:&#10;        # 캐시 키 생성 (가장 최근 15캔들 기준)&#10;        key = f&quot;{ticker}|{timeframe}|15&quot;&#10;        # 캐시 조회&#10;        cached = _cache_get(key)&#10;        # 캐시 유효성 검사&#10;        if cached and (now - cached[0]) &lt; _KLINES_CACHE_TTL: # 캐시 유효 시&#10;            klines = cached[1] # 캐시된 값 사용&#10;        else:&#10;            try:&#10;                # Upbit에서 변동성 계산용 klines 조회 (rate-limited)&#10;                # 15캔들 기준 (폴백 200캔들 아님)&#10;                klines = _rate_limited_get_klines(ticker, timeframe, count=15)&#10;            except Exception as e:&#10;                log.warning(f'Rate-limited fetch failed for {ticker}: {e}')&#10;                klines = None&#10;            # 캐시 설정, None도 캐시하여 반복 실패 방지&#10;            _cache_set(key, klines, ttl=_KLINES_CACHE_TTL)&#10;        if not klines:&#10;            continue&#10;        highs = [float(k['high_price']) for k in klines]&#10;        lows = [float(k['low_price']) for k in klines]&#10;        closes = [float(k['trade_price']) for k in klines]&#10;        # 변동성 계산 : (최고가 - 최저가) / 평균 종가 방식&#10;        try:&#10;            vol = (max(highs) - min(lows)) / (sum(closes) / len(closes))&#10;        except Exception:&#10;            vol = 0&#10;        results.append({'ticker': ticker, 'volatility': vol})&#10;&#10;    # 변동성 기준 내림차순 정렬 후 상위 N개 반환&#10;    results_sorted = sorted(results, key=lambda x: x['volatility'], reverse=True)[:top_n]&#10;    return {&quot;top&quot;: results_sorted}&#10;&#10;&#10;# --- Background Event Watcher ---&#10;# 단순 폴링 기반 워처 구현&#10;# 워처는 별도 스레드에서 동작하며, 지정된 마켓의 klines를 주기적으로 조회&#10;# 지정된 조건에 부합하는 이벤트 발생 시 로그 출력&#10;# 조건은 JSON 배열로 전달되며, 각 조건은 다음과 같은 형태를 가짐&#10;# {&quot;type&quot;: &quot;volatility_breakout&quot;, &quot;k&quot;: 0.5} : 변동성 돌파 이벤트 (Larry Williams 스타일)&#10;# {&quot;type&quot;: &quot;volume_spike&quot;, &quot;multiplier&quot;: 3} : 거래량 급증 이벤트&#10;# 워처 시작 엔드포인트&#10;# 요청 본문 예시:&#10;# {&quot;market&quot;: &quot;KRW-BTC&quot;,&#10;# &quot;interval&quot;: 1,&#10;# &quot;callbacks&quot;:[&#10;#     {&quot;type&quot;:&quot;volatility_breakout&quot;, &quot;k&quot;:0.5},&#10;#     {&quot;type&quot;:&quot;volume_spike&quot;, &quot;multiplier&quot;:3}&#10;# ]}&#10;# 워처 중지 엔드포인트&#10;def _watcher_loop(stop_event, market: str, check_interval: float, callbacks: List[dict]):&#10;    &quot;&quot;&quot;Simple polling watcher that fetches latest klines and invokes callbacks when conditions met.&quot;&quot;&quot;&#10;    log.info(f&quot;Starting watcher loop for {market} (interval {check_interval}s)&quot;)&#10;    last_checked_time = None&#10;    while not stop_event.is_set():&#10;        try:&#10;            try:&#10;                # Upbit에서 최신 60캔들 조회 (rate-limited)&#10;                klines = _rate_limited_get_klines(market, 'minute1', count=60)&#10;            except Exception as e:&#10;                log.error(f'Watcher fetch rate-limited or failed for {market}: {e}')&#10;                klines = None&#10;&#10;            # 이벤트 체크&#10;            if klines:&#10;                # 최근 캔들&#10;                latest = klines[0]&#10;                # 변동성 체크용 15캔들 윈도우 준비&#10;                window = klines[:15]&#10;                highs = [float(k['high_price']) for k in window]&#10;                lows = [float(k['low_price']) for k in window]&#10;                volumes = [float(k['candle_acc_trade_volume']) for k in window]&#10;                closes = [float(k['trade_price']) for k in window]&#10;&#10;                # 변동성 돌파 체크 (간단화된 Larry Williams 스타일)&#10;                try:&#10;                    prev_close = closes[1]&#10;                    curr_close = closes[0]&#10;                    volatility_range = max(highs) - min(lows)&#10;                except Exception:&#10;                    prev_close = curr_close = volatility_range = None&#10;&#10;                # 콜백 조건 체크&#10;                if prev_close is not None and curr_close is not None: # 유효한 데이터 시&#10;                    avg_vol = sum(volumes[1:]) / (len(volumes)-1) if len(volumes) &gt; 1 else 0&#10;                    statuses = []&#10;                    for cb in callbacks:&#10;                        cb_type = cb.get('type')&#10;                        # 변동성 돌파 체크&#10;                        if cb_type == 'volatility_breakout':&#10;                            k = cb.get('k', 0.5)&#10;                            triggered = curr_close &gt; (prev_close + volatility_range * k)&#10;                            status = (&#10;                                f&quot;volatility_breakout(k={k}) current={curr_close:.0f} prev={prev_close:.0f} &quot;&#10;                                f&quot;range={volatility_range:.0f} triggered={triggered}&quot;&#10;                            )&#10;                            statuses.append(status)&#10;                            if triggered:&#10;                                log.info(f&quot;Watcher detected volatility breakout on {market} (k={k})&quot;)&#10;                        # 거래량 급증 체크&#10;                        elif cb_type == 'volume_spike':&#10;                            multiplier = cb.get('multiplier', 3)&#10;                            triggered = avg_vol and volumes[0] &gt; avg_vol * multiplier&#10;                            status = (&#10;                                f&quot;volume_spike(mult={multiplier}) current_vol={volumes[0]:.0f} avg_vol={avg_vol:.0f} &quot;&#10;                                f&quot;triggered={bool(triggered)}&quot;&#10;                            )&#10;                            statuses.append(status)&#10;                            if triggered:&#10;                                log.info(f&quot;Watcher detected volume spike on {market} (x{multiplier})&quot;)&#10;                        else:&#10;                            statuses.append(f&quot;unknown callback {cb}&quot;)&#10;                    config_desc = (f&quot;market={market} interval={check_interval}s callbacks={len(callbacks)}&quot;)&#10;                    log.info(f&quot;WatcherCheck: {config_desc} | { ' ; '.join(statuses)}&quot;)&#10;&#10;            time.sleep(check_interval)&#10;        except Exception as e:&#10;            log.error(f&quot;Error in watcher loop: {e}&quot;)&#10;            time.sleep(check_interval)&#10;    log.info(&quot;Watcher loop stopped.&quot;)&#10;&#10;# 워처 시작 엔드포인트&#10;# 요청 본문 예시:&#10;# {&quot;market&quot;: &quot;KRW-BTC&quot;,&#10;# &quot;interval&quot;: 1,&#10;# &quot;callbacks&quot;:[&#10;#     {&quot;type&quot;:&quot;volatility_breakout&quot;, &quot;k&quot;:0.5},&#10;#     {&quot;type&quot;:&quot;volume_spike&quot;, &quot;multiplier&quot;:3}&#10;# ]}&#10;@app.post(&quot;/watcher/start&quot;) # 워처 시작 엔드포인트&#10;def start_watcher(payload: Dict[str, Any]):&#10;    if _watcher['running']:&#10;        raise HTTPException(status_code=400, detail=&quot;Watcher already running&quot;)&#10;&#10;    # 파라미터 추출&#10;    market = payload.get('market', config.MARKET)   # 마켓 (기본값 config.MARKET)&#10;    interval = float(payload.get('interval', 1.0))  # 체크 간격 (초)&#10;    callbacks = payload.get('callbacks', [])        # 콜백 조건 리스트&#10;&#10;    # 워처 스레드 시작&#10;    stop_event = threading.Event()&#10;    # 워처 루프 스레드 생성 및 시작&#10;    t = threading.Thread(target=_watcher_loop, args=(stop_event, market, interval, callbacks), daemon=True)&#10;    _watcher['running'] = True              # 워처 상태 갱신&#10;    _watcher['thread'] = t                  # 워처 스레드 저장&#10;    _watcher['stop_event'] = stop_event     # 중지 이벤트 저장&#10;    t.start()&#10;    return {&quot;status&quot;: &quot;started&quot;}&#10;&#10;# 워처 중지 엔드포인트&#10;# 워처 중지 이벤트 설정 및 스레드 종료 대기&#10;# 워처 상태 초기화&#10;# 반환값: {&quot;status&quot;: &quot;stopped&quot;} 또는 {&quot;status&quot;: &quot;not_running&quot;}&#10;@app.post(&quot;/watcher/stop&quot;)&#10;def stop_watcher():&#10;    if not _watcher['running']:&#10;        return {&quot;status&quot;: &quot;not_running&quot;}&#10;    _watcher['stop_event'].set()&#10;    _watcher['thread'].join(timeout=5)&#10;    _watcher['running'] = False&#10;    _watcher['thread'] = None&#10;    _watcher['stop_event'] = None&#10;    return {&quot;status&quot;: &quot;stopped&quot;}&#10;&#10;# 배치 klines 조회 엔드포인트&#10;# 티커/타임프레임/카운트 조합별로 캐시 키 생성 (인메모리 또는 Redis)&#10;# 요청 본문 예시:&#10;# {&quot;tickers&quot;: [&quot;KRW-BTC&quot;,&quot;KRW-ETH&quot;], &quot;timeframe&quot;:&quot;minute15&quot;, &quot;count&quot;:100}&#10;# 반환값 예시:&#10;# {&quot;klines&quot;: {&quot;KRW-BTC&quot;: [...], &quot;KRW-ETH&quot;: [...]} }&#10;# 각 티커별로 klines를 조회하여 결과 딕셔너리에 저장&#10;# 내부적으로 캐시를 사용하여 중복 Upbit 호출 최소화&#10;# 캐시 TTL은 _KLINES_CACHE_TTL 사용&#10;# 캐시 미스 시 rate-limited fetcher를 사용하여 Upbit에서 klines 조회&#10;# 예외 발생 시 해당 티커는 None으로 설정&#10;@app.post('/klines_batch')&#10;def klines_batch(payload: KlinesBatchRequest):&#10;    req = payload.model_dump()&#10;    tickers = req.get('tickers', []) or []&#10;    timeframe = req.get('timeframe', 'minute15')&#10;    count = int(req.get('count', 100))&#10;&#10;    result = {}&#10;    now = time.time()&#10;    for ticker in tickers:&#10;        key = f&quot;{ticker}|{timeframe}|{count}&quot; # 캐시 키 생성&#10;        cached = _cache_get(key)&#10;        # 캐시 유효성 검사&#10;        # 캐시 유효 시 캐시된 값 사용&#10;        if cached and (now - cached[0]) &lt; _KLINES_CACHE_TTL:&#10;            result[ticker] = cached[1]&#10;            continue&#10;&#10;        # 카운트 이상인 캐시 항목 검색 시도 (인메모리 및 Redis 모두 지원)&#10;        # 가장 큰 count를 가진 항목 선택&#10;        # 캐시 미스 시 rate-limited fetcher 사용&#10;        klines = None&#10;        try:&#10;            # 가능한 경우 Redis에서 검색&#10;            if _redis_client:&#10;                try:&#10;                    pattern = f&quot;{ticker}|{timeframe}|*&quot;&#10;                    # 패턴 매칭 키 조회&#10;                    keys = _redis_client.keys(pattern)&#10;                    # 후보 탐색 및 선택 (요청보다 가장 큰 count)&#10;                    best = None&#10;                    best_cnt = 0&#10;                    for k in keys:&#10;                        try:&#10;                            # 키 파싱 [ticker, timeframe, count]&#10;                            parts = k.split('|')&#10;&#10;                            # 유효한 키 형식 시 (3개 이상 파트로 구성)&#10;                            if len(parts) &gt;= 3:&#10;                                # count 부분 (마지막 부분)&#10;                                kcnt = int(parts[-1])&#10;                                # 요청한 카운트보다 크고 현재 최상위 후보보다 큰 경우&#10;                                if kcnt &gt;= count and kcnt &gt; best_cnt:&#10;                                    best = k        # 후보 키 갱신&#10;                                    best_cnt = kcnt # 후보 카운트 갱신&#10;                        except Exception:&#10;                            continue&#10;                    # 후보 키가 발견된 경우&#10;                    if best:&#10;                        # 후보 키로 캐시 조회&#10;                        cached2 = _cache_get(best, ttl=_KLINES_CACHE_TTL)&#10;                        # 후보 캐시에서 klines 추출&#10;                        if cached2:&#10;                            klines_full = cached2[1]&#10;                            # 유효한 klines 시&#10;                            if isinstance(klines_full, list) and len(klines_full) &gt; 0:&#10;                                # 요청한 개수만큼 슬라이싱하여 반환&#10;                                klines = klines_full[-count:]&#10;                except Exception:&#10;                    pass&#10;            else:&#10;                # 인-메모리 캐시에서 후보 탐색&#10;                try:&#10;                    candidates = []&#10;                    # 인-메모리 캐시 순회&#10;                    for k, v in list(_klines_cache.items()):&#10;                        try:&#10;                            # 키 파싱 [ticker, timeframe, count]&#10;                            parts = k.split('|')&#10;                            # 유효한 키 형식 시 (3개 이상 파트로 구성)&#10;                            if parts[0] == ticker and parts[1] == timeframe:&#10;                                kcnt = int(parts[2])            # count 부분&#10;                                candidates.append((kcnt, v))    # 후보 리스트에 추가&#10;                        except Exception:&#10;                            continue&#10;                    # 후보 정렬 및 선택 (요청보다 큰 count)&#10;                    candidates = sorted(candidates, key=lambda x: x[0], reverse=True) # 내림차순 정렬&#10;                    for kcnt, v in candidates:&#10;                        if kcnt &gt;= count:&#10;                            klines_full = v[1]&#10;                            # 유효한 klines 시&#10;                            if isinstance(klines_full, list) and len(klines_full) &gt; 0:&#10;                                # 요청한 개수만큼 슬라이싱하여 반환&#10;                                klines = klines_full[-count:]&#10;                                break&#10;                except Exception:&#10;                    pass&#10;&#10;            # 캐시에서 발견되지 않은 경우 rate-limited fetcher 사용&#10;            if klines is None:&#10;                try:&#10;                    klines = _rate_limited_get_klines(ticker, timeframe, count=count)&#10;                except Exception as e:&#10;                    log.warning(f'Rate-limited batch fetch failed for {ticker}: {e}')&#10;                    klines = None&#10;        except Exception as e:&#10;            log.warning(f'klines_batch lookup error for {ticker}: {e}')&#10;            klines = None&#10;&#10;        # 캐시 설정 (실패 시에도 캐시하여 반복 실패 방지)&#10;        _cache_set(key, klines, ttl=_KLINES_CACHE_TTL)&#10;        result[ticker] = klines&#10;&#10;    return {'klines': result}&#10;&#10;# --- Private API Endpoints ---&#10;# 잔고 조회 엔드포인트&#10;# Upbit 개인 API 키를 사용하여 잔고 조회&#10;# 키가 구성되지 않은 경우 503 반환&#10;# 이 엔드포인트는 짧은 TTL(_BALANCES_CACHE_TTL)로 잔고를 캐시하여 반복된 Upbit 호출을 줄임&#10;# 반환값에는 추가 진단 필드 포함:&#10;#   - balances: Upbit에서 반환된 원시 잔고 리스트&#10;#   - reported_krw_balance: 잔고에서 보고된 KRW 잔고 (없으면 0)&#10;#   - cached: 응답이 서버 캐시에서 왔는지 여부&#10;#   - cached_ts: 캐시된 시점 타임스탬프&#10;@app.get('/balances')&#10;def get_balances():&#10;    # 잔고 조회 엔드포인트&#10;    if _upbit_private is None:&#10;        raise HTTPException(status_code=503, detail='Upbit API keys not configured on server; balances unavailable')&#10;&#10;    cache_key = 'upbit:balances:all'&#10;    now = time.time()&#10;&#10;    # 캐시 조회 시도&#10;    cached = _cache_get(cache_key, ttl=_BALANCES_CACHE_TTL)&#10;    if cached and (now - cached[0]) &lt; _BALANCES_CACHE_TTL:&#10;        bl = cached[1]&#10;        cached_flag = True&#10;        cached_ts = cached[0]&#10;        log.debug('Balances: cache hit')&#10;    else:&#10;        cached_flag = False&#10;        cached_ts = None&#10;        try:&#10;            bl = _upbit_private.get_balances()&#10;        except Exception as e:&#10;            log.error(f'Balances retrieval failed: {e}')&#10;            # 캐시가 존재하면 캐시된 값 반환 (최선의 노력)&#10;            if cached:&#10;                bl = cached[1]&#10;                cached_flag = True&#10;                cached_ts = cached[0]&#10;            else:&#10;                raise HTTPException(status_code=502, detail=f'Upbit API call failed: {e}')&#10;        # 캐시 설정 (실패 시에도 캐시하여 반복 실패 방지)&#10;        _cache_set(cache_key, bl, ttl=_BALANCES_CACHE_TTL)&#10;&#10;    # KRW 잔고 계산 (반환된 잔고에서)&#10;    # 'currency' 또는 'unit' 필드 사용&#10;    reported_krw = 0.0&#10;    try:&#10;        if isinstance(bl, list):&#10;            for item in bl:&#10;                # 업비트API /v1/accounts는 'currency'와 'balance' 필드를 가진 항목 반환&#10;                try:&#10;                    cur = str(item.get('currency') or item.get('unit') or '').upper()&#10;                    bal = float(item.get('balance') or 0.0)&#10;                except Exception:&#10;                    continue&#10;                if cur == 'KRW' or cur.startswith('KRW'):&#10;                    reported_krw += bal&#10;        elif isinstance(bl, dict):&#10;            # 딕셔너리 형태인 경우 'balances' 키에서 리스트 추출&#10;            lst = bl.get('balances') if 'balances' in bl else None&#10;            if isinstance(lst, list):&#10;                for item in lst:&#10;                    try:&#10;                        cur = str(item.get('currency') or item.get('unit') or '').upper()&#10;                        bal = float(item.get('balance') or 0.0)&#10;                    except Exception:&#10;                        continue&#10;                    if cur == 'KRW' or cur.startswith('KRW'):&#10;                        reported_krw += bal&#10;    except Exception:&#10;        reported_krw = 0.0&#10;&#10;    return {&#10;        'balances': bl,&#10;        'reported_krw_balance': reported_krw,&#10;        'cached': bool(cached_flag),&#10;        'cached_ts': cached_ts,&#10;    }&#10;&#10;# 포지션 조회 엔드포인트&#10;# Upbit 개인 API 키를 사용하여 잔고 조회 후 현재 가격과 결합하여 포지션 계산&#10;# 키가 구성되지 않은 경우 503 반환&#10;# 각 자산별 포지션 정보와 요약 총계 반환&#10;# 포지션 정보에는 다음 필드 포함:&#10;#   - symbol: 마켓 심볼 (예: KRW-BTC)&#10;#   - side: 포지션 방향 (항상 'LONG'으로 설정)&#10;#   - size: 보유 수량&#10;#   - entry_price: 평균 매수가 (없으면 null)&#10;#   - current_price: 현재 가격&#10;#   - unrealized_pnl: 미실현 손익 (없으면 null)&#10;#   - unrealized_pnl_rate: 미실현 손익률 (없으면 null)&#10;#   - notional_krw: 원화 기준 명목 가치&#10;# 요약 정보에는 다음 필드 포함:&#10;#   - total_equity_krw: 총 자산 가치 (원화 기준)&#10;#   - available_krw: 사용 가능한 원화 잔고&#10;#   - prices_fetched: 현재 가격을 성공적으로 조회한 자산 수&#10;#   - excluded_assets: 현재 가격을 조회하지 못해 제외된 자산 목록 (심볼 및 사유 포함)&#10;# 포지션 스냅샷은 히스토리 스토어에 기록됨&#10;# 반환값 예시:&#10;# {&#10;#   &quot;positions&quot;: [ {...}, {...}, ... ],&#10;#   &quot;total_equity_krw&quot;: 12345678.9,&#10;#   &quot;available_krw&quot;: 2345678.9,&#10;#   &quot;prices_fetched&quot;: 5,&#10;#   &quot;excluded_assets&quot;: [ {&quot;symbol&quot;: &quot;KRW-XYZ&quot;, &quot;reason&quot;: &quot;no_price&quot;}, ... ]&#10;# }&#10;@app.get(&quot;/positions&quot;)&#10;def get_positions():&#10;    if _upbit_private is None:&#10;        raise HTTPException(status_code=503, detail='Upbit API keys not configured on server; positions unavailable')&#10;&#10;    try:&#10;        bl = _upbit_private.get_balances() or []&#10;    except Exception as e:&#10;        log.error(f'Failed to retrieve balances for positions endpoint: {e}')&#10;        raise HTTPException(status_code=502, detail=f'Failed to retrieve balances: {e}')&#10;&#10;    positions = []&#10;    total_equity = 0.0&#10;    available_krw = 0.0&#10;&#10;    #시장리스트 작성 및 통화맵 작성 (가격 조회용)&#10;    markets = []&#10;    currency_map = {}&#10;    try:&#10;        for item in bl:&#10;            cur = str(item.get('currency') or item.get('unit') or '').upper()&#10;            bal = float(item.get('balance') or 0) if item is not None else 0.0&#10;            locked = float(item.get('locked') or 0) if item is not None else 0.0&#10;&#10;            # 원화 현금잔고 처리&#10;            if cur == 'KRW' or cur.startswith('KRW'):&#10;                available_krw += bal&#10;                total_equity += bal&#10;                continue&#10;            size = bal + locked&#10;            if size &lt;= 0:&#10;                continue&#10;            market = f'KRW-{cur}'&#10;            markets.append(market)&#10;            currency_map[market] = {&#10;                'currency': cur,&#10;                'size': size,&#10;                'avg_buy_price': float(item.get('avg_buy_price') or 0)&#10;            }&#10;    except Exception as e:&#10;        log.warning(f'Error while parsing balances for positions: {e}')&#10;&#10;    # 현재가격 조회 (1개 캔들 minute1, count=1) (조회수 제한 주의)&#10;    price_map = {}&#10;    for m in set(markets):&#10;        try:&#10;            kl = None&#10;            try:&#10;                kl = _rate_limited_get_klines(m, 'minute1', count=1)&#10;            except Exception as e:&#10;                log.warning(f'Price fetch failed for {m}: {e}')&#10;                kl = None&#10;            price = None&#10;            if kl and isinstance(kl, list) and len(kl) &gt; 0:&#10;                try:&#10;                    first = kl[0]&#10;                    price_candidate = None&#10;&#10;                    # 딕셔너리 레코드 작업&#10;                    # (Upbit API는 'trade_price' 사용)&#10;                    if isinstance(first, dict):&#10;                        price_candidate = first.get('trade_price') or first.get('close')&#10;                    else:&#10;                        # 속성 접근 시도 (일부 래퍼는 .close 또는 .trade_price 노출 가능)&#10;                        price_candidate = getattr(first, 'trade_price', None) or getattr(first, 'close', None)&#10;                    if price_candidate is None:&#10;                        price = None&#10;                    else:&#10;                        price = float(price_candidate)&#10;                except Exception:&#10;                    price = None&#10;            price_map[m] = price&#10;        except Exception as e:&#10;             log.warning(f'Unexpected error fetching price for {m}: {e}')&#10;             price_map[m] = None&#10;&#10;    # 포지션 구성 및 미실현 손익/명목 가치 계산&#10;    excluded_assets = []&#10;    for market, meta in currency_map.items():&#10;        cur = meta['currency']&#10;        size = float(meta['size'])&#10;        avg_price = float(meta.get('avg_buy_price') or 0.0)&#10;        current_price = price_map.get(market)&#10;&#10;        # 자산 현재 가격이 없으면 건너뛰고 보고&#10;        if current_price is None:&#10;            excluded_assets.append({'symbol': market, 'reason': 'no_price'})&#10;            continue&#10;&#10;        notional = size * float(current_price)&#10;        total_equity += notional&#10;        unrealized = None&#10;        unrealized_rate = None&#10;        if avg_price and avg_price &gt; 0:&#10;            unrealized = (float(current_price) - avg_price) * size&#10;            unrealized_rate = (float(current_price) - avg_price) / avg_price * 100&#10;&#10;        pos = {&#10;            'symbol': market,&#10;            'side': 'LONG',&#10;            'size': size,&#10;            'entry_price': avg_price if avg_price &gt; 0 else None,&#10;            'current_price': current_price,&#10;            'unrealized_pnl': unrealized,&#10;            'unrealized_pnl_rate': unrealized_rate,&#10;            'notional_krw': notional,&#10;        }&#10;        positions.append(pos)&#10;&#10;    # Also include list of excluded assets so UI can show a friendly message.&#10;    result = {&#10;        'positions': positions,&#10;        'total_equity_krw': total_equity,&#10;        'available_krw': available_krw,&#10;        'prices_fetched': len([p for p in price_map.values() if p is not None]),&#10;        'excluded_assets': excluded_assets,&#10;    }&#10;    history_store.record_snapshot({&#10;        'ts': time.time(),&#10;        'total_equity': total_equity,&#10;        'available_krw': available_krw,&#10;        'positions': [&#10;            {&#10;                'symbol': pos['symbol'],&#10;                'notional_krw': pos['notional_krw'],&#10;                'unrealized_pnl': pos['unrealized_pnl'],&#10;            }&#10;            for pos in positions&#10;        ],&#10;    })&#10;    return result&#10;&#10;&#10;@app.get('/ai/history')&#10;def get_ai_history(limit: int = 50):&#10;    try:&#10;        limit = max(1, min(int(limit), 200))&#10;    except Exception:&#10;        limit = 50&#10;    history = ai_history_store.get_history(limit=limit)&#10;    return {'items': history}&#10;&#10;&#10;@app.get('/positions/history')&#10;def get_positions_history(limit: int = 365, days: int = 365):&#10;    since = time.time() - float(days) * 86400&#10;    history = history_store.get_history(since=since, limit=limit)&#10;    return {'history': history}&#10;&#10;&#10;@app.post('/ws/start')&#10;def ws_start():&#10;    try:&#10;        start_ws_listener()&#10;        start_ticker_listener()&#10;        return {'status': 'started'}&#10;    except Exception as exc:&#10;        raise HTTPException(status_code=500, detail=f'Failed to start websocket listener: {exc}')&#10;&#10;@app.post('/ws/stop')&#10;def ws_stop():&#10;    try:&#10;        stop_ws_listener()&#10;        stop_ticker_listener()&#10;        return {'status': 'stopped'}&#10;    except Exception as exc:&#10;        raise HTTPException(status_code=500, detail=f'Failed to stop websocket listener: {exc}')&#10;&#10;@app.get('/ws/status')&#10;def ws_status():&#10;    running = bool(_ws_listener and _ws_listener._thread and _ws_listener._thread.is_alive())&#10;    return {'running': running, 'targets': _ws_listener.targets if _ws_listener else []}&#10;&#10;@app.get('/ws/stats')&#10;def ws_stats(last_hour_sec: int = 3600, recent_limit: int = 10):&#10;    raw_stats = load_ws_stats()&#10;    summary = summarize_ws_stats(raw_stats, last_hour_secs=last_hour_sec, recent_limit=recent_limit)&#10;    summary.update({&#10;        'running': bool(_ws_listener and _ws_listener._thread and _ws_listener._thread.is_alive()),&#10;        'targets': _ws_listener.targets if _ws_listener else [],&#10;    })&#10;    return summary&#10;&#10;@app.get('/ws/executions')&#10;def ws_executions(limit: int = 0):&#10;    try:&#10;        entries = read_exec_history(limit=limit)&#10;    except Exception as exc:&#10;        raise HTTPException(status_code=500, detail=f'Failed to load exec history: {exc}')&#10;    return {'executions': entries}&#10;&#10;@app.get('/ws/trades')&#10;def ws_trades(symbol: str, limit: int = 20):&#10;    if _redis_client is None:&#10;        raise HTTPException(status_code=503, detail='Redis cache unavailable; cannot read trades.')&#10;    if not symbol:&#10;        raise HTTPException(status_code=400, detail='symbol query parameter is required.')&#10;    max_limit = min(max(limit, 1), 200)&#10;    key = f'ws:trades:{symbol}'&#10;    raw = _redis_client.lrange(key, 0, max_limit - 1)&#10;    trades = []&#10;    try:&#10;        for item in raw:&#10;            import json as _json&#10;            trades.append(_json.loads(item))&#10;    except Exception:&#10;        trades = []&#10;    return {'symbol': symbol, 'trades': trades}&#10;&#10;&#10;def _ws_ticker_targets() -&gt; List[str]:&#10;    if _ws_listener:&#10;        return _ws_listener.targets&#10;    universe = config._config.get('universe')&#10;    if isinstance(universe, list) and universe:&#10;        return universe&#10;    return [&#10;        'KRW-BTC',&#10;        'KRW-ETH',&#10;        'KRW-ADA',&#10;        'KRW-XRP',&#10;        'KRW-SOL',&#10;    ]&#10;&#10;&#10;@app.get('/ws/ticker_data')&#10;def ws_ticker_data():&#10;    if _redis_client is None:&#10;        raise HTTPException(status_code=503, detail='Redis cache unavailable; cannot read ticker data.')&#10;    targets = _ws_ticker_targets()&#10;    payloads: List[Dict[str, Any]] = []&#10;    for symbol in targets:&#10;        key = f'ws:ticker:{symbol}'&#10;        raw = _redis_client.get(key)&#10;        if not raw:&#10;            continue&#10;        try:&#10;            data = json.loads(raw)&#10;        except Exception:&#10;            continue&#10;        payloads.append({&#10;            'symbol': symbol,&#10;            'opening_price': data.get('opening_price'),&#10;            'high_price': data.get('high_price'),&#10;            'low_price': data.get('low_price'),&#10;            'trade_price': data.get('trade_price') or data.get('trade_price'),&#10;            'prev_closing_price': data.get('prev_closing_price'),&#10;            'change': data.get('change'),&#10;            'timestamp': data.get('trade_timestamp') or data.get('timestamp'),&#10;        })&#10;    return {'tickers': payloads}&#10;&#10;# --- Trading Bot Control API ---&#10;&#10;# 봇 실행 중 여부 확인&#10;def _bot_running():&#10;    return config.BOT_ENABLED&#10;&#10;&#10;@app.post('/bot/control')&#10;def bot_control(payload: Dict[str, Any]):&#10;    enabled = payload.get('enabled')&#10;    interval = payload.get('interval_sec')&#10;    if enabled is None and interval is None:&#10;        raise HTTPException(status_code=400, detail='enabled or interval_sec required')&#10;    try:&#10;        updated = config.update_bot_control(bot_enabled=enabled, bot_interval_sec=interval)&#10;    except Exception as exc:&#10;        raise HTTPException(status_code=500, detail=f'Failed to update bot config: {exc}')&#10;    return {'status': 'updated', 'bot_enabled': config.BOT_ENABLED, 'bot_interval_sec': config.BOT_INTERVAL_SEC, 'updated': updated}&#10;&#10;&#10;@app.get('/bot/status')&#10;def bot_status():&#10;    return {&#10;        'bot_enabled': config.BOT_ENABLED,&#10;        'bot_interval_sec': config.BOT_INTERVAL_SEC,&#10;        'running': config.BOT_ENABLED,&#10;    }&#10;&#10;" />
              <option name="updatedContent" value="from fastapi import FastAPI, HTTPException # web framework&#10;from contextlib import asynccontextmanager # for lifespan management&#10;from pydantic import BaseModel # data validation, settings management&#10;from typing import Any, Dict, List, Optional # type hints&#10;import threading&#10;import time&#10;import os&#10;&#10;# 시간대 설정&#10;os.environ.setdefault('TZ', 'Asia/Seoul')&#10;try:&#10;    time.tzset()&#10;except Exception:&#10;    pass&#10;&#10;# 외부라이브러리 임포트&#10;import redis # Redis 클라이언트&#10;import json&#10;from concurrent.futures import ThreadPoolExecutor, as_completed # for parallel prefetching&#10;&#10;# 내부API 모듈 임포트&#10;from server import config               # 런타임 설정 관리&#10;from server.upbit_api import UpbitAPI   # 업비트 API 연동&#10;from server.logger import log           # 로깅 설정&#10;from server.history import history_store&#10;from server.history import order_history_store&#10;from server.history import ai_history_store&#10;from server.ws_listener_base import (&#10;    load_ws_stats,&#10;    summarize_ws_stats,&#10;    read_exec_history,&#10;)&#10;from server.ws_listener_private import PrivateWebsocketListener&#10;from server.ws_listener_public import PublicWebsocketlistener&#10;&#10;# Token Bucket 구현 for prefetch&#10;# 간단한 토큰 버킷(rate limiter) 구현&#10;# rate: 초당 토큰 생성 속도&#10;# capacity: 버킷 최대 토큰 수&#10;# consume(tokens, timeout): 지정된 토큰 수를 소비 시도, 타임아웃 내에 성공 여부 반환&#10;# 스레드 안전 구현&#10;# 사용 예시:&#10;# tb = TokenBucket(rate=5, capacity=10)  # 초당 5토큰, 최대 10토큰&#10;# if tb.consume(tokens=1, timeout=2.0):&#10;#     print(&quot;Token acquired&quot;)&#10;# else:&#10;#     print(&quot;Failed to acquire token within timeout&quot;)&#10;class TokenBucket:&#10;    def __init__(self, rate: float, capacity: float):&#10;        self.rate = float(rate)         # 토큰 생성 속도 (초당)&#10;        self.capacity = float(capacity) # 버킷 최대 용량&#10;        self._tokens = float(capacity)  # 현재 토큰 수&#10;        self._last = time.time()        # 마지막 토큰 갱신 시각&#10;        self._lock = threading.Lock()   # 스레드 안전을 위한 락&#10;&#10;    # 토큰 소비 메서드&#10;    # tokens: 소비할 토큰 수&#10;    # timeout: 최대 대기 시간 (초)&#10;    # 반환값: 성공 시 True, 실패 시 False&#10;    def consume(self, tokens: float = 1.0, timeout: float = 5.0) -&gt; bool:&#10;        end = time.time() + float(timeout)&#10;        while time.time() &lt; end:&#10;            with self._lock:&#10;                now = time.time()&#10;                elapsed = max(0.0, now - self._last)&#10;                self._tokens = min(self.capacity, self._tokens + elapsed * self.rate)&#10;                self._last = now&#10;                if self._tokens &gt;= tokens:&#10;                    self._tokens -= tokens&#10;                    return True&#10;            time.sleep(0.01)&#10;        return False&#10;&#10;&#10;# 세마포어 및 토큰 버킷 초기화 (스케줄러 시작 시)&#10;_prefetch_token_bucket: Optional[TokenBucket] = None&#10;_prefetch_semaphore: Optional[threading.BoundedSemaphore] = None&#10;&#10;# 기본 klines 캐시 TTL (초)&#10;# 환경변수 'KLINES_CACHE_TTL'로 설정 가능, 기본값 600초&#10;# 예: os.environ['KLINES_CACHE_TTL'] = '600'&#10;# (기본값 600초로 설정하여 중복 Upbit 요청 감소, 실시간성은 다소 희생, 값이 클수록 캐시 지속시간 증가)&#10;_KLINES_CACHE_TTL = int(os.getenv('KLINES_CACHE_TTL', str(600)))  # default 600s&#10;&#10;# Balances cache TTL (seconds)&#10;_BALANCES_CACHE_TTL = int(os.getenv('BALANCES_CACHE_TTL', '15'))&#10;&#10;# FastAPI 앱 생성 및 수명 주기 관리&#10;@asynccontextmanager&#10;async def lifespan(app: FastAPI): # 수명 주기 관리&#10;    # start prefetch scheduler on startup&#10;    try:&#10;        # read interval from config, default 30s&#10;        # if invalid, fallback to 30s&#10;        # prefetch interval 설정&#10;        # 기본값 30초&#10;        # 환경변수나 config.json의 'prefetch_interval_sec' 키로 설정 가능&#10;        interval = int(config._config.get('prefetch_interval_sec', 30))&#10;    except Exception:&#10;        interval = 30&#10;&#10;    # 스케쥴러 시작&#10;    start_prefetch_scheduler(interval=interval)&#10;    try:&#10;        start_ws_listener()&#10;        start_ticker_listener()&#10;    except Exception as exc:&#10;        log.warning(f'Failed to start websocket listener on startup: {exc}')&#10;    try:&#10;        yield&#10;    finally:&#10;        # 스케쥴러 중지&#10;        stop_prefetch_scheduler()&#10;        stop_ws_listener()&#10;        stop_ticker_listener()&#10;&#10;app = FastAPI(title=&quot;Upbit Trader Runtime API&quot;, lifespan=lifespan) # FastAPI 앱 생성&#10;&#10;# 데이터 모델 정의&#10;class ConfigPayload(BaseModel):&#10;    config: Dict[str, Any]&#10;&#10;# 배치 klines 요청 모델&#10;class KlinesBatchRequest(BaseModel):&#10;    tickers: List[str]&#10;    timeframe: Optional[str] = 'minute15'&#10;    count: Optional[int] = 100&#10;&#10;# 포지션 모델 정의&#10;class Position(BaseModel):&#10;    ticker: str&#10;    amount: float&#10;    avg_price: float&#10;    current_price: float&#10;    pnl: float&#10;&#10;# --- Background Prefetch Scheduler 및 캐시 관리 ---&#10;# 전역 상태 변수들&#10;# Prefetch 스레드 및 제어 변수&#10;# Simple in-memory watcher state (explicit typing to satisfy linters)&#10;_watcher: Dict[str, Any] = {&#10;    'running': False,&#10;    'thread': None,&#10;    'stop_event': None,&#10;}&#10;&#10;# 캐시 딕셔너리&#10;# Simple in-memory cache for batch klines: { key: (timestamp, data) }&#10;_klines_cache: Dict[str, Any] = {}&#10;&#10;&#10;# 레디스(Redis) 클라이언트 초기화&#10;# Redis setup (optional). Use local redis://localhost:6379 if REDIS_URL not set&#10;# 환경변수 'REDIS_URL'로 Redis URL 설정 가능&#10;REDIS_URL = os.getenv('REDIS_URL', 'redis://localhost:6379/0')&#10;_redis_client = None&#10;try:&#10;    # Redis 클라이언트 생성 및 연결 테스트&#10;    _redis_client = redis.from_url(REDIS_URL, decode_responses=True)&#10;    # ping 테스트&#10;    _redis_client.ping()&#10;    log.info(f'Redis cache connected: {REDIS_URL}')&#10;except Exception as e:&#10;    _redis_client = None&#10;    log.warning(f'Redis not available ({REDIS_URL}): {e}. Falling back to in-memory cache')&#10;&#10;# 캐시 설정 함수&#10;# key: 캐시 키&#10;# value: 캐시 값&#10;# ttl: 캐시 만료 시간 (초)&#10;# 기본 TTL은 _KLINES_CACHE_TTL 사용&#10;# Redis 사용 가능 시 Redis에 저장, 아니면 메모리 내 딕셔너리에 저장&#10;# 캐시 조회 시 만료 시간 확인&#10;# 반환값: (타임스탬프, 값) 또는 None&#10;def _cache_set(key: str, value: Any, ttl: int = _KLINES_CACHE_TTL):&#10;    &quot;&quot;&quot;Set cache in Redis if available, else in-memory.&quot;&quot;&quot;&#10;    now = time.time()&#10;    if _redis_client:&#10;        try:&#10;            # store JSON string&#10;            import json as _json&#10;            payload = {'ts': now, 'value': value}&#10;            _redis_client.setex(key, ttl, _json.dumps(payload)) # set with expiry&#10;            return&#10;        except Exception:&#10;            pass&#10;    _klines_cache[key] = (now, value) # store in-memory&#10;&#10;# 캐시 조회 함수&#10;# key: 캐시 키&#10;# ttl: 캐시 만료 시간 (초)&#10;# 기본 TTL은 _KLINES_CACHE_TTL 사용&#10;# 반환값: (타임스탬프, 값) 또는 None&#10;def _cache_get(key: str, ttl: int = _KLINES_CACHE_TTL):&#10;    &quot;&quot;&quot;Get cache value. Return (timestamp, value) or None.&quot;&quot;&quot;&#10;    if _redis_client:&#10;        try:&#10;            import json as _json&#10;            s = _redis_client.get(key) # get JSON string&#10;            if not s:&#10;                return None&#10;            obj = _json.loads(s) # parse JSON&#10;            if time.time() - obj.get('ts', 0) &gt; ttl:&#10;                return None&#10;            return (obj.get('ts'), obj.get('value')) # return (timestamp, value)&#10;        except Exception:&#10;            return None&#10;    return _klines_cache.get(key) # return (timestamp, value) or None&#10;&#10;# Websocket listener state&#10;_ws_listener: Optional[PrivateWebsocketListener] = None&#10;_ticker_listener: Optional[PublicWebsocketlistener] = None&#10;&#10;def start_ws_listener() -&gt; None:&#10;    global _ws_listener&#10;    if _ws_listener and _ws_listener._thread and _ws_listener._thread.is_alive():&#10;        return&#10;    _ws_listener = PrivateWebsocketListener(redis_client=_redis_client)&#10;    _ws_listener.start()&#10;&#10;&#10;def start_ticker_listener() -&gt; None:&#10;    global _ticker_listener&#10;    if _ticker_listener and _ticker_listener._thread and _ticker_listener._thread.is_alive():&#10;        return&#10;    _ticker_listener = PublicWebsocketlistener(redis_client=_redis_client)&#10;    _ticker_listener.start()&#10;&#10;&#10;def stop_ws_listener() -&gt; None:&#10;    global _ws_listener&#10;    if _ws_listener:&#10;        _ws_listener.stop()&#10;&#10;&#10;def stop_ticker_listener() -&gt; None:&#10;    global _ticker_listener&#10;    if _ticker_listener:&#10;        _ticker_listener.stop()&#10;&#10;# Rate-limited Upbit klines fetcher&#10;# ticker_local: 업비트 로컬 티커명 (예: KRW-BTC)&#10;# timeframe: 캔들 시간대 (예: 'minute15')&#10;# count: 조회할 캔들 개수&#10;# 반환값: UpbitAPI.get_klines() 결과&#10;# 전역 토큰 버킷 및 세마포어를 사용하여 호출 제한 및 동시성 제어&#10;# 토큰 획득 및 세마포어 획득 시 타임아웃 처리&#10;# 예외 발생 시 호출 실패&#10;# 반환값: UpbitAPI.get_klines() 결과&#10;def _rate_limited_get_klines(ticker_local: str, timeframe: str, count: int):&#10;    # 전역 토큰 버킷 및 세마포어 사용&#10;    global _prefetch_token_bucket, _prefetch_semaphore&#10;&#10;    # 세마포어 및 토큰 획득 시도&#10;    # 타임아웃은 config의 'prefetch_token_wait_timeout' 키로 설정 가능, 기본 10초&#10;    # 실제 Upbit 호출 수행&#10;    # 예외 발생 시 호출 실패&#10;    acquired = False&#10;    try:&#10;        # 세마포어 획득 시도&#10;        if _prefetch_semaphore is not None:&#10;            # 세마포어 획득 (대기 시간 설정 기본값 10초)&#10;            acquired = _prefetch_semaphore.acquire(timeout=10)&#10;            if not acquired:&#10;                raise RuntimeError('prefetch_semaphore_timeout')&#10;&#10;        # 토큰 획득 시도&#10;        if _prefetch_token_bucket is not None:&#10;            # 토큰 대기 시간 설정&#10;            # 기본값 10초 (즉시 호출 선호), config의 'prefetch_token_wait_timeout' 키로 설정 가능&#10;            try:&#10;                token_wait = float(config._config.get('prefetch_token_wait_timeout', 10.0))&#10;            except Exception:&#10;                token_wait = 10.0&#10;            ok = _prefetch_token_bucket.consume(tokens=1.0, timeout=token_wait)&#10;            if not ok:&#10;                raise RuntimeError('rate_limited')&#10;        # 업비트 공용 API 호출 수행&#10;        # 반환값: UpbitAPI.get_klines() 결과&#10;        # 참고: UpbitAPI 인스턴스는 전역 _upbit_public 사용&#10;        # 이 인스턴스는 API 키를 사용하지 않음&#10;        return _upbit_public.get_klines(ticker_local, timeframe, count=count)&#10;    finally:&#10;        if acquired and _prefetch_semaphore is not None:&#10;            try:&#10;                _prefetch_semaphore.release() # 세마포어 해제&#10;            except Exception:&#10;                pass&#10;&#10;&#10;# 업비트 공용 API 인스턴스&#10;_upbit_public = UpbitAPI()&#10;&#10;# 업비트 인증(Private) API 인스턴스&#10;try:&#10;    access = getattr(config, 'UPBIT_ACCESS_KEY', None)&#10;    secret = getattr(config, 'UPBIT_SECRET_KEY', None)&#10;    if access and secret:&#10;        _upbit_private = UpbitAPI(access_key=access, secret_key=secret)&#10;        log.info('Upbit private API initialized with provided keys')&#10;    else:&#10;        _upbit_private = None&#10;        log.warning('Upbit API keys not provided: private endpoints will be unavailable')&#10;except Exception as e:&#10;    _upbit_private = None&#10;    log.warning(f'Failed to initialize Upbit private API: {e}')&#10;&#10;# 스케쥴러 스레드 및 제어 변수&#10;_prefetch_thread: Optional[threading.Thread] = None&#10;_prefetch_stop = threading.Event()&#10;_prefetch_index = 0&#10;&#10;# 루프 함수 - 주기적으로 universe의 티커들에 대해 klines를 미리 가져와 캐시에 저장&#10;# interval: 루프 주기 (초)&#10;# 기본값 30초&#10;def _prefetch_loop(interval: int = 30):&#10;    log.info('Prefetch scheduler started')&#10;    effective_interval = interval&#10;    while not _prefetch_stop.is_set():&#10;        try:&#10;            # 설정 읽기&#10;            cfg = config._config&#10;            # 티커 유니버스&#10;            universe = cfg.get('universe', [])&#10;            # 실행 중 설정 체크 (런타임 config에서 재정의 허용)&#10;            cfg_count = int(cfg.get('prefetch_count', 200))&#10;            # Redis 미사용 시 보수적으로 설정, upper bound 허용&#10;            if _redis_client is None:&#10;                # When Redis is missing, be conservative but allow a configurable upper bound&#10;                # Redis 미사용 시 최대값 설정, 기본 120, config의 'prefetch_no_redis_max_count' 키로 설정 가능&#10;                try:&#10;                    no_redis_max = int(cfg.get('prefetch_no_redis_max_count', 120))&#10;                except Exception:&#10;                    no_redis_max = 120&#10;                count = min(cfg_count, no_redis_max)&#10;                per_ticker_sleep = float(cfg.get('prefetch_sleep_sec', 1.0))&#10;                log.info('Redis not available: using conservative prefetch settings (count=%s, sleep=%.2f)', count, per_ticker_sleep)&#10;            else:&#10;                count = cfg_count&#10;                per_ticker_sleep = float(cfg.get('prefetch_sleep_sec', 0.2))&#10;&#10;            # Redis 미사용 시 최소 간격 보장&#10;            effective_interval = interval&#10;            if _redis_client is None:&#10;                effective_interval = max(interval, int(cfg.get('prefetch_min_interval_sec', 60)))&#10;            if universe:&#10;                # staggered batch processing to avoid bursts&#10;                batch_size = int(cfg.get('prefetch_batch_size', 5))     # batch size per run&#10;                parallelism = int(cfg.get('prefetch_parallelism', 3))   # max parallel fetches per batch&#10;                global _prefetch_index&#10;                n = len(universe)&#10;                if n == 0:&#10;                    pass&#10;                else:&#10;                    start = _prefetch_index % n # start index&#10;                    end = start + batch_size    # end index (exclusive)&#10;                    indices = list(range(start, min(end, n)))&#10;                    # wrap-around if needed&#10;                    if end &gt; n:&#10;                        indices += list(range(0, end - n))&#10;                    tickers_to_process = [universe[i] for i in indices]&#10;                    # advance index for next run&#10;                    _prefetch_index = (start + len(tickers_to_process)) % max(n,1)&#10;&#10;                    # helper to fetch and cache single ticker&#10;                    def _prefetch_single(ticker_local: str):&#10;                        try:&#10;                            key_local = f&quot;{ticker_local}|minute15|{count}&quot;&#10;                            cached_local = _cache_get(key_local)&#10;                            if cached_local and (time.time() - cached_local[0]) &lt; _KLINES_CACHE_TTL:&#10;                                return (ticker_local, True, 'cached')&#10;                            # use rate-limited fetch so prefetch respects global rate/concurrency limits&#10;                            klines_local = _rate_limited_get_klines(ticker_local, 'minute15', count=count)&#10;                            _cache_set(key_local, klines_local, ttl=_KLINES_CACHE_TTL)&#10;                            return (ticker_local, True, 'fetched')&#10;                        except Exception as exc:&#10;                            log.error(f'Prefetch ticker error for {ticker_local}: {exc}')&#10;                            return (ticker_local, False, str(exc))&#10;&#10;                    # run in ThreadPoolExecutor with limited parallelism&#10;                    with ThreadPoolExecutor(max_workers=min(parallelism, len(tickers_to_process))) as executor:&#10;                        futures = {executor.submit(_prefetch_single, t): t for t in tickers_to_process}&#10;                        for fut in as_completed(futures):&#10;                            try:&#10;                                ticker_res, ok, msg = fut.result()&#10;                                log.debug(f'Prefetch result: {ticker_res} ok={ok} info={msg}')&#10;                            except Exception as e:&#10;                                log.error(f'Prefetch future error: {e}')&#10;                    # after parallel batch, small pause to avoid immediate repeated calls&#10;                    time.sleep(per_ticker_sleep)&#10;        except Exception as e:&#10;            log.error(f'Prefetch error: {e}')&#10;        # wait using effective interval (recompute per loop)&#10;        try:&#10;            _prefetch_stop.wait(effective_interval)&#10;        except UnboundLocalError:&#10;            _prefetch_stop.wait(interval)&#10;    log.info('Prefetch scheduler stopped')&#10;&#10;# 스케쥴러 시작 함수&#10;# interval: 루프 주기 (초)&#10;# 기본값 30초&#10;def start_prefetch_scheduler(interval: int = 30):&#10;    global _prefetch_thread, _prefetch_stop&#10;    if _prefetch_thread is not None and _prefetch_thread.is_alive():&#10;        return&#10;    _prefetch_stop.clear()&#10;    # Redis 미사용 시 기본 간격 증가&#10;    # Upbit 호출 부담 축소를 위한 조치&#10;    # 기본 최소 60초&#10;    if _redis_client is None:&#10;        interval = max(interval, 60)&#10;        log.info('Redis not connected: starting prefetch with interval %s seconds', interval)&#10;    # Redis 미사용 시 기본 배치 크기 축소&#10;    if _redis_client is None:&#10;        try:&#10;            # 배치사이즈 기본 3으로 축소, config에 없으면 설정&#10;            if 'prefetch_batch_size' not in config._config:&#10;                config._config['prefetch_batch_size'] = 3&#10;        except Exception:&#10;            pass&#10;    # 프리페치 레이트 리미터 및 세마포어 초기화&#10;    # 설정값 읽기 및 기본값 적용&#10;    global _prefetch_token_bucket, _prefetch_semaphore # 전역 변수&#10;    try:&#10;        # 초당 5토큰&#10;        rate = int(config._config.get('prefetch_rate_per_sec', 5))&#10;    except Exception:&#10;        rate = 5&#10;    try:&#10;        # 용량은 rate와 같게&#10;        capacity = int(config._config.get('prefetch_rate_capacity', max(1, rate)))&#10;    except Exception:&#10;        capacity = max(1, rate)&#10;    try:&#10;        # 동시 3개&#10;        max_concurrent = int(config._config.get('prefetch_max_concurrent', 3))&#10;    except Exception:&#10;        max_concurrent = 3&#10;    try:&#10;        # 토큰 버킷 및 세마포어 초기화&#10;        _prefetch_token_bucket = TokenBucket(rate=float(rate), capacity=float(capacity))&#10;        _prefetch_semaphore = threading.BoundedSemaphore(max_concurrent)&#10;        log.info(f'Prefetch rate limiter initialized: rate={rate}/s, capacity={capacity}, max_concurrent={max_concurrent}')&#10;    except Exception as e:&#10;        _prefetch_token_bucket = None&#10;        _prefetch_semaphore = None&#10;        log.warning(f'Failed to initialize prefetch rate limiter: {e}')&#10;    _prefetch_thread = threading.Thread(target=_prefetch_loop, args=(interval,), daemon=True)&#10;    _prefetch_thread.start()&#10;&#10;# 스케쥴러 중지 함수&#10;# 스케쥴러 스레드 종료 대기 (최대 2초)&#10;# 기본값 30초&#10;def stop_prefetch_scheduler():&#10;    global _prefetch_thread, _prefetch_stop&#10;    _prefetch_stop.set()&#10;    if _prefetch_thread is not None:&#10;        _prefetch_thread.join(timeout=2)&#10;    _prefetch_thread = None&#10;&#10;&#10;@app.get(&quot;/health&quot;) # 헬스체크 엔드포인트&#10;def health():&#10;    return {&quot;status&quot;: &quot;ok&quot;}&#10;&#10;&#10;@app.get('/debug/status') # 디버그 상태 엔드포인트&#10;def debug_status():&#10;    &quot;&quot;&quot;Return diagnostic info: pyupbit presence, redis connection, prefetch thread state, universe size.&quot;&quot;&quot;&#10;    try:&#10;        import server.upbit_api as upbit_api&#10;        has_pyupbit = bool(getattr(upbit_api, '_HAS_PYUPBIT', False))&#10;    except Exception:&#10;        has_pyupbit = False&#10;&#10;    redis_up = False&#10;    try:&#10;        redis_up = _redis_client is not None&#10;    except Exception:&#10;        redis_up = False&#10;&#10;    prefetch_running = False&#10;    try:&#10;        prefetch_running = (_prefetch_thread is not None and _prefetch_thread.is_alive())&#10;    except Exception:&#10;        prefetch_running = False&#10;&#10;    universe_len = 0&#10;    try:&#10;        universe_len = len(config._config.get('universe', []))&#10;    except Exception:&#10;        universe_len = 0&#10;&#10;    return {&#10;        'pyupbit': has_pyupbit,&#10;        'redis': redis_up,&#10;        'prefetch_running': prefetch_running,&#10;        'prefetch_index': _prefetch_index,&#10;        'universe_len': universe_len,&#10;    }&#10;&#10;&#10;@app.get(&quot;/config&quot;) # 설정 조회 엔드포인트&#10;def get_config():&#10;    cfg = config._config&#10;    return {&quot;config&quot;: cfg}&#10;&#10;&#10;@app.post(&quot;/config&quot;) # 설정 저장 엔드포인트&#10;def post_config(payload: ConfigPayload):&#10;    new_cfg = payload.config&#10;    # 기본적인 검증: 반드시 strategy_name과 market이 있어야 함&#10;    if not isinstance(new_cfg, dict) or 'strategy_name' not in new_cfg or 'market' not in new_cfg:&#10;        raise HTTPException(status_code=400, detail=&quot;Invalid config payload. 'strategy_name' and 'market' required.&quot;)&#10;&#10;    success = config.save_config(new_cfg)&#10;    if not success:&#10;        raise HTTPException(status_code=500, detail=&quot;Failed to save configuration&quot;)&#10;&#10;    # 저장 후 재로딩&#10;    config.reload_config()&#10;    return {&quot;status&quot;: &quot;saved&quot;}&#10;&#10;&#10;@app.post(&quot;/reload&quot;) # 설정 재로딩 엔드포인트&#10;def reload_config():&#10;    config.reload_config()&#10;    return {&quot;status&quot;: &quot;reloaded&quot;}&#10;&#10;&#10;# --- Screening endpoints ---&#10;# 변동성 상위 N개 티커 조회&#10;# market_prefix: 마켓 접두사 (기본값 &quot;KRW&quot;)&#10;# top_n: 상위 N개 (기본값 10)&#10;# timeframe: 변동성 계산에 사용할 시간대 (기본값 &quot;minute15&quot;)&#10;# 반환값: 변동성 상위 N개 티커 리스트&#10;# 변동성 계산은 (최고가 - 최저가) / 평균 종가 방식 사용&#10;# Upbit의 공용 kline 엔드포인트 사용&#10;# config.json의 'universe' 키에 티커 리스트가 없으면 기본 샘플 리스트 사용, 폴백 처리&#10;# 반환값: {&quot;top&quot;: [ {&quot;ticker&quot;: 티커명, &quot;volatility&quot;: 변동성}, ... ] }&#10;# 캐시 사용으로 중복 Upbit 호출 최소화&#10;# 캐시 TTL은 _KLINES_CACHE_TTL 사용&#10;# 예외 발생 시 해당 티커는 건너뜀&#10;@app.get(&quot;/screen/volatility_top&quot;) # 변동성 상위 티커 조회 엔드포인트&#10;def volatility_top(market_prefix: str = &quot;KRW&quot;, top_n: int = 10, timeframe: str = &quot;minute15&quot;):&#10;    cfg = config._config # 설정 읽기&#10;    universe = cfg.get('universe', []) # 유니버스 읽기&#10;    if not universe:&#10;        # 폴백: 기본 샘플 유니버스&#10;        universe = [f&quot;{market_prefix}-BTC&quot;, f&quot;{market_prefix}-ETH&quot;, f&quot;{market_prefix}-XRP&quot;, f&quot;{market_prefix}-ADA&quot;, f&quot;{market_prefix}-DOGE&quot;, f&quot;{market_prefix}-SOL&quot;, f&quot;{market_prefix}-DOT&quot;, f&quot;{market_prefix}-MATIC&quot;, f&quot;{market_prefix}-BCH&quot;, f&quot;{market_prefix}-LTC&quot;]&#10;&#10;    results = []&#10;    # Try to use internal cache to avoid hammering Upbit when checking multiple tickers&#10;    now = time.time()&#10;    for ticker in universe:&#10;        # 캐시 키 생성 (가장 최근 15캔들 기준)&#10;        key = f&quot;{ticker}|{timeframe}|15&quot;&#10;        # 캐시 조회&#10;        cached = _cache_get(key)&#10;        # 캐시 유효성 검사&#10;        if cached and (now - cached[0]) &lt; _KLINES_CACHE_TTL: # 캐시 유효 시&#10;            klines = cached[1] # 캐시된 값 사용&#10;        else:&#10;            try:&#10;                # Upbit에서 변동성 계산용 klines 조회 (rate-limited)&#10;                # 15캔들 기준 (폴백 200캔들 아님)&#10;                klines = _rate_limited_get_klines(ticker, timeframe, count=15)&#10;            except Exception as e:&#10;                log.warning(f'Rate-limited fetch failed for {ticker}: {e}')&#10;                klines = None&#10;            # 캐시 설정, None도 캐시하여 반복 실패 방지&#10;            _cache_set(key, klines, ttl=_KLINES_CACHE_TTL)&#10;        if not klines:&#10;            continue&#10;        highs = [float(k['high_price']) for k in klines]&#10;        lows = [float(k['low_price']) for k in klines]&#10;        closes = [float(k['trade_price']) for k in klines]&#10;        # 변동성 계산 : (최고가 - 최저가) / 평균 종가 방식&#10;        try:&#10;            vol = (max(highs) - min(lows)) / (sum(closes) / len(closes))&#10;        except Exception:&#10;            vol = 0&#10;        results.append({'ticker': ticker, 'volatility': vol})&#10;&#10;    # 변동성 기준 내림차순 정렬 후 상위 N개 반환&#10;    results_sorted = sorted(results, key=lambda x: x['volatility'], reverse=True)[:top_n]&#10;    return {&quot;top&quot;: results_sorted}&#10;&#10;&#10;# --- Background Event Watcher ---&#10;# 단순 폴링 기반 워처 구현&#10;# 워처는 별도 스레드에서 동작하며, 지정된 마켓의 klines를 주기적으로 조회&#10;# 지정된 조건에 부합하는 이벤트 발생 시 로그 출력&#10;# 조건은 JSON 배열로 전달되며, 각 조건은 다음과 같은 형태를 가짐&#10;# {&quot;type&quot;: &quot;volatility_breakout&quot;, &quot;k&quot;: 0.5} : 변동성 돌파 이벤트 (Larry Williams 스타일)&#10;# {&quot;type&quot;: &quot;volume_spike&quot;, &quot;multiplier&quot;: 3} : 거래량 급증 이벤트&#10;# 워처 시작 엔드포인트&#10;# 요청 본문 예시:&#10;# {&quot;market&quot;: &quot;KRW-BTC&quot;,&#10;# &quot;interval&quot;: 1,&#10;# &quot;callbacks&quot;:[&#10;#     {&quot;type&quot;:&quot;volatility_breakout&quot;, &quot;k&quot;:0.5},&#10;#     {&quot;type&quot;:&quot;volume_spike&quot;, &quot;multiplier&quot;:3}&#10;# ]}&#10;# 워처 중지 엔드포인트&#10;def _watcher_loop(stop_event, market: str, check_interval: float, callbacks: List[dict]):&#10;    &quot;&quot;&quot;Simple polling watcher that fetches latest klines and invokes callbacks when conditions met.&quot;&quot;&quot;&#10;    log.info(f&quot;Starting watcher loop for {market} (interval {check_interval}s)&quot;)&#10;    last_checked_time = None&#10;    while not stop_event.is_set():&#10;        try:&#10;            try:&#10;                # Upbit에서 최신 60캔들 조회 (rate-limited)&#10;                klines = _rate_limited_get_klines(market, 'minute1', count=60)&#10;            except Exception as e:&#10;                log.error(f'Watcher fetch rate-limited or failed for {market}: {e}')&#10;                klines = None&#10;&#10;            # 이벤트 체크&#10;            if klines:&#10;                # 최근 캔들&#10;                latest = klines[0]&#10;                # 변동성 체크용 15캔들 윈도우 준비&#10;                window = klines[:15]&#10;                highs = [float(k['high_price']) for k in window]&#10;                lows = [float(k['low_price']) for k in window]&#10;                volumes = [float(k['candle_acc_trade_volume']) for k in window]&#10;                closes = [float(k['trade_price']) for k in window]&#10;&#10;                # 변동성 돌파 체크 (간단화된 Larry Williams 스타일)&#10;                try:&#10;                    prev_close = closes[1]&#10;                    curr_close = closes[0]&#10;                    volatility_range = max(highs) - min(lows)&#10;                except Exception:&#10;                    prev_close = curr_close = volatility_range = None&#10;&#10;                # 콜백 조건 체크&#10;                if prev_close is not None and curr_close is not None: # 유효한 데이터 시&#10;                    avg_vol = sum(volumes[1:]) / (len(volumes)-1) if len(volumes) &gt; 1 else 0&#10;                    statuses = []&#10;                    for cb in callbacks:&#10;                        cb_type = cb.get('type')&#10;                        # 변동성 돌파 체크&#10;                        if cb_type == 'volatility_breakout':&#10;                            k = cb.get('k', 0.5)&#10;                            triggered = curr_close &gt; (prev_close + volatility_range * k)&#10;                            status = (&#10;                                f&quot;volatility_breakout(k={k}) current={curr_close:.0f} prev={prev_close:.0f} &quot;&#10;                                f&quot;range={volatility_range:.0f} triggered={triggered}&quot;&#10;                            )&#10;                            statuses.append(status)&#10;                            if triggered:&#10;                                log.info(f&quot;Watcher detected volatility breakout on {market} (k={k})&quot;)&#10;                        # 거래량 급증 체크&#10;                        elif cb_type == 'volume_spike':&#10;                            multiplier = cb.get('multiplier', 3)&#10;                            triggered = avg_vol and volumes[0] &gt; avg_vol * multiplier&#10;                            status = (&#10;                                f&quot;volume_spike(mult={multiplier}) current_vol={volumes[0]:.0f} avg_vol={avg_vol:.0f} &quot;&#10;                                f&quot;triggered={bool(triggered)}&quot;&#10;                            )&#10;                            statuses.append(status)&#10;                            if triggered:&#10;                                log.info(f&quot;Watcher detected volume spike on {market} (x{multiplier})&quot;)&#10;                        else:&#10;                            statuses.append(f&quot;unknown callback {cb}&quot;)&#10;                    config_desc = (f&quot;market={market} interval={check_interval}s callbacks={len(callbacks)}&quot;)&#10;                    log.info(f&quot;WatcherCheck: {config_desc} | { ' ; '.join(statuses)}&quot;)&#10;&#10;            time.sleep(check_interval)&#10;        except Exception as e:&#10;            log.error(f&quot;Error in watcher loop: {e}&quot;)&#10;            time.sleep(check_interval)&#10;    log.info(&quot;Watcher loop stopped.&quot;)&#10;&#10;# 워처 시작 엔드포인트&#10;# 요청 본문 예시:&#10;# {&quot;market&quot;: &quot;KRW-BTC&quot;,&#10;# &quot;interval&quot;: 1,&#10;# &quot;callbacks&quot;:[&#10;#     {&quot;type&quot;:&quot;volatility_breakout&quot;, &quot;k&quot;:0.5},&#10;#     {&quot;type&quot;:&quot;volume_spike&quot;, &quot;multiplier&quot;:3}&#10;# ]}&#10;@app.post(&quot;/watcher/start&quot;) # 워처 시작 엔드포인트&#10;def start_watcher(payload: Dict[str, Any]):&#10;    if _watcher['running']:&#10;        raise HTTPException(status_code=400, detail=&quot;Watcher already running&quot;)&#10;&#10;    # 파라미터 추출&#10;    market = payload.get('market', config.MARKET)   # 마켓 (기본값 config.MARKET)&#10;    interval = float(payload.get('interval', 1.0))  # 체크 간격 (초)&#10;    callbacks = payload.get('callbacks', [])        # 콜백 조건 리스트&#10;&#10;    # 워처 스레드 시작&#10;    stop_event = threading.Event()&#10;    # 워처 루프 스레드 생성 및 시작&#10;    t = threading.Thread(target=_watcher_loop, args=(stop_event, market, interval, callbacks), daemon=True)&#10;    _watcher['running'] = True              # 워처 상태 갱신&#10;    _watcher['thread'] = t                  # 워처 스레드 저장&#10;    _watcher['stop_event'] = stop_event     # 중지 이벤트 저장&#10;    t.start()&#10;    return {&quot;status&quot;: &quot;started&quot;}&#10;&#10;# 워처 중지 엔드포인트&#10;# 워처 중지 이벤트 설정 및 스레드 종료 대기&#10;# 워처 상태 초기화&#10;# 반환값: {&quot;status&quot;: &quot;stopped&quot;} 또는 {&quot;status&quot;: &quot;not_running&quot;}&#10;@app.post(&quot;/watcher/stop&quot;)&#10;def stop_watcher():&#10;    if not _watcher['running']:&#10;        return {&quot;status&quot;: &quot;not_running&quot;}&#10;    _watcher['stop_event'].set()&#10;    _watcher['thread'].join(timeout=5)&#10;    _watcher['running'] = False&#10;    _watcher['thread'] = None&#10;    _watcher['stop_event'] = None&#10;    return {&quot;status&quot;: &quot;stopped&quot;}&#10;&#10;# 배치 klines 조회 엔드포인트&#10;# 티커/타임프레임/카운트 조합별로 캐시 키 생성 (인메모리 또는 Redis)&#10;# 요청 본문 예시:&#10;# {&quot;tickers&quot;: [&quot;KRW-BTC&quot;,&quot;KRW-ETH&quot;], &quot;timeframe&quot;:&quot;minute15&quot;, &quot;count&quot;:100}&#10;# 반환값 예시:&#10;# {&quot;klines&quot;: {&quot;KRW-BTC&quot;: [...], &quot;KRW-ETH&quot;: [...]} }&#10;# 각 티커별로 klines를 조회하여 결과 딕셔너리에 저장&#10;# 내부적으로 캐시를 사용하여 중복 Upbit 호출 최소화&#10;# 캐시 TTL은 _KLINES_CACHE_TTL 사용&#10;# 캐시 미스 시 rate-limited fetcher를 사용하여 Upbit에서 klines 조회&#10;# 예외 발생 시 해당 티커는 None으로 설정&#10;@app.post('/klines_batch')&#10;def klines_batch(payload: KlinesBatchRequest):&#10;    req = payload.model_dump()&#10;    tickers = req.get('tickers', []) or []&#10;    timeframe = req.get('timeframe', 'minute15')&#10;    count = int(req.get('count', 100))&#10;&#10;    result = {}&#10;    now = time.time()&#10;    for ticker in tickers:&#10;        key = f&quot;{ticker}|{timeframe}|{count}&quot; # 캐시 키 생성&#10;        cached = _cache_get(key)&#10;        # 캐시 유효성 검사&#10;        # 캐시 유효 시 캐시된 값 사용&#10;        if cached and (now - cached[0]) &lt; _KLINES_CACHE_TTL:&#10;            result[ticker] = cached[1]&#10;            continue&#10;&#10;        # 카운트 이상인 캐시 항목 검색 시도 (인메모리 및 Redis 모두 지원)&#10;        # 가장 큰 count를 가진 항목 선택&#10;        # 캐시 미스 시 rate-limited fetcher 사용&#10;        klines = None&#10;        try:&#10;            # 가능한 경우 Redis에서 검색&#10;            if _redis_client:&#10;                try:&#10;                    pattern = f&quot;{ticker}|{timeframe}|*&quot;&#10;                    # 패턴 매칭 키 조회&#10;                    keys = _redis_client.keys(pattern)&#10;                    # 후보 탐색 및 선택 (요청보다 가장 큰 count)&#10;                    best = None&#10;                    best_cnt = 0&#10;                    for k in keys:&#10;                        try:&#10;                            # 키 파싱 [ticker, timeframe, count]&#10;                            parts = k.split('|')&#10;&#10;                            # 유효한 키 형식 시 (3개 이상 파트로 구성)&#10;                            if len(parts) &gt;= 3:&#10;                                # count 부분 (마지막 부분)&#10;                                kcnt = int(parts[-1])&#10;                                # 요청한 카운트보다 크고 현재 최상위 후보보다 큰 경우&#10;                                if kcnt &gt;= count and kcnt &gt; best_cnt:&#10;                                    best = k        # 후보 키 갱신&#10;                                    best_cnt = kcnt # 후보 카운트 갱신&#10;                        except Exception:&#10;                            continue&#10;                    # 후보 키가 발견된 경우&#10;                    if best:&#10;                        # 후보 키로 캐시 조회&#10;                        cached2 = _cache_get(best, ttl=_KLINES_CACHE_TTL)&#10;                        # 후보 캐시에서 klines 추출&#10;                        if cached2:&#10;                            klines_full = cached2[1]&#10;                            # 유효한 klines 시&#10;                            if isinstance(klines_full, list) and len(klines_full) &gt; 0:&#10;                                # 요청한 개수만큼 슬라이싱하여 반환&#10;                                klines = klines_full[-count:]&#10;                except Exception:&#10;                    pass&#10;            else:&#10;                # 인-메모리 캐시에서 후보 탐색&#10;                try:&#10;                    candidates = []&#10;                    # 인-메모리 캐시 순회&#10;                    for k, v in list(_klines_cache.items()):&#10;                        try:&#10;                            # 키 파싱 [ticker, timeframe, count]&#10;                            parts = k.split('|')&#10;                            # 유효한 키 형식 시 (3개 이상 파트로 구성)&#10;                            if parts[0] == ticker and parts[1] == timeframe:&#10;                                kcnt = int(parts[2])            # count 부분&#10;                                candidates.append((kcnt, v))    # 후보 리스트에 추가&#10;                        except Exception:&#10;                            continue&#10;                    # 후보 정렬 및 선택 (요청보다 큰 count)&#10;                    candidates = sorted(candidates, key=lambda x: x[0], reverse=True) # 내림차순 정렬&#10;                    for kcnt, v in candidates:&#10;                        if kcnt &gt;= count:&#10;                            klines_full = v[1]&#10;                            # 유효한 klines 시&#10;                            if isinstance(klines_full, list) and len(klines_full) &gt; 0:&#10;                                # 요청한 개수만큼 슬라이싱하여 반환&#10;                                klines = klines_full[-count:]&#10;                                break&#10;                except Exception:&#10;                    pass&#10;&#10;            # 캐시에서 발견되지 않은 경우 rate-limited fetcher 사용&#10;            if klines is None:&#10;                try:&#10;                    klines = _rate_limited_get_klines(ticker, timeframe, count=count)&#10;                except Exception as e:&#10;                    log.warning(f'Rate-limited batch fetch failed for {ticker}: {e}')&#10;                    klines = None&#10;        except Exception as e:&#10;            log.warning(f'klines_batch lookup error for {ticker}: {e}')&#10;            klines = None&#10;&#10;        # 캐시 설정 (실패 시에도 캐시하여 반복 실패 방지)&#10;        _cache_set(key, klines, ttl=_KLINES_CACHE_TTL)&#10;        result[ticker] = klines&#10;&#10;    return {'klines': result}&#10;&#10;# --- Private API Endpoints ---&#10;# 잔고 조회 엔드포인트&#10;# Upbit 개인 API 키를 사용하여 잔고 조회&#10;# 키가 구성되지 않은 경우 503 반환&#10;# 이 엔드포인트는 짧은 TTL(_BALANCES_CACHE_TTL)로 잔고를 캐시하여 반복된 Upbit 호출을 줄임&#10;# 반환값에는 추가 진단 필드 포함:&#10;#   - balances: Upbit에서 반환된 원시 잔고 리스트&#10;#   - reported_krw_balance: 잔고에서 보고된 KRW 잔고 (없으면 0)&#10;#   - cached: 응답이 서버 캐시에서 왔는지 여부&#10;#   - cached_ts: 캐시된 시점 타임스탬프&#10;@app.get('/balances')&#10;def get_balances():&#10;    # 잔고 조회 엔드포인트&#10;    if _upbit_private is None:&#10;        raise HTTPException(status_code=503, detail='Upbit API keys not configured on server; balances unavailable')&#10;&#10;    cache_key = 'upbit:balances:all'&#10;    now = time.time()&#10;&#10;    # 캐시 조회 시도&#10;    cached = _cache_get(cache_key, ttl=_BALANCES_CACHE_TTL)&#10;    if cached and (now - cached[0]) &lt; _BALANCES_CACHE_TTL:&#10;        bl = cached[1]&#10;        cached_flag = True&#10;        cached_ts = cached[0]&#10;        log.debug('Balances: cache hit')&#10;    else:&#10;        cached_flag = False&#10;        cached_ts = None&#10;        try:&#10;            bl = _upbit_private.get_balances()&#10;        except Exception as e:&#10;            log.error(f'Balances retrieval failed: {e}')&#10;            # 캐시가 존재하면 캐시된 값 반환 (최선의 노력)&#10;            if cached:&#10;                bl = cached[1]&#10;                cached_flag = True&#10;                cached_ts = cached[0]&#10;            else:&#10;                raise HTTPException(status_code=502, detail=f'Upbit API call failed: {e}')&#10;        # 캐시 설정 (실패 시에도 캐시하여 반복 실패 방지)&#10;        _cache_set(cache_key, bl, ttl=_BALANCES_CACHE_TTL)&#10;&#10;    # KRW 잔고 계산 (반환된 잔고에서)&#10;    # 'currency' 또는 'unit' 필드 사용&#10;    reported_krw = 0.0&#10;    try:&#10;        if isinstance(bl, list):&#10;            for item in bl:&#10;                # 업비트API /v1/accounts는 'currency'와 'balance' 필드를 가진 항목 반환&#10;                try:&#10;                    cur = str(item.get('currency') or item.get('unit') or '').upper()&#10;                    bal = float(item.get('balance') or 0.0)&#10;                except Exception:&#10;                    continue&#10;                if cur == 'KRW' or cur.startswith('KRW'):&#10;                    reported_krw += bal&#10;        elif isinstance(bl, dict):&#10;            # 딕셔너리 형태인 경우 'balances' 키에서 리스트 추출&#10;            lst = bl.get('balances') if 'balances' in bl else None&#10;            if isinstance(lst, list):&#10;                for item in lst:&#10;                    try:&#10;                        cur = str(item.get('currency') or item.get('unit') or '').upper()&#10;                        bal = float(item.get('balance') or 0.0)&#10;                    except Exception:&#10;                        continue&#10;                    if cur == 'KRW' or cur.startswith('KRW'):&#10;                        reported_krw += bal&#10;    except Exception:&#10;        reported_krw = 0.0&#10;&#10;    return {&#10;        'balances': bl,&#10;        'reported_krw_balance': reported_krw,&#10;        'cached': bool(cached_flag),&#10;        'cached_ts': cached_ts,&#10;    }&#10;&#10;# 포지션 조회 엔드포인트&#10;# Upbit 개인 API 키를 사용하여 잔고 조회 후 현재 가격과 결합하여 포지션 계산&#10;# 키가 구성되지 않은 경우 503 반환&#10;# 각 자산별 포지션 정보와 요약 총계 반환&#10;# 포지션 정보에는 다음 필드 포함:&#10;#   - symbol: 마켓 심볼 (예: KRW-BTC)&#10;#   - side: 포지션 방향 (항상 'LONG'으로 설정)&#10;#   - size: 보유 수량&#10;#   - entry_price: 평균 매수가 (없으면 null)&#10;#   - current_price: 현재 가격&#10;#   - unrealized_pnl: 미실현 손익 (없으면 null)&#10;#   - unrealized_pnl_rate: 미실현 손익률 (없으면 null)&#10;#   - notional_krw: 원화 기준 명목 가치&#10;# 요약 정보에는 다음 필드 포함:&#10;#   - total_equity_krw: 총 자산 가치 (원화 기준)&#10;#   - available_krw: 사용 가능한 원화 잔고&#10;#   - prices_fetched: 현재 가격을 성공적으로 조회한 자산 수&#10;#   - excluded_assets: 현재 가격을 조회하지 못해 제외된 자산 목록 (심볼 및 사유 포함)&#10;# 포지션 스냅샷은 히스토리 스토어에 기록됨&#10;# 반환값 예시:&#10;# {&#10;#   &quot;positions&quot;: [ {...}, {...}, ... ],&#10;#   &quot;total_equity_krw&quot;: 12345678.9,&#10;#   &quot;available_krw&quot;: 2345678.9,&#10;#   &quot;prices_fetched&quot;: 5,&#10;#   &quot;excluded_assets&quot;: [ {&quot;symbol&quot;: &quot;KRW-XYZ&quot;, &quot;reason&quot;: &quot;no_price&quot;}, ... ]&#10;# }&#10;@app.get(&quot;/positions&quot;)&#10;def get_positions():&#10;    if _upbit_private is None:&#10;        raise HTTPException(status_code=503, detail='Upbit API keys not configured on server; positions unavailable')&#10;&#10;    try:&#10;        bl = _upbit_private.get_balances() or []&#10;    except Exception as e:&#10;        log.error(f'Failed to retrieve balances for positions endpoint: {e}')&#10;        raise HTTPException(status_code=502, detail=f'Failed to retrieve balances: {e}')&#10;&#10;    positions = []&#10;    total_equity = 0.0&#10;    available_krw = 0.0&#10;&#10;    #시장리스트 작성 및 통화맵 작성 (가격 조회용)&#10;    markets = []&#10;    currency_map = {}&#10;    try:&#10;        for item in bl:&#10;            cur = str(item.get('currency') or item.get('unit') or '').upper()&#10;            bal = float(item.get('balance') or 0) if item is not None else 0.0&#10;            locked = float(item.get('locked') or 0) if item is not None else 0.0&#10;&#10;            # 원화 현금잔고 처리&#10;            if cur == 'KRW' or cur.startswith('KRW'):&#10;                available_krw += bal&#10;                total_equity += bal&#10;                continue&#10;            size = bal + locked&#10;            if size &lt;= 0:&#10;                continue&#10;            market = f'KRW-{cur}'&#10;            markets.append(market)&#10;            currency_map[market] = {&#10;                'currency': cur,&#10;                'size': size,&#10;                'avg_buy_price': float(item.get('avg_buy_price') or 0)&#10;            }&#10;    except Exception as e:&#10;        log.warning(f'Error while parsing balances for positions: {e}')&#10;&#10;    # 현재가격 조회 (1개 캔들 minute1, count=1) (조회수 제한 주의)&#10;    price_map = {}&#10;    for m in set(markets):&#10;        try:&#10;            kl = None&#10;            try:&#10;                kl = _rate_limited_get_klines(m, 'minute1', count=1)&#10;            except Exception as e:&#10;                log.warning(f'Price fetch failed for {m}: {e}')&#10;                kl = None&#10;            price = None&#10;            if kl and isinstance(kl, list) and len(kl) &gt; 0:&#10;                try:&#10;                    first = kl[0]&#10;                    price_candidate = None&#10;&#10;                    # 딕셔너리 레코드 작업&#10;                    # (Upbit API는 'trade_price' 사용)&#10;                    if isinstance(first, dict):&#10;                        price_candidate = first.get('trade_price') or first.get('close')&#10;                    else:&#10;                        # 속성 접근 시도 (일부 래퍼는 .close 또는 .trade_price 노출 가능)&#10;                        price_candidate = getattr(first, 'trade_price', None) or getattr(first, 'close', None)&#10;                    if price_candidate is None:&#10;                        price = None&#10;                    else:&#10;                        price = float(price_candidate)&#10;                except Exception:&#10;                    price = None&#10;            price_map[m] = price&#10;        except Exception as e:&#10;             log.warning(f'Unexpected error fetching price for {m}: {e}')&#10;             price_map[m] = None&#10;&#10;    # 포지션 구성 및 미실현 손익/명목 가치 계산&#10;    excluded_assets = []&#10;    for market, meta in currency_map.items():&#10;        cur = meta['currency']&#10;        size = float(meta['size'])&#10;        avg_price = float(meta.get('avg_buy_price') or 0.0)&#10;        current_price = price_map.get(market)&#10;&#10;        # 자산 현재 가격이 없으면 건너뛰고 보고&#10;        if current_price is None:&#10;            excluded_assets.append({'symbol': market, 'reason': 'no_price'})&#10;            continue&#10;&#10;        notional = size * float(current_price)&#10;        total_equity += notional&#10;        unrealized = None&#10;        unrealized_rate = None&#10;        if avg_price and avg_price &gt; 0:&#10;            unrealized = (float(current_price) - avg_price) * size&#10;            unrealized_rate = (float(current_price) - avg_price) / avg_price * 100&#10;&#10;        pos = {&#10;            'symbol': market,&#10;            'side': 'LONG',&#10;            'size': size,&#10;            'entry_price': avg_price if avg_price &gt; 0 else None,&#10;            'current_price': current_price,&#10;            'unrealized_pnl': unrealized,&#10;            'unrealized_pnl_rate': unrealized_rate,&#10;            'notional_krw': notional,&#10;        }&#10;        positions.append(pos)&#10;&#10;    # Also include list of excluded assets so UI can show a friendly message.&#10;    result = {&#10;        'positions': positions,&#10;        'total_equity_krw': total_equity,&#10;        'available_krw': available_krw,&#10;        'prices_fetched': len([p for p in price_map.values() if p is not None]),&#10;        'excluded_assets': excluded_assets,&#10;    }&#10;    history_store.record_snapshot({&#10;        'ts': time.time(),&#10;        'total_equity': total_equity,&#10;        'available_krw': available_krw,&#10;        'positions': [&#10;            {&#10;                'symbol': pos['symbol'],&#10;                'notional_krw': pos['notional_krw'],&#10;                'unrealized_pnl': pos['unrealized_pnl'],&#10;            }&#10;            for pos in positions&#10;        ],&#10;    })&#10;    return result&#10;&#10;&#10;@app.get('/ai/history')&#10;def get_ai_history(limit: int = 50):&#10;    try:&#10;        limit = max(1, min(int(limit), 200))&#10;    except Exception:&#10;        limit = 50&#10;    history = ai_history_store.get_history(limit=limit)&#10;    return {'items': history}&#10;&#10;&#10;@app.get('/positions/history')&#10;def get_positions_history(limit: int = 365, days: int = 365):&#10;    since = time.time() - float(days) * 86400&#10;    history = history_store.get_history(since=since, limit=limit)&#10;    return {'history': history}&#10;&#10;&#10;@app.post('/ws/start')&#10;def ws_start():&#10;    try:&#10;        start_ws_listener()&#10;        start_ticker_listener()&#10;        return {'status': 'started'}&#10;    except Exception as exc:&#10;        raise HTTPException(status_code=500, detail=f'Failed to start websocket listener: {exc}')&#10;&#10;@app.post('/ws/stop')&#10;def ws_stop():&#10;    try:&#10;        stop_ws_listener()&#10;        stop_ticker_listener()&#10;        return {'status': 'stopped'}&#10;    except Exception as exc:&#10;        raise HTTPException(status_code=500, detail=f'Failed to stop websocket listener: {exc}')&#10;&#10;@app.get('/ws/status')&#10;def ws_status():&#10;    running = bool(_ws_listener and _ws_listener._thread and _ws_listener._thread.is_alive())&#10;    return {'running': running, 'targets': _ws_listener.targets if _ws_listener else []}&#10;&#10;@app.get('/ws/stats')&#10;def ws_stats(last_hour_sec: int = 3600, recent_limit: int = 10):&#10;    raw_stats = load_ws_stats()&#10;    summary = summarize_ws_stats(raw_stats, last_hour_secs=last_hour_sec, recent_limit=recent_limit)&#10;    summary.update({&#10;        'running': bool(_ws_listener and _ws_listener._thread and _ws_listener._thread.is_alive()),&#10;        'targets': _ws_listener.targets if _ws_listener else [],&#10;    })&#10;    return summary&#10;&#10;@app.get('/ws/executions')&#10;def ws_executions(limit: int = 0):&#10;    try:&#10;        entries = read_exec_history(limit=limit)&#10;    except Exception as exc:&#10;        raise HTTPException(status_code=500, detail=f'Failed to load exec history: {exc}')&#10;    return {'executions': entries}&#10;&#10;@app.get('/ws/trades')&#10;def ws_trades(symbol: str, limit: int = 20):&#10;    if _redis_client is None:&#10;        raise HTTPException(status_code=503, detail='Redis cache unavailable; cannot read trades.')&#10;    if not symbol:&#10;        raise HTTPException(status_code=400, detail='symbol query parameter is required.')&#10;    max_limit = min(max(limit, 1), 200)&#10;    key = f'ws:trades:{symbol}'&#10;    raw = _redis_client.lrange(key, 0, max_limit - 1)&#10;    trades = []&#10;    try:&#10;        for item in raw:&#10;            import json as _json&#10;            trades.append(_json.loads(item))&#10;    except Exception:&#10;        trades = []&#10;    return {'symbol': symbol, 'trades': trades}&#10;&#10;&#10;def _ws_ticker_targets() -&gt; List[str]:&#10;    if _ws_listener:&#10;        return _ws_listener.targets&#10;    universe = config._config.get('universe')&#10;    if isinstance(universe, list) and universe:&#10;        return universe&#10;    return [&#10;        'KRW-BTC',&#10;        'KRW-ETH',&#10;        'KRW-ADA',&#10;        'KRW-XRP',&#10;        'KRW-SOL',&#10;    ]&#10;&#10;&#10;@app.get('/ws/ticker_data')&#10;def ws_ticker_data():&#10;    if _redis_client is None:&#10;        raise HTTPException(status_code=503, detail='Redis cache unavailable; cannot read ticker data.')&#10;    targets = _ws_ticker_targets()&#10;    payloads: List[Dict[str, Any]] = []&#10;    for symbol in targets:&#10;        key = f'ws:ticker:{symbol}'&#10;        raw = _redis_client.get(key)&#10;        if not raw:&#10;            continue&#10;        try:&#10;            data = json.loads(raw)&#10;        except Exception:&#10;            continue&#10;        payloads.append({&#10;            'symbol': symbol,&#10;            'opening_price': data.get('opening_price'),&#10;            'high_price': data.get('high_price'),&#10;            'low_price': data.get('low_price'),&#10;            'trade_price': data.get('trade_price') or data.get('trade_price'),&#10;            'prev_closing_price': data.get('prev_closing_price'),&#10;            'change': data.get('change'),&#10;            'timestamp': data.get('trade_timestamp') or data.get('timestamp'),&#10;        })&#10;    return {'tickers': payloads}&#10;&#10;# --- Trading Bot Control API ---&#10;&#10;# 봇 실행 중 여부 확인&#10;def _bot_running():&#10;    return config.BOT_ENABLED&#10;&#10;&#10;@app.post('/bot/control')&#10;def bot_control(payload: Dict[str, Any]):&#10;    enabled = payload.get('enabled')&#10;    interval = payload.get('interval_sec')&#10;    if enabled is None and interval is None:&#10;        raise HTTPException(status_code=400, detail='enabled or interval_sec required')&#10;    try:&#10;        updated = config.update_bot_control(bot_enabled=enabled, bot_interval_sec=interval)&#10;    except Exception as exc:&#10;        raise HTTPException(status_code=500, detail=f'Failed to update bot config: {exc}')&#10;    return {'status': 'updated', 'bot_enabled': config.BOT_ENABLED, 'bot_interval_sec': config.BOT_INTERVAL_SEC, 'updated': updated}&#10;&#10;&#10;@app.get('/bot/status')&#10;def bot_status():&#10;    return {&#10;        'bot_enabled': config.BOT_ENABLED,&#10;        'bot_interval_sec': config.BOT_INTERVAL_SEC,&#10;        'running': config.BOT_ENABLED,&#10;    }&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/server/config.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/server/config.py" />
              <option name="originalContent" value="import os&#10;import json&#10;from dotenv import load_dotenv&#10;from typing import Dict, Any, Optional&#10;from server.logger import log&#10;&#10;# --- 1. .env 파일에서 민감 정보 로드 ---&#10;# server 디렉토리 기준으로 .env 파일 경로 설정&#10;dotenv_path = os.path.join(os.path.dirname(__file__), '.env')&#10;if os.path.exists(dotenv_path):&#10;    load_dotenv(dotenv_path)&#10;    log.info(&quot;.env file loaded successfully.&quot;)&#10;else:&#10;    log.warning(&quot;server/.env file not found. Please create one with your API keys.&quot;)&#10;&#10;# 환경 변수에서 API 키 가져오기 (따옴표/공백 제거)&#10;def _read_env(key: str) -&gt; str | None:&#10;    val = os.getenv(key)&#10;    if val is None:&#10;        return None&#10;    val = val.strip()&#10;    if (val.startswith('&quot;') and val.endswith('&quot;')) or (val.startswith(&quot;'&quot;) and val.endswith(&quot;'&quot;)):&#10;        val = val[1:-1]&#10;    return val or None&#10;&#10;UPBIT_ACCESS_KEY = _read_env(&quot;UPBIT_ACCESS_KEY&quot;)&#10;UPBIT_SECRET_KEY = _read_env(&quot;UPBIT_SECRET_KEY&quot;)&#10;OPENAI_API_KEY = _read_env(&quot;OPENAI_API_KEY&quot;)&#10;GEMINI_API_KEY = _read_env(&quot;GEMINI_API_KEY&quot;)&#10;&#10;# --- 2. runtime/config.json 파일에서 설정 파라미터 로드 ---&#10;def _get_runtime_config_path():&#10;    project_root = os.path.dirname(os.path.dirname(__file__))&#10;    return os.path.join(project_root, 'runtime', 'config.json')&#10;&#10;&#10;def _migrate_config_schema(cfg: Dict[str, Any]) -&gt; Dict[str, Any]:&#10;    &quot;&quot;&quot;Normalize legacy config keys to the current schema without mutating the original dict.&quot;&quot;&quot;&#10;    normalized = json.loads(json.dumps(cfg)) if isinstance(cfg, dict) else {}&#10;    strategy_params = normalized.setdefault('strategy_params', {})&#10;    vb_params = strategy_params.setdefault('VolatilityBreakout', {})&#10;    legacy = normalized.pop('vb_target_vol_pct', None)&#10;    if 'target_vol_pct' not in vb_params and legacy is not None:&#10;        try:&#10;            vb_params['target_vol_pct'] = float(legacy)&#10;        except (TypeError, ValueError):&#10;            vb_params['target_vol_pct'] = 30.0&#10;    if 'target_vol_pct' not in vb_params:&#10;        vb_params['target_vol_pct'] = 30.0&#10;    ai_ensemble = normalized.setdefault('ai_ensemble', {}) if isinstance(normalized.get('ai_ensemble'), dict) else {}&#10;    base_strategy = str(ai_ensemble.get('strategy', 'UNANIMOUS')).upper()&#10;    buy_strategy = str(ai_ensemble.get('buy_strategy', '')).upper()&#10;    sell_strategy = str(ai_ensemble.get('sell_strategy', '')).upper()&#10;    if not buy_strategy:&#10;        buy_strategy = base_strategy&#10;    if not sell_strategy:&#10;        sell_strategy = base_strategy&#10;    ai_ensemble['buy_strategy'] = buy_strategy or 'UNANIMOUS'&#10;    ai_ensemble['sell_strategy'] = sell_strategy or 'UNANIMOUS'&#10;    try:&#10;        ai_ensemble['average_threshold'] = float(ai_ensemble.get('average_threshold', 0.5))&#10;    except (TypeError, ValueError):&#10;        ai_ensemble['average_threshold'] = 0.5&#10;    normalized['ai_ensemble'] = ai_ensemble&#10;    return normalized&#10;&#10;&#10;def load_config() -&gt; Dict[str, Any]:&#10;    &quot;&quot;&quot;config.json 파일에서 설정을 로드하여 반환합니다.&quot;&quot;&quot;&#10;    config_path = _get_runtime_config_path()&#10;    try:&#10;        with open(config_path, 'r', encoding='utf-8') as f:&#10;            config_data = json.load(f)&#10;        log.info(&quot;runtime/config.json file loaded successfully.&quot;)&#10;        return _migrate_config_schema(config_data)&#10;    except FileNotFoundError:&#10;        log.error(&quot;runtime/config.json not found! Please create a configuration file in runtime directory.&quot;)&#10;        return {}&#10;    except json.JSONDecodeError:&#10;        log.error(&quot;Error decoding runtime/config.json. Please check for syntax errors.&quot;)&#10;        return {}&#10;&#10;&#10;def save_config(new_config: Dict[str, Any]) -&gt; bool:&#10;    &quot;&quot;&quot;config.json 파일에 설정을 저장합니다. 안전을 위해 기존 파일을 백업합니다.&#10;&#10;    :param new_config: 저장할 설정 딕셔너리&#10;    :return: 저장 성공 여부&#10;    &quot;&quot;&quot;&#10;    config_path = _get_runtime_config_path()&#10;    backup_path = config_path + '.bak'&#10;    try:&#10;        # 기존 파일 백업&#10;        if os.path.exists(config_path):&#10;            os.replace(config_path, backup_path)&#10;            log.info(f&quot;Existing config.json backed up to {backup_path}&quot;)&#10;&#10;        normalized = _migrate_config_schema(new_config)&#10;        with open(config_path, 'w', encoding='utf-8') as f:&#10;            json.dump(normalized, f, ensure_ascii=False, indent=2)&#10;        log.info(&quot;New configuration saved to runtime/config.json&quot;)&#10;        return True&#10;    except Exception as e:&#10;        log.error(f&quot;Failed to save runtime/config.json: {e}&quot;)&#10;        # 백업 복원 시도&#10;        if os.path.exists(backup_path):&#10;            os.replace(backup_path, config_path)&#10;            log.info(&quot;Restored original config.json from backup due to failure.&quot;)&#10;        return False&#10;&#10;&#10;# 즉시 로드하여 전역 설정 변수로 노출&#10;_config = load_config()&#10;&#10;&#10;def _sync_globals_from_config(cfg: Dict[str, Any]):&#10;    &quot;&quot;&quot;로드된 `_config` 딕셔너리의 값을 모듈 전역 변수로 동기화합니다.&#10;    이 함수는 `reload_config()` 호출 시 기존 전역 변수들이 최신 값으로 갱신되도록 보장합니다.&#10;    &quot;&quot;&quot;&#10;    global STRATEGY_NAME, MARKET, TIMEFRAME, CANDLE_COUNT, LOOP_INTERVAL_SEC&#10;    global MIN_ORDER_AMOUNT, TRADE_AMOUNT_KRW, SELL_RATIO&#10;    global USE_KELLY_CRITERION, KELLY_WIN_RATE, KELLY_PAYOFF_RATIO, KELLY_FRACTION&#10;    global RSI_PERIOD, RSI_OVERSOLD, RSI_OVERBOUGHT&#10;    global VB_K_VALUE, VB_TARGET_VOL_PCT, DM_WINDOW&#10;    global ENSEMBLE_STRATEGY, OPENAI_MODEL, GEMINI_MODEL&#10;    global BOT_ENABLED, BOT_INTERVAL_SEC, BOT_SELL_COOLDOWN_SEC&#10;    global AI_ENS_BS, AI_ENS_SS, AI_ENS_AT&#10;    global AI_REJECT_COOLDOWN_CANDLES&#10;&#10;    STRATEGY_NAME = cfg.get(&quot;strategy_name&quot;, &quot;RSI&quot;)&#10;    MARKET = cfg.get(&quot;market&quot;, &quot;KRW-BTC&quot;)&#10;    TIMEFRAME = cfg.get(&quot;timeframe&quot;, &quot;minute5&quot;)&#10;    CANDLE_COUNT = cfg.get(&quot;candle_count&quot;, 200)&#10;    LOOP_INTERVAL_SEC = cfg.get(&quot;loop_interval_sec&quot;, 5)&#10;&#10;    _order_settings = cfg.get(&quot;order_settings&quot;, {})&#10;    MIN_ORDER_AMOUNT = _order_settings.get(&quot;min_order_amount&quot;, 5500)&#10;    TRADE_AMOUNT_KRW = _order_settings.get(&quot;trade_amount_krw&quot;, 6000)&#10;    SELL_RATIO = _order_settings.get(&quot;sell_ratio&quot;, 0.3)&#10;&#10;    USE_KELLY_CRITERION = cfg.get(&quot;use_kelly_criterion&quot;, False)&#10;    _kelly_settings = cfg.get(&quot;kelly_criterion&quot;, {})&#10;    KELLY_WIN_RATE = _kelly_settings.get(&quot;win_rate&quot;, 0.5)&#10;    KELLY_PAYOFF_RATIO = _kelly_settings.get(&quot;payoff_ratio&quot;, 1.0)&#10;    KELLY_FRACTION = _kelly_settings.get(&quot;fraction&quot;, 0.5)&#10;&#10;    _strategy_params = cfg.get(&quot;strategy_params&quot;, {})&#10;    _rsi_params = _strategy_params.get(&quot;RSI&quot;, {})&#10;    RSI_PERIOD = _rsi_params.get(&quot;period&quot;, 14)&#10;    RSI_OVERSOLD = _rsi_params.get(&quot;oversold&quot;, 30)&#10;    RSI_OVERBOUGHT = _rsi_params.get(&quot;overbought&quot;, 70)&#10;&#10;    _vb_params = _strategy_params.get(&quot;VolatilityBreakout&quot;, {})&#10;    VB_K_VALUE = _vb_params.get(&quot;k_value&quot;, 0.5)&#10;    VB_TARGET_VOL_PCT = _vb_params.get(&quot;target_vol_pct&quot;, 30.0)&#10;&#10;    _dm_params = _strategy_params.get(&quot;DualMomentum&quot;, {})&#10;    DM_WINDOW = _dm_params.get(&quot;window&quot;, 12)&#10;&#10;    _ai_ensemble_settings = cfg.get(&quot;ai_ensemble&quot;, {})&#10;    ENSEMBLE_STRATEGY = _ai_ensemble_settings.get(&quot;strategy&quot;, &quot;UNANIMOUS&quot;)&#10;    OPENAI_MODEL = _ai_ensemble_settings.get(&quot;openai_model&quot;, &quot;gpt-5.1-nano&quot;)&#10;    GEMINI_MODEL = _ai_ensemble_settings.get(&quot;gemini_model&quot;, &quot;gemini-2.5-flash&quot;)&#10;    AI_ENS_BS = _ai_ensemble_settings.get(&quot;buy_strategy&quot;, ENSEMBLE_STRATEGY).upper()&#10;    AI_ENS_SS = _ai_ensemble_settings.get(&quot;sell_strategy&quot;, ENSEMBLE_STRATEGY).upper()&#10;    AI_ENS_AT = _ai_ensemble_settings.get(&quot;average_threshold&quot;, 0.5)&#10;&#10;    bot_enabled = cfg.get(&quot;bot_enabled&quot;)&#10;    if bot_enabled is None:&#10;        bot_enabled = True&#10;    BOT_ENABLED = bool(bot_enabled)&#10;    BOT_INTERVAL_SEC = float(cfg.get(&quot;bot_interval_sec&quot;, 5.0))&#10;    BOT_SELL_COOLDOWN_SEC = float(cfg.get(&quot;bot_sell_cooldown_sec&quot;, 120.0))&#10;    AI_REJECT_COOLDOWN_CANDLES = int(cfg.get(&quot;ai_reject_cooldown_candles&quot;, 3))&#10;&#10;&#10;# 초기 로드 이후 전역 변수 동기화&#10;_sync_globals_from_config(_config)&#10;&#10;# expose some convenience getters&#10;def get_setting(key: str, default=None):&#10;    value = _config.get(key, default)&#10;    if value is None:&#10;        value = os.environ.get(key, default)&#10;    return value&#10;&#10;&#10;def reload_config():&#10;    global _config&#10;    _config = load_config()&#10;    # 로드된 config로 전역 변수 동기화&#10;    _sync_globals_from_config(_config)&#10;    log.info(&quot;Configuration reloaded.&quot;)&#10;    return _config&#10;&#10;&#10;# --- 기존 전역 변수화 (하위 모듈 호환성 유지) ---&#10;STRATEGY_NAME = _config.get(&quot;strategy_name&quot;, &quot;RSI&quot;)&#10;MARKET = _config.get(&quot;market&quot;, &quot;KRW-BTC&quot;)&#10;TIMEFRAME = _config.get(&quot;timeframe&quot;, &quot;minute5&quot;)&#10;CANDLE_COUNT = _config.get(&quot;candle_count&quot;, 200)&#10;LOOP_INTERVAL_SEC = _config.get(&quot;loop_interval_sec&quot;, 5)&#10;&#10;_order_settings = _config.get(&quot;order_settings&quot;, {})&#10;MIN_ORDER_AMOUNT = _order_settings.get(&quot;min_order_amount&quot;, 5500)&#10;TRADE_AMOUNT_KRW = _order_settings.get(&quot;trade_amount_krw&quot;, 6000)&#10;SELL_RATIO = _order_settings.get(&quot;sell_ratio&quot;, 0.3)  # 매도 시 전체 잔고의 30%만 매도&#10;&#10;USE_KELLY_CRITERION = _config.get(&quot;use_kelly_criterion&quot;, False)&#10;_kelly_settings = _config.get(&quot;kelly_criterion&quot;, {})&#10;KELLY_WIN_RATE = _kelly_settings.get(&quot;win_rate&quot;, 0.5)&#10;KELLY_PAYOFF_RATIO = _kelly_settings.get(&quot;payoff_ratio&quot;, 1.0)&#10;KELLY_FRACTION = _kelly_settings.get(&quot;fraction&quot;, 0.5)&#10;&#10;_strategy_params = _config.get(&quot;strategy_params&quot;, {})&#10;_rsi_params = _strategy_params.get(&quot;RSI&quot;, {})&#10;RSI_PERIOD = _rsi_params.get(&quot;period&quot;, 14)&#10;RSI_OVERSOLD = _rsi_params.get(&quot;oversold&quot;, 30)&#10;RSI_OVERBOUGHT = _rsi_params.get(&quot;overbought&quot;, 70)&#10;&#10;_vb_params = _config.get(&quot;strategy_params&quot;, {}).get(&quot;VolatilityBreakout&quot;, {})&#10;VB_K_VALUE = _vb_params.get(&quot;k_value&quot;, 0.5)&#10;VB_TARGET_VOL_PCT = _vb_params.get(&quot;target_vol_pct&quot;, 30.0)&#10;&#10;_dm_params = _strategy_params.get(&quot;DualMomentum&quot;, {})&#10;DM_WINDOW = _dm_params.get(&quot;window&quot;, 12)&#10;&#10;_ai_ensemble_settings = _config.get(&quot;ai_ensemble&quot;, {})&#10;ENSEMBLE_STRATEGY = _ai_ensemble_settings.get(&quot;strategy&quot;, &quot;UNANIMOUS&quot;)&#10;OPENAI_MODEL = _ai_ensemble_settings.get(&quot;openai_model&quot;, &quot;gpt-5.1-nano&quot;)&#10;GEMINI_MODEL = _ai_ensemble_settings.get(&quot;gemini_model&quot;, &quot;gemini-2.5-flash&quot;)&#10;AI_ENS_BS = _ai_ensemble_settings.get(&quot;buy_strategy&quot;, ENSEMBLE_STRATEGY).upper()&#10;AI_ENS_SS = _ai_ensemble_settings.get(&quot;sell_strategy&quot;, ENSEMBLE_STRATEGY).upper()&#10;AI_ENS_AT = _ai_ensemble_settings.get(&quot;average_threshold&quot;, 0.5)&#10;&#10;BOT_ENABLED = _config.get(&quot;bot_enabled&quot;, True)&#10;BOT_INTERVAL_SEC = float(_config.get(&quot;bot_interval_sec&quot;, 5.0))&#10;BOT_SELL_COOLDOWN_SEC = float(_config.get(&quot;bot_sell_cooldown_sec&quot;, 120.0))&#10;&#10;log.info(f&quot;Configuration loaded: Strategy='{STRATEGY_NAME}', Market='{MARKET}'&quot;)&#10;log.debug(f&quot;Volatility breakout target volatility pct set to {VB_TARGET_VOL_PCT}&quot;)&#10;&#10;&#10;def update_bot_control(bot_enabled: Optional[bool] = None, bot_interval_sec: Optional[float] = None, bot_sell_cooldown_sec: Optional[float] = None):&#10;    &quot;&quot;&quot;Update bot control values and persist them.&quot;&quot;&quot;&#10;    global _config&#10;    updated = False&#10;    if bot_enabled is not None:&#10;        _config['bot_enabled'] = bool(bot_enabled)&#10;        updated = True&#10;    if bot_interval_sec is not None:&#10;        _config['bot_interval_sec'] = float(bot_interval_sec)&#10;        updated = True&#10;    if bot_sell_cooldown_sec is not None:&#10;        _config['bot_sell_cooldown_sec'] = float(bot_sell_cooldown_sec)&#10;        updated = True&#10;    if updated:&#10;        save_config(_config)&#10;        reload_config()&#10;    return updated&#10;" />
              <option name="updatedContent" value="import os&#10;import json&#10;from dotenv import load_dotenv&#10;from typing import Dict, Any, Optional&#10;from server.logger import log&#10;&#10;# --- 1. .env 파일에서 민감 정보 로드 ---&#10;# server 디렉토리 기준으로 .env 파일 경로 설정&#10;dotenv_path = os.path.join(os.path.dirname(__file__), '.env')&#10;if os.path.exists(dotenv_path):&#10;    load_dotenv(dotenv_path)&#10;    log.info(&quot;.env file loaded successfully.&quot;)&#10;else:&#10;    log.warning(&quot;server/.env file not found. Please create one with your API keys.&quot;)&#10;&#10;# 환경 변수에서 API 키 가져오기 (따옴표/공백 제거)&#10;def _read_env(key: str) -&gt; str | None:&#10;    val = os.getenv(key)&#10;    if val is None:&#10;        return None&#10;    val = val.strip()&#10;    if (val.startswith('&quot;') and val.endswith('&quot;')) or (val.startswith(&quot;'&quot;) and val.endswith(&quot;'&quot;)):&#10;        val = val[1:-1]&#10;    return val or None&#10;&#10;UPBIT_ACCESS_KEY = _read_env(&quot;UPBIT_ACCESS_KEY&quot;)&#10;UPBIT_SECRET_KEY = _read_env(&quot;UPBIT_SECRET_KEY&quot;)&#10;OPENAI_API_KEY = _read_env(&quot;OPENAI_API_KEY&quot;)&#10;GEMINI_API_KEY = _read_env(&quot;GEMINI_API_KEY&quot;)&#10;&#10;# --- 2. runtime/config.json 파일에서 설정 파라미터 로드 ---&#10;def _get_runtime_config_path():&#10;    project_root = os.path.dirname(os.path.dirname(__file__))&#10;    return os.path.join(project_root, 'runtime', 'config.json')&#10;&#10;&#10;def _migrate_config_schema(cfg: Dict[str, Any]) -&gt; Dict[str, Any]:&#10;    &quot;&quot;&quot;Normalize legacy config keys to the current schema without mutating the original dict.&quot;&quot;&quot;&#10;    normalized = json.loads(json.dumps(cfg)) if isinstance(cfg, dict) else {}&#10;    strategy_params = normalized.setdefault('strategy_params', {})&#10;    vb_params = strategy_params.setdefault('VolatilityBreakout', {})&#10;    legacy = normalized.pop('vb_target_vol_pct', None)&#10;    if 'target_vol_pct' not in vb_params and legacy is not None:&#10;        try:&#10;            vb_params['target_vol_pct'] = float(legacy)&#10;        except (TypeError, ValueError):&#10;            vb_params['target_vol_pct'] = 30.0&#10;    if 'target_vol_pct' not in vb_params:&#10;        vb_params['target_vol_pct'] = 30.0&#10;    ai_ensemble = normalized.setdefault('ai_ensemble', {}) if isinstance(normalized.get('ai_ensemble'), dict) else {}&#10;    base_strategy = str(ai_ensemble.get('strategy', 'UNANIMOUS')).upper()&#10;    buy_strategy = str(ai_ensemble.get('buy_strategy', '')).upper()&#10;    sell_strategy = str(ai_ensemble.get('sell_strategy', '')).upper()&#10;    if not buy_strategy:&#10;        buy_strategy = base_strategy&#10;    if not sell_strategy:&#10;        sell_strategy = base_strategy&#10;    ai_ensemble['buy_strategy'] = buy_strategy or 'UNANIMOUS'&#10;    ai_ensemble['sell_strategy'] = sell_strategy or 'UNANIMOUS'&#10;    try:&#10;        ai_ensemble['average_threshold'] = float(ai_ensemble.get('average_threshold', 0.5))&#10;    except (TypeError, ValueError):&#10;        ai_ensemble['average_threshold'] = 0.5&#10;    normalized['ai_ensemble'] = ai_ensemble&#10;    return normalized&#10;&#10;&#10;def load_config() -&gt; Dict[str, Any]:&#10;    &quot;&quot;&quot;config.json 파일에서 설정을 로드하여 반환합니다.&quot;&quot;&quot;&#10;    config_path = _get_runtime_config_path()&#10;    try:&#10;        with open(config_path, 'r', encoding='utf-8') as f:&#10;            config_data = json.load(f)&#10;        log.info(&quot;runtime/config.json file loaded successfully.&quot;)&#10;        return _migrate_config_schema(config_data)&#10;    except FileNotFoundError:&#10;        log.error(&quot;runtime/config.json not found! Please create a configuration file in runtime directory.&quot;)&#10;        return {}&#10;    except json.JSONDecodeError:&#10;        log.error(&quot;Error decoding runtime/config.json. Please check for syntax errors.&quot;)&#10;        return {}&#10;&#10;&#10;def save_config(new_config: Dict[str, Any]) -&gt; bool:&#10;    &quot;&quot;&quot;config.json 파일에 설정을 저장합니다. 안전을 위해 기존 파일을 백업합니다.&#10;&#10;    :param new_config: 저장할 설정 딕셔너리&#10;    :return: 저장 성공 여부&#10;    &quot;&quot;&quot;&#10;    config_path = _get_runtime_config_path()&#10;    backup_path = config_path + '.bak'&#10;    try:&#10;        # 기존 파일 백업&#10;        if os.path.exists(config_path):&#10;            os.replace(config_path, backup_path)&#10;            log.info(f&quot;Existing config.json backed up to {backup_path}&quot;)&#10;&#10;        normalized = _migrate_config_schema(new_config)&#10;        with open(config_path, 'w', encoding='utf-8') as f:&#10;            json.dump(normalized, f, ensure_ascii=False, indent=2)&#10;        log.info(&quot;New configuration saved to runtime/config.json&quot;)&#10;        return True&#10;    except Exception as e:&#10;        log.error(f&quot;Failed to save runtime/config.json: {e}&quot;)&#10;        # 백업 복원 시도&#10;        if os.path.exists(backup_path):&#10;            os.replace(backup_path, config_path)&#10;            log.info(&quot;Restored original config.json from backup due to failure.&quot;)&#10;        return False&#10;&#10;&#10;# 즉시 로드하여 전역 설정 변수로 노출&#10;_config = load_config()&#10;&#10;&#10;def _sync_globals_from_config(cfg: Dict[str, Any]):&#10;    &quot;&quot;&quot;로드된 `_config` 딕셔너리의 값을 모듈 전역 변수로 동기화합니다.&#10;    이 함수는 `reload_config()` 호출 시 기존 전역 변수들이 최신 값으로 갱신되도록 보장합니다.&#10;    &quot;&quot;&quot;&#10;    global STRATEGY_NAME, MARKET, TIMEFRAME, CANDLE_COUNT, LOOP_INTERVAL_SEC&#10;    global MIN_ORDER_AMOUNT, TRADE_AMOUNT_KRW, SELL_RATIO&#10;    global USE_KELLY_CRITERION, KELLY_WIN_RATE, KELLY_PAYOFF_RATIO, KELLY_FRACTION&#10;    global RSI_PERIOD, RSI_OVERSOLD, RSI_OVERBOUGHT&#10;    global VB_K_VALUE, VB_TARGET_VOL_PCT, DM_WINDOW&#10;    global ENSEMBLE_STRATEGY, OPENAI_MODEL, GEMINI_MODEL&#10;    global BOT_ENABLED, BOT_INTERVAL_SEC, BOT_SELL_COOLDOWN_SEC&#10;    global AI_ENS_BS, AI_ENS_SS, AI_ENS_AT&#10;    global AI_REJECT_COOLDOWN_CANDLES&#10;&#10;    STRATEGY_NAME = cfg.get(&quot;strategy_name&quot;, &quot;RSI&quot;)&#10;    MARKET = cfg.get(&quot;market&quot;, &quot;KRW-BTC&quot;)&#10;    TIMEFRAME = cfg.get(&quot;timeframe&quot;, &quot;minute5&quot;)&#10;    CANDLE_COUNT = cfg.get(&quot;candle_count&quot;, 200)&#10;    LOOP_INTERVAL_SEC = cfg.get(&quot;loop_interval_sec&quot;, 5)&#10;&#10;    _order_settings = cfg.get(&quot;order_settings&quot;, {})&#10;    MIN_ORDER_AMOUNT = _order_settings.get(&quot;min_order_amount&quot;, 5500)&#10;    TRADE_AMOUNT_KRW = _order_settings.get(&quot;trade_amount_krw&quot;, 6000)&#10;    SELL_RATIO = _order_settings.get(&quot;sell_ratio&quot;, 0.3)&#10;&#10;    USE_KELLY_CRITERION = cfg.get(&quot;use_kelly_criterion&quot;, False)&#10;    _kelly_settings = cfg.get(&quot;kelly_criterion&quot;, {})&#10;    KELLY_WIN_RATE = _kelly_settings.get(&quot;win_rate&quot;, 0.5)&#10;    KELLY_PAYOFF_RATIO = _kelly_settings.get(&quot;payoff_ratio&quot;, 1.0)&#10;    KELLY_FRACTION = _kelly_settings.get(&quot;fraction&quot;, 0.5)&#10;&#10;    _strategy_params = cfg.get(&quot;strategy_params&quot;, {})&#10;    _rsi_params = _strategy_params.get(&quot;RSI&quot;, {})&#10;    RSI_PERIOD = _rsi_params.get(&quot;period&quot;, 14)&#10;    RSI_OVERSOLD = _rsi_params.get(&quot;oversold&quot;, 30)&#10;    RSI_OVERBOUGHT = _rsi_params.get(&quot;overbought&quot;, 70)&#10;&#10;    _vb_params = _strategy_params.get(&quot;VolatilityBreakout&quot;, {})&#10;    VB_K_VALUE = _vb_params.get(&quot;k_value&quot;, 0.5)&#10;    VB_TARGET_VOL_PCT = _vb_params.get(&quot;target_vol_pct&quot;, 30.0)&#10;&#10;    _dm_params = _strategy_params.get(&quot;DualMomentum&quot;, {})&#10;    DM_WINDOW = _dm_params.get(&quot;window&quot;, 12)&#10;&#10;    _ai_ensemble_settings = cfg.get(&quot;ai_ensemble&quot;, {})&#10;    ENSEMBLE_STRATEGY = _ai_ensemble_settings.get(&quot;strategy&quot;, &quot;UNANIMOUS&quot;)&#10;    OPENAI_MODEL = _ai_ensemble_settings.get(&quot;openai_model&quot;, &quot;gpt-5.1-nano&quot;)&#10;    GEMINI_MODEL = _ai_ensemble_settings.get(&quot;gemini_model&quot;, &quot;gemini-2.5-flash&quot;)&#10;    AI_ENS_BS = _ai_ensemble_settings.get(&quot;buy_strategy&quot;, ENSEMBLE_STRATEGY).upper()&#10;    AI_ENS_SS = _ai_ensemble_settings.get(&quot;sell_strategy&quot;, ENSEMBLE_STRATEGY).upper()&#10;    AI_ENS_AT = _ai_ensemble_settings.get(&quot;average_threshold&quot;, 0.5)&#10;&#10;    bot_enabled = cfg.get(&quot;bot_enabled&quot;)&#10;    if bot_enabled is None:&#10;        bot_enabled = True&#10;    BOT_ENABLED = bool(bot_enabled)&#10;    BOT_INTERVAL_SEC = float(cfg.get(&quot;bot_interval_sec&quot;, 5.0))&#10;    BOT_SELL_COOLDOWN_SEC = float(cfg.get(&quot;bot_sell_cooldown_sec&quot;, 120.0))&#10;    AI_REJECT_COOLDOWN_CANDLES = int(cfg.get(&quot;ai_reject_cooldown_candles&quot;, 3))&#10;&#10;&#10;# 초기 로드 이후 전역 변수 동기화&#10;_sync_globals_from_config(_config)&#10;&#10;# expose some convenience getters&#10;def get_setting(key: str, default=None):&#10;    value = _config.get(key, default)&#10;    if value is None:&#10;        value = os.environ.get(key, default)&#10;    return value&#10;&#10;&#10;def reload_config():&#10;    global _config&#10;    _config = load_config()&#10;    # 로드된 config로 전역 변수 동기화&#10;    _sync_globals_from_config(_config)&#10;    log.info(&quot;Configuration reloaded.&quot;)&#10;    return _config&#10;&#10;&#10;# --- 기존 전역 변수화 (하위 모듈 호환성 유지) ---&#10;STRATEGY_NAME = _config.get(&quot;strategy_name&quot;, &quot;RSI&quot;)&#10;MARKET = _config.get(&quot;market&quot;, &quot;KRW-BTC&quot;)&#10;TIMEFRAME = _config.get(&quot;timeframe&quot;, &quot;minute5&quot;)&#10;CANDLE_COUNT = _config.get(&quot;candle_count&quot;, 200)&#10;LOOP_INTERVAL_SEC = _config.get(&quot;loop_interval_sec&quot;, 5)&#10;&#10;_order_settings = _config.get(&quot;order_settings&quot;, {})&#10;MIN_ORDER_AMOUNT = _order_settings.get(&quot;min_order_amount&quot;, 5500)&#10;TRADE_AMOUNT_KRW = _order_settings.get(&quot;trade_amount_krw&quot;, 6000)&#10;SELL_RATIO = _order_settings.get(&quot;sell_ratio&quot;, 0.3)  # 매도 시 전체 잔고의 30%만 매도&#10;&#10;USE_KELLY_CRITERION = _config.get(&quot;use_kelly_criterion&quot;, False)&#10;_kelly_settings = _config.get(&quot;kelly_criterion&quot;, {})&#10;KELLY_WIN_RATE = _kelly_settings.get(&quot;win_rate&quot;, 0.5)&#10;KELLY_PAYOFF_RATIO = _kelly_settings.get(&quot;payoff_ratio&quot;, 1.0)&#10;KELLY_FRACTION = _kelly_settings.get(&quot;fraction&quot;, 0.5)&#10;&#10;_strategy_params = _config.get(&quot;strategy_params&quot;, {})&#10;_rsi_params = _strategy_params.get(&quot;RSI&quot;, {})&#10;RSI_PERIOD = _rsi_params.get(&quot;period&quot;, 14)&#10;RSI_OVERSOLD = _rsi_params.get(&quot;oversold&quot;, 30)&#10;RSI_OVERBOUGHT = _rsi_params.get(&quot;overbought&quot;, 70)&#10;&#10;_vb_params = _config.get(&quot;strategy_params&quot;, {}).get(&quot;VolatilityBreakout&quot;, {})&#10;VB_K_VALUE = _vb_params.get(&quot;k_value&quot;, 0.5)&#10;VB_TARGET_VOL_PCT = _vb_params.get(&quot;target_vol_pct&quot;, 30.0)&#10;&#10;_dm_params = _strategy_params.get(&quot;DualMomentum&quot;, {})&#10;DM_WINDOW = _dm_params.get(&quot;window&quot;, 12)&#10;&#10;_ai_ensemble_settings = _config.get(&quot;ai_ensemble&quot;, {})&#10;ENSEMBLE_STRATEGY = _ai_ensemble_settings.get(&quot;strategy&quot;, &quot;UNANIMOUS&quot;)&#10;OPENAI_MODEL = _ai_ensemble_settings.get(&quot;openai_model&quot;, &quot;gpt-5.1-nano&quot;)&#10;GEMINI_MODEL = _ai_ensemble_settings.get(&quot;gemini_model&quot;, &quot;gemini-2.5-flash&quot;)&#10;AI_ENS_BS = _ai_ensemble_settings.get(&quot;buy_strategy&quot;, ENSEMBLE_STRATEGY).upper()&#10;AI_ENS_SS = _ai_ensemble_settings.get(&quot;sell_strategy&quot;, ENSEMBLE_STRATEGY).upper()&#10;AI_ENS_AT = _ai_ensemble_settings.get(&quot;average_threshold&quot;, 0.5)&#10;&#10;BOT_ENABLED = _config.get(&quot;bot_enabled&quot;, True)&#10;BOT_INTERVAL_SEC = float(_config.get(&quot;bot_interval_sec&quot;, 5.0))&#10;BOT_SELL_COOLDOWN_SEC = float(_config.get(&quot;bot_sell_cooldown_sec&quot;, 120.0))&#10;&#10;log.info(f&quot;Configuration loaded: Strategy='{STRATEGY_NAME}', Market='{MARKET}'&quot;)&#10;log.debug(f&quot;Volatility breakout target volatility pct set to {VB_TARGET_VOL_PCT}&quot;)&#10;&#10;&#10;def update_bot_control(bot_enabled: Optional[bool] = None, bot_interval_sec: Optional[float] = None, bot_sell_cooldown_sec: Optional[float] = None):&#10;    &quot;&quot;&quot;Update bot control values and persist them.&quot;&quot;&quot;&#10;    global _config&#10;    updated = False&#10;    if bot_enabled is not None:&#10;        _config['bot_enabled'] = bool(bot_enabled)&#10;        updated = True&#10;    if bot_interval_sec is not None:&#10;        _config['bot_interval_sec'] = float(bot_interval_sec)&#10;        updated = True&#10;    if bot_sell_cooldown_sec is not None:&#10;        _config['bot_sell_cooldown_sec'] = float(bot_sell_cooldown_sec)&#10;        updated = True&#10;    if updated:&#10;        save_config(_config)&#10;        reload_config()&#10;    return updated&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/server/history.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/server/history.py" />
              <option name="originalContent" value="import json&#10;import os&#10;import threading&#10;import time&#10;from pathlib import Path&#10;from typing import Any, Dict, List, Optional&#10;&#10;HISTORY_DIR = Path(__file__).resolve().parents[1] / &quot;runtime&quot; / &quot;history&quot;&#10;HISTORY_FILE = HISTORY_DIR / &quot;positions_history.json&quot;&#10;MAX_ENTRIES = int(os.getenv(&quot;POSITIONS_HISTORY_MAX_ENTRIES&quot;, &quot;720&quot;))&#10;MIN_INTERVAL_SEC = int(os.getenv(&quot;POSITIONS_HISTORY_MIN_INTERVAL_SEC&quot;, &quot;900&quot;))&#10;ORDER_HISTORY_FILE = HISTORY_DIR / &quot;order_history.json&quot;&#10;ORDER_HISTORY_MAX = int(os.getenv(&quot;ORDER_HISTORY_MAX_ENTRIES&quot;, &quot;1024&quot;))&#10;AI_HISTORY_FILE = HISTORY_DIR / &quot;ai_decisions.json&quot;&#10;AI_HISTORY_MAX = int(os.getenv(&quot;AI_HISTORY_MAX_ENTRIES&quot;, &quot;1024&quot;))&#10;&#10;&#10;def _ensure_dir() -&gt; None:&#10;    HISTORY_DIR.mkdir(parents=True, exist_ok=True)&#10;&#10;&#10;class HistoryStore:&#10;    def __init__(self, path: Path = HISTORY_FILE, max_entries: int = MAX_ENTRIES, min_interval: int = MIN_INTERVAL_SEC):&#10;        self.path = path&#10;        self.max_entries = max_entries&#10;        self.min_interval = min_interval&#10;        self.lock = threading.Lock()&#10;        _ensure_dir()&#10;&#10;    def _load(self) -&gt; List[Dict[str, Any]]:&#10;        if not self.path.exists():&#10;            return []&#10;        try:&#10;            with self.path.open(&quot;r&quot;, encoding=&quot;utf-8&quot;) as fp:&#10;                return json.load(fp)&#10;        except Exception:&#10;            return []&#10;&#10;    def _save(self, data: List[Dict[str, Any]]) -&gt; None:&#10;        try:&#10;            with self.path.open(&quot;w&quot;, encoding=&quot;utf-8&quot;) as fp:&#10;                json.dump(data, fp, ensure_ascii=False)&#10;        except Exception:&#10;            pass&#10;&#10;    def record_snapshot(self, snapshot: Dict[str, Any]) -&gt; bool:&#10;        now = snapshot.get(&quot;ts&quot;) or time.time()&#10;        snapshot[&quot;ts&quot;] = float(now)&#10;        with self.lock:&#10;            data = self._load()&#10;            last_ts = float(data[-1].get(&quot;ts&quot;, 0)) if data else 0&#10;            if now - last_ts &lt; self.min_interval:&#10;                return False&#10;            data.append(snapshot)&#10;            if len(data) &gt; self.max_entries:&#10;                data = data[-self.max_entries :]&#10;            self._save(data)&#10;        return True&#10;&#10;    def get_history(self, since: Optional[float] = None, limit: Optional[int] = None) -&gt; List[Dict[str, Any]]:&#10;        with self.lock:&#10;            data = self._load()&#10;        if since is not None:&#10;            data = [item for item in data if float(item.get(&quot;ts&quot;, 0)) &gt;= since]&#10;        if limit is not None and limit &lt; len(data):&#10;            data = data[-limit:]&#10;        return data&#10;&#10;&#10;history_store = HistoryStore()&#10;&#10;&#10;class OrderHistoryStore:&#10;    def __init__(self, path: Path = ORDER_HISTORY_FILE, max_entries: int = ORDER_HISTORY_MAX):&#10;        self.path = path&#10;        self.max_entries = max_entries&#10;        self.lock = threading.Lock()&#10;        _ensure_dir()&#10;&#10;    def _load(self) -&gt; List[Dict[str, Any]]:&#10;        if not self.path.exists():&#10;            return []&#10;        try:&#10;            with self.path.open(&quot;r&quot;, encoding=&quot;utf-8&quot;) as fp:&#10;                return json.load(fp)&#10;        except Exception:&#10;            return []&#10;&#10;    def _save(self, data: List[Dict[str, Any]]) -&gt; None:&#10;        try:&#10;            with self.path.open(&quot;w&quot;, encoding=&quot;utf-8&quot;) as fp:&#10;                json.dump(data, fp, ensure_ascii=False)&#10;        except Exception:&#10;            pass&#10;&#10;    def record(self, entry: Dict[str, Any]) -&gt; None:&#10;        entry.setdefault(&quot;ts&quot;, time.time())&#10;        with self.lock:&#10;            data = self._load()&#10;            data.append(entry)&#10;            if len(data) &gt; self.max_entries:&#10;                data = data[-self.max_entries :]&#10;            self._save(data)&#10;&#10;&#10;order_history_store = OrderHistoryStore()&#10;&#10;&#10;class AIHistoryStore:&#10;    def __init__(self, path: Path = AI_HISTORY_FILE, max_entries: int = AI_HISTORY_MAX):&#10;        self.path = path&#10;        self.max_entries = max_entries&#10;        self.lock = threading.Lock()&#10;        _ensure_dir()&#10;&#10;    def _load(self) -&gt; List[Dict[str, Any]]:&#10;        if not self.path.exists():&#10;            return []&#10;        try:&#10;            with self.path.open(&quot;r&quot;, encoding=&quot;utf-8&quot;) as fp:&#10;                return json.load(fp)&#10;        except Exception:&#10;            return []&#10;&#10;    def _save(self, data: List[Dict[str, Any]]) -&gt; None:&#10;        try:&#10;            with self.path.open(&quot;w&quot;, encoding=&quot;utf-8&quot;) as fp:&#10;                json.dump(data, fp, ensure_ascii=False)&#10;        except Exception:&#10;            pass&#10;&#10;    def record(self, entry: Dict[str, Any]) -&gt; None:&#10;        entry.setdefault(&quot;ts&quot;, time.time())&#10;        with self.lock:&#10;            data = self._load()&#10;            data.append(entry)&#10;            if len(data) &gt; self.max_entries:&#10;                data = data[-self.max_entries :]&#10;            self._save(data)&#10;&#10;    def get_history(self, limit: Optional[int] = None) -&gt; List[Dict[str, Any]]:&#10;        with self.lock:&#10;            data = self._load()&#10;        if limit is not None and limit &gt; 0 and len(data) &gt; limit:&#10;            data = data[-limit:]&#10;        return data&#10;&#10;&#10;ai_history_store = AIHistoryStore()&#10;" />
              <option name="updatedContent" value="import json&#10;import os&#10;import threading&#10;import time&#10;from pathlib import Path&#10;from typing import Any, Dict, List, Optional&#10;&#10;HISTORY_DIR = Path(__file__).resolve().parents[1] / &quot;runtime&quot; / &quot;history&quot;&#10;HISTORY_FILE = HISTORY_DIR / &quot;positions_history.json&quot;&#10;MAX_ENTRIES = int(os.getenv(&quot;POSITIONS_HISTORY_MAX_ENTRIES&quot;, &quot;720&quot;))&#10;MIN_INTERVAL_SEC = int(os.getenv(&quot;POSITIONS_HISTORY_MIN_INTERVAL_SEC&quot;, &quot;900&quot;))&#10;ORDER_HISTORY_FILE = HISTORY_DIR / &quot;order_history.json&quot;&#10;ORDER_HISTORY_MAX = int(os.getenv(&quot;ORDER_HISTORY_MAX_ENTRIES&quot;, &quot;1024&quot;))&#10;AI_HISTORY_FILE = HISTORY_DIR / &quot;ai_decisions.json&quot;&#10;AI_HISTORY_MAX = int(os.getenv(&quot;AI_HISTORY_MAX_ENTRIES&quot;, &quot;1024&quot;))&#10;&#10;&#10;def _ensure_dir() -&gt; None:&#10;    HISTORY_DIR.mkdir(parents=True, exist_ok=True)&#10;&#10;&#10;class HistoryStore:&#10;    def __init__(self, path: Path = HISTORY_FILE, max_entries: int = MAX_ENTRIES, min_interval: int = MIN_INTERVAL_SEC):&#10;        self.path = path&#10;        self.max_entries = max_entries&#10;        self.min_interval = min_interval&#10;        self.lock = threading.Lock()&#10;        _ensure_dir()&#10;&#10;    def _load(self) -&gt; List[Dict[str, Any]]:&#10;        if not self.path.exists():&#10;            return []&#10;        try:&#10;            with self.path.open(&quot;r&quot;, encoding=&quot;utf-8&quot;) as fp:&#10;                return json.load(fp)&#10;        except Exception:&#10;            return []&#10;&#10;    def _save(self, data: List[Dict[str, Any]]) -&gt; None:&#10;        try:&#10;            with self.path.open(&quot;w&quot;, encoding=&quot;utf-8&quot;) as fp:&#10;                json.dump(data, fp, ensure_ascii=False)&#10;        except Exception:&#10;            pass&#10;&#10;    def record_snapshot(self, snapshot: Dict[str, Any]) -&gt; bool:&#10;        now = snapshot.get(&quot;ts&quot;) or time.time()&#10;        snapshot[&quot;ts&quot;] = float(now)&#10;        with self.lock:&#10;            data = self._load()&#10;            last_ts = float(data[-1].get(&quot;ts&quot;, 0)) if data else 0&#10;            if now - last_ts &lt; self.min_interval:&#10;                return False&#10;            data.append(snapshot)&#10;            if len(data) &gt; self.max_entries:&#10;                data = data[-self.max_entries :]&#10;            self._save(data)&#10;        return True&#10;&#10;    def get_history(self, since: Optional[float] = None, limit: Optional[int] = None) -&gt; List[Dict[str, Any]]:&#10;        with self.lock:&#10;            data = self._load()&#10;        if since is not None:&#10;            data = [item for item in data if float(item.get(&quot;ts&quot;, 0)) &gt;= since]&#10;        if limit is not None and limit &lt; len(data):&#10;            data = data[-limit:]&#10;        return data&#10;&#10;&#10;history_store = HistoryStore()&#10;&#10;&#10;class OrderHistoryStore:&#10;    def __init__(self, path: Path = ORDER_HISTORY_FILE, max_entries: int = ORDER_HISTORY_MAX):&#10;        self.path = path&#10;        self.max_entries = max_entries&#10;        self.lock = threading.Lock()&#10;        _ensure_dir()&#10;&#10;    def _load(self) -&gt; List[Dict[str, Any]]:&#10;        if not self.path.exists():&#10;            return []&#10;        try:&#10;            with self.path.open(&quot;r&quot;, encoding=&quot;utf-8&quot;) as fp:&#10;                return json.load(fp)&#10;        except Exception:&#10;            return []&#10;&#10;    def _save(self, data: List[Dict[str, Any]]) -&gt; None:&#10;        try:&#10;            with self.path.open(&quot;w&quot;, encoding=&quot;utf-8&quot;) as fp:&#10;                json.dump(data, fp, ensure_ascii=False)&#10;        except Exception:&#10;            pass&#10;&#10;    def record(self, entry: Dict[str, Any]) -&gt; None:&#10;        entry.setdefault(&quot;ts&quot;, time.time())&#10;        with self.lock:&#10;            data = self._load()&#10;            data.append(entry)&#10;            if len(data) &gt; self.max_entries:&#10;                data = data[-self.max_entries :]&#10;            self._save(data)&#10;&#10;&#10;order_history_store = OrderHistoryStore()&#10;&#10;&#10;class AIHistoryStore:&#10;    def __init__(self, path: Path = AI_HISTORY_FILE, max_entries: int = AI_HISTORY_MAX):&#10;        self.path = path&#10;        self.max_entries = max_entries&#10;        self.lock = threading.Lock()&#10;        _ensure_dir()&#10;&#10;    def _load(self) -&gt; List[Dict[str, Any]]:&#10;        if not self.path.exists():&#10;            return []&#10;        try:&#10;            with self.path.open(&quot;r&quot;, encoding=&quot;utf-8&quot;) as fp:&#10;                return json.load(fp)&#10;        except Exception:&#10;            return []&#10;&#10;    def _save(self, data: List[Dict[str, Any]]) -&gt; None:&#10;        try:&#10;            with self.path.open(&quot;w&quot;, encoding=&quot;utf-8&quot;) as fp:&#10;                json.dump(data, fp, ensure_ascii=False)&#10;        except Exception:&#10;            pass&#10;&#10;    def record(self, entry: Dict[str, Any]) -&gt; None:&#10;        entry.setdefault(&quot;ts&quot;, time.time())&#10;        with self.lock:&#10;            data = self._load()&#10;            data.append(entry)&#10;            if len(data) &gt; self.max_entries:&#10;                data = data[-self.max_entries :]&#10;            self._save(data)&#10;&#10;    def get_history(self, limit: Optional[int] = None) -&gt; List[Dict[str, Any]]:&#10;        with self.lock:&#10;            data = self._load()&#10;        if limit is not None and limit &gt; 0 and len(data) &gt; limit:&#10;            data = data[-limit:]&#10;        return data&#10;&#10;&#10;ai_history_store = AIHistoryStore()" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/server/money_manager.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/server/money_manager.py" />
              <option name="originalContent" value="from server.logger import log&#10;&#10;#  Kelly Criterion 기반 자금 관리자&#10;# Kelly Criterion: f* = (p*b - (1-p)) / b&#10;# f* = 최적 베팅 비율&#10;# p = 승률 (0 &lt; p &lt; 1)&#10;# b = 평균 이익 / 평균 손실 (payoff ratio, b &gt; 0)&#10;# 참고: https://en.wikipedia.org/wiki/Kelly_criterion&#10;# 예시: 승률 60%, 손익비 1.5인 전략의 경우&#10;# f* = (0.6*1.5 - 0.4) / 1.5 = 0.4 (즉, 자산의 40%를 투자)&#10;# 단, 실제 투자에서는 변동성을 고려하여 절반 켈리(Half Kelly) 등을 권장합니다.&#10;&#10;class KellyCriterionManager:&#10;&#10;    # 켈리 기준 자금 관리자 초기화&#10;    def __init__(self, win_rate=0.4, payoff_ratio=2.0, fraction=0.5, risk_per_trade=0.02):&#10;&#10;        #:param win_rate: 전략의 승률 (0 &lt; win_rate &lt; 1)&#10;        #:param payoff_ratio: 평균 이익 / 평균 손실 (payoff_ratio &gt; 0)&#10;        #:param fraction: 계산된 켈리 비율에 적용할 비중 (e.g., 0.5 for Half Kelly)&#10;        #:param risk_per_trade: 1회 트레이딩 당 계좌 대비 최대 손실 허용 비율 (기본 2%)&#10;        if not (0 &lt; win_rate &lt; 1):&#10;            raise ValueError(&quot;Win rate must be between 0 and 1.&quot;)&#10;        if payoff_ratio &lt;= 0:&#10;            raise ValueError(&quot;Payoff ratio must be greater than 0.&quot;)&#10;        if not (0 &lt; fraction &lt;= 1):&#10;            raise ValueError(&quot;Kelly fraction must be between 0 and 1.&quot;)&#10;&#10;        # 멤버 변수 설정&#10;        self.win_rate = win_rate&#10;        self.payoff_ratio = payoff_ratio&#10;        self.fraction = fraction&#10;        self.risk_per_trade = risk_per_trade&#10;&#10;        # 켈리 공식: f = (p*b - (1-p)) / b&#10;        # p = win_rate, b = payoff_ratio&#10;        kelly_f = ((self.win_rate * self.payoff_ratio) - (1 - self.win_rate)) / self.payoff_ratio&#10;&#10;        # 음수일 경우 0으로 설정하여 손실 방지&#10;        self.kelly_fraction = max(0, kelly_f) * self.fraction  # 음수일 경우 0으로&#10;&#10;        log.info(&quot;Kelly Criterion Initialized.&quot;)&#10;        log.info(f&quot;  - Win Rate: {self.win_rate:.2%}&quot;)&#10;        log.info(f&quot;  - Payoff Ratio: {self.payoff_ratio:.2f}&quot;)&#10;        log.info(f&quot;  - Applied Kelly Fraction (f): {self.kelly_fraction:.2%}&quot;)&#10;        log.info(f&quot;  - Risk per Trade: {self.risk_per_trade:.2%}&quot;)&#10;&#10;    # 총 자산 대비 투자 금액 계산&#10;    # 총 자산의 일정 비율을 켈리 공식에 따라 투자 금액으로 산정&#10;    # e.g., 총 자산 1,000,000 KRW, 켈리 비율 20% -&gt; 200,000 KRW 투자&#10;    # 반환값: 투자할 금액 (float)&#10;    #:param total_balance: 총 자산 (e.g., KRW 잔고)&#10;    #:return: (float) 투자할 금액&#10;    # 계산된 투자 금액 반환&#10;    # 총 자산이 0이거나 켈리 비율이 0인 경우 0 반환&#10;    # 로그에 계산된 투자 금액 출력&#10;    # e.g., &quot;Calculated trade amount: 200,000 KRW (Balance: 1,000,000 * Kelly: 20.00%)&quot;&#10;    # 반환값: 투자할 금액 (float)&#10;    def calculate_trade_amount(self, total_balance):&#10;        if self.kelly_fraction &lt;= 0:&#10;            log.warning(&quot;Kelly fraction is 0 or negative. No investment is advised.&quot;)&#10;            return 0&#10;&#10;        # 총 자산이 0인 경우 0 반환&#10;        if total_balance &lt;= 0:&#10;            log.warning(&quot;Total balance is 0 or negative. No investment can be made.&quot;)&#10;            return 0&#10;&#10;        trade_amount = total_balance * self.kelly_fraction&#10;        log.info(f&quot;Calculated trade amount: {trade_amount:,.0f} KRW (Balance: {total_balance:,.0f} * Kelly: {self.kelly_fraction:.2%})&quot;)&#10;        return trade_amount&#10;&#10;    # 매수 진입 시 적절한 투자 금액과 수량 계산&#10;    # 리스크 관리와 켈리 기준을 모두 고려하여 최종 투자 금액 산정&#10;    #   [로직 설명]&#10;    #    1. 리스크 기반 계산 (Survival): 손절 나갔을 때 계좌의 R(2%)만 잃도록 수량 설정.&#10;    #       - 공식: 허용 손실금액 / (매수가 - 손절가)&#10;    #    2. 켈리 기반 계산 (Growth): 켈리 비중만큼 투자.&#10;    #    3. 최종 결정: 두 값 중 더 '안전한(작은)' 값을 선택하고, 시장 상황(market_factor)을 곱함.&#10;    #&#10;    #    # input&#10;    #    :param total_balance: 현재 계좌 총액 (KRW)&#10;    #    :param entry_price: 진입 예정 가격&#10;    #    :param stop_loss_price: 손절 예정 가격&#10;    #    :param market_factor: 시장 상황 점수 (0.0 ~ 1.0, 1.0=상승장 풀배팅, 0.5=보수적, 0.0=매매금지)&#10;&#10;    #    # return: {&#10;    #        'trade_amount': 투자할 총 금액 (KRW),&#10;    #        'quantity': 구매할 코인 수량,&#10;    #        'risk_amount': 예상 손실 금액,&#10;    #        'reason': 계산 근거&#10;    #    }&#10;    def get_position_size(self, total_balance, entry_price, stop_loss_price, market_factor=1.0):&#10;        if total_balance &lt;= 0 or entry_price &lt;= 0:&#10;            return {'trade_amount': 0, 'quantity': 0, 'reason': &quot;Invalid Balance or Price&quot;}&#10;&#10;        # 1. 1회 최대 허용 손실금액 (R) 계산&#10;        # 예: 1억 계좌, 2% 리스크 -&gt; 200만원 (엑셀의 '2% 금액')&#10;        max_risk_amount = total_balance * self.risk_per_trade&#10;&#10;        # 2. 주당 리스크 (Stop Loss Gap)&#10;        # 예: 1000원에 사서 920원에 손절 -&gt; 주당 80원 리스크&#10;        risk_per_share = entry_price - stop_loss_price&#10;&#10;        if risk_per_share &lt;= 0:&#10;            log.warning(&quot;Stop loss price is higher than entry price (Long Position). Adjusting Logic.&quot;)&#10;            risk_per_share = entry_price * 0.01  # 방어 코드&#10;&#10;        stop_loss_percent = risk_per_share / entry_price&#10;&#10;        # 3. 리스크 기반 최대 진입 수량 (Position Sizing based on Risk)&#10;        # 공식: 내가 감당할 총 손실 / 주당 손실&#10;        quantity_by_risk = max_risk_amount / risk_per_share&#10;        amount_by_risk = quantity_by_risk * entry_price&#10;&#10;        # 4. 켈리 기반 투자 금액 (Position Sizing based on Kelly)&#10;        amount_by_kelly = total_balance * self.kelly_fraction&#10;&#10;        # 5. 최종 금액 선정 (안전한 쪽 선택) &amp; 시장 팩터 반영&#10;        # 켈리가 너무 공격적이면 리스크 관리 룰을 따르고,&#10;        # 리스크 룰이 너무 크면 켈리(자금성장 최적화)를 따름.&#10;        safe_factor = max(0.0, min(1.0, market_factor if market_factor is not None else 1.0))&#10;        final_amount = min(amount_by_risk, amount_by_kelly) * safe_factor&#10;&#10;        # 최소 주문 금액(예: 업비트 5000원) 처리 등은 봇 로직에서 하겠지만 여기선 0 처리&#10;        final_amount = max(0, final_amount)&#10;        final_quantity = final_amount / entry_price&#10;&#10;        # 로그 출력&#10;        log.info(f&quot;[Money Mgmt] Balance: {total_balance:,.0f} KRW | Market Factor: {market_factor}&quot;)&#10;        log.info(f&quot; -&gt; Risk Limit (R={self.risk_per_trade:.1%}): Max Loss {max_risk_amount:,.0f} KRW&quot;)&#10;        log.info(f&quot; -&gt; Stop Loss: {stop_loss_percent:.2%} (Gap: {risk_per_share:,.0f} KRW)&quot;)&#10;        log.info(f&quot; -&gt; Sizing (Risk): {amount_by_risk:,.0f} KRW vs (Kelly): {amount_by_kelly:,.0f} KRW&quot;)&#10;        log.info(f&quot; -&gt; Final Check: Invest {final_amount:,.0f} KRW (Qty: {final_quantity:.4f})&quot;)&#10;&#10;        return {&#10;            'trade_amount': final_amount,&#10;            'quantity': final_quantity,&#10;            'risk_amount': final_quantity * risk_per_share,  # 실제 예상 손실액&#10;            'stop_loss_pct': stop_loss_percent&#10;        }&#10;" />
              <option name="updatedContent" value="from server.logger import log&#10;&#10;#  Kelly Criterion 기반 자금 관리자&#10;# Kelly Criterion: f* = (p*b - (1-p)) / b&#10;# f* = 최적 베팅 비율&#10;# p = 승률 (0 &lt; p &lt; 1)&#10;# b = 평균 이익 / 평균 손실 (payoff ratio, b &gt; 0)&#10;# 참고: https://en.wikipedia.org/wiki/Kelly_criterion&#10;# 예시: 승률 60%, 손익비 1.5인 전략의 경우&#10;# f* = (0.6*1.5 - 0.4) / 1.5 = 0.4 (즉, 자산의 40%를 투자)&#10;# 단, 실제 투자에서는 변동성을 고려하여 절반 켈리(Half Kelly) 등을 권장합니다.&#10;&#10;class KellyCriterionManager:&#10;&#10;    # 켈리 기준 자금 관리자 초기화&#10;    def __init__(self, win_rate=0.4, payoff_ratio=2.0, fraction=0.5, risk_per_trade=0.02):&#10;&#10;        #:param win_rate: 전략의 승률 (0 &lt; win_rate &lt; 1)&#10;        #:param payoff_ratio: 평균 이익 / 평균 손실 (payoff_ratio &gt; 0)&#10;        #:param fraction: 계산된 켈리 비율에 적용할 비중 (e.g., 0.5 for Half Kelly)&#10;        #:param risk_per_trade: 1회 트레이딩 당 계좌 대비 최대 손실 허용 비율 (기본 2%)&#10;        if not (0 &lt; win_rate &lt; 1):&#10;            raise ValueError(&quot;Win rate must be between 0 and 1.&quot;)&#10;        if payoff_ratio &lt;= 0:&#10;            raise ValueError(&quot;Payoff ratio must be greater than 0.&quot;)&#10;        if not (0 &lt; fraction &lt;= 1):&#10;            raise ValueError(&quot;Kelly fraction must be between 0 and 1.&quot;)&#10;&#10;        # 멤버 변수 설정&#10;        self.win_rate = win_rate&#10;        self.payoff_ratio = payoff_ratio&#10;        self.fraction = fraction&#10;        self.risk_per_trade = risk_per_trade&#10;&#10;        # 켈리 공식: f = (p*b - (1-p)) / b&#10;        # p = win_rate, b = payoff_ratio&#10;        kelly_f = ((self.win_rate * self.payoff_ratio) - (1 - self.win_rate)) / self.payoff_ratio&#10;&#10;        # 음수일 경우 0으로 설정하여 손실 방지&#10;        self.kelly_fraction = max(0, kelly_f) * self.fraction  # 음수일 경우 0으로&#10;&#10;        log.info(&quot;Kelly Criterion Initialized.&quot;)&#10;        log.info(f&quot;  - Win Rate: {self.win_rate:.2%}&quot;)&#10;        log.info(f&quot;  - Payoff Ratio: {self.payoff_ratio:.2f}&quot;)&#10;        log.info(f&quot;  - Applied Kelly Fraction (f): {self.kelly_fraction:.2%}&quot;)&#10;        log.info(f&quot;  - Risk per Trade: {self.risk_per_trade:.2%}&quot;)&#10;&#10;    # 총 자산 대비 투자 금액 계산&#10;    # 총 자산의 일정 비율을 켈리 공식에 따라 투자 금액으로 산정&#10;    # e.g., 총 자산 1,000,000 KRW, 켈리 비율 20% -&gt; 200,000 KRW 투자&#10;    # 반환값: 투자할 금액 (float)&#10;    #:param total_balance: 총 자산 (e.g., KRW 잔고)&#10;    #:return: (float) 투자할 금액&#10;    # 계산된 투자 금액 반환&#10;    # 총 자산이 0이거나 켈리 비율이 0인 경우 0 반환&#10;    # 로그에 계산된 투자 금액 출력&#10;    # e.g., &quot;Calculated trade amount: 200,000 KRW (Balance: 1,000,000 * Kelly: 20.00%)&quot;&#10;    # 반환값: 투자할 금액 (float)&#10;    def calculate_trade_amount(self, total_balance):&#10;        if self.kelly_fraction &lt;= 0:&#10;            log.warning(&quot;Kelly fraction is 0 or negative. No investment is advised.&quot;)&#10;            return 0&#10;&#10;        # 총 자산이 0인 경우 0 반환&#10;        if total_balance &lt;= 0:&#10;            log.warning(&quot;Total balance is 0 or negative. No investment can be made.&quot;)&#10;            return 0&#10;&#10;        trade_amount = total_balance * self.kelly_fraction&#10;        log.info(f&quot;Calculated trade amount: {trade_amount:,.0f} KRW (Balance: {total_balance:,.0f} * Kelly: {self.kelly_fraction:.2%})&quot;)&#10;        return trade_amount&#10;&#10;    # 매수 진입 시 적절한 투자 금액과 수량 계산&#10;    # 리스크 관리와 켈리 기준을 모두 고려하여 최종 투자 금액 산정&#10;    #   [로직 설명]&#10;    #    1. 리스크 기반 계산 (Survival): 손절 나갔을 때 계좌의 R(2%)만 잃도록 수량 설정.&#10;    #       - 공식: 허용 손실금액 / (매수가 - 손절가)&#10;    #    2. 켈리 기반 계산 (Growth): 켈리 비중만큼 투자.&#10;    #    3. 최종 결정: 두 값 중 더 '안전한(작은)' 값을 선택하고, 시장 상황(market_factor)을 곱함.&#10;    #&#10;    #    # input&#10;    #    :param total_balance: 현재 계좌 총액 (KRW)&#10;    #    :param entry_price: 진입 예정 가격&#10;    #    :param stop_loss_price: 손절 예정 가격&#10;    #    :param market_factor: 시장 상황 점수 (0.0 ~ 1.0, 1.0=상승장 풀배팅, 0.5=보수적, 0.0=매매금지)&#10;&#10;    #    # return: {&#10;    #        'trade_amount': 투자할 총 금액 (KRW),&#10;    #        'quantity': 구매할 코인 수량,&#10;    #        'risk_amount': 예상 손실 금액,&#10;    #        'reason': 계산 근거&#10;    #    }&#10;    def get_position_size(self, total_balance, entry_price, stop_loss_price, market_factor=1.0):&#10;        if total_balance &lt;= 0 or entry_price &lt;= 0:&#10;            return {'trade_amount': 0, 'quantity': 0, 'reason': &quot;Invalid Balance or Price&quot;}&#10;&#10;        # 1. 1회 최대 허용 손실금액 (R) 계산&#10;        # 예: 1억 계좌, 2% 리스크 -&gt; 200만원 (엑셀의 '2% 금액')&#10;        max_risk_amount = total_balance * self.risk_per_trade&#10;&#10;        # 2. 주당 리스크 (Stop Loss Gap)&#10;        # 예: 1000원에 사서 920원에 손절 -&gt; 주당 80원 리스크&#10;        risk_per_share = entry_price - stop_loss_price&#10;&#10;        if risk_per_share &lt;= 0:&#10;            log.warning(&quot;Stop loss price is higher than entry price (Long Position). Adjusting Logic.&quot;)&#10;            risk_per_share = entry_price * 0.01  # 방어 코드&#10;&#10;        stop_loss_percent = risk_per_share / entry_price&#10;&#10;        # 3. 리스크 기반 최대 진입 수량 (Position Sizing based on Risk)&#10;        # 공식: 내가 감당할 총 손실 / 주당 손실&#10;        quantity_by_risk = max_risk_amount / risk_per_share&#10;        amount_by_risk = quantity_by_risk * entry_price&#10;&#10;        # 4. 켈리 기반 투자 금액 (Position Sizing based on Kelly)&#10;        amount_by_kelly = total_balance * self.kelly_fraction&#10;&#10;        # 5. 최종 금액 선정 (안전한 쪽 선택) &amp; 시장 팩터 반영&#10;        # 켈리가 너무 공격적이면 리스크 관리 룰을 따르고,&#10;        # 리스크 룰이 너무 크면 켈리(자금성장 최적화)를 따름.&#10;        safe_factor = max(0.0, min(1.0, market_factor if market_factor is not None else 1.0))&#10;        final_amount = min(amount_by_risk, amount_by_kelly) * safe_factor&#10;&#10;        # 최소 주문 금액(예: 업비트 5000원) 처리 등은 봇 로직에서 하겠지만 여기선 0 처리&#10;        final_amount = max(0, final_amount)&#10;        final_quantity = final_amount / entry_price&#10;&#10;        # 로그 출력&#10;        log.info(f&quot;[Money Mgmt] Balance: {total_balance:,.0f} KRW | Market Factor: {market_factor}&quot;)&#10;        log.info(f&quot; -&gt; Risk Limit (R={self.risk_per_trade:.1%}): Max Loss {max_risk_amount:,.0f} KRW&quot;)&#10;        log.info(f&quot; -&gt; Stop Loss: {stop_loss_percent:.2%} (Gap: {risk_per_share:,.0f} KRW)&quot;)&#10;        log.info(f&quot; -&gt; Sizing (Risk): {amount_by_risk:,.0f} KRW vs (Kelly): {amount_by_kelly:,.0f} KRW&quot;)&#10;        log.info(f&quot; -&gt; Final Check: Invest {final_amount:,.0f} KRW (Qty: {final_quantity:.4f})&quot;)&#10;&#10;        return {&#10;            'trade_amount': final_amount,&#10;            'quantity': final_quantity,&#10;            'risk_amount': final_quantity * risk_per_share,  # 실제 예상 손실액&#10;            'stop_loss_pct': stop_loss_percent&#10;        }" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/server/order_executor.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/server/order_executor.py" />
              <option name="originalContent" value="from dataclasses import dataclass, field&#10;import math&#10;import queue&#10;import threading&#10;import time&#10;from typing import Any, Callable, Dict, Optional&#10;&#10;import server.config as config&#10;from server.history import order_history_store&#10;from server.logger import log&#10;from server.upbit_api import UpbitAPI&#10;&#10;&#10;@dataclass&#10;class OrderRequest:&#10;    action: str&#10;    symbol: str&#10;    amount_krw: float = 0.0&#10;    volume: float = 0.0&#10;    reason: str = &quot;&quot;&#10;    callback: Optional[Callable[[bool, Dict[str, Any]], None]] = None&#10;    metadata: Dict[str, Any] = field(default_factory=dict)&#10;    trade_amount: Optional[float] = None&#10;    target_quantity: Optional[float] = None&#10;    entry_price: Optional[float] = None&#10;    stop_loss_price: Optional[float] = None&#10;    take_profit_price: Optional[float] = None&#10;    market_factor: Optional[float] = None&#10;    risk_amount: Optional[float] = None&#10;&#10;&#10;class OrderExecutor:&#10;    def __init__(self, api: UpbitAPI, min_order_amount: float = config.MIN_ORDER_AMOUNT):&#10;        self.api = api&#10;        self.min_order_amount = float(min_order_amount)&#10;        self._queue: queue.Queue[Optional[OrderRequest]] = queue.Queue()&#10;        self._stop_event = threading.Event()&#10;        self._thread = threading.Thread(target=self._run, daemon=True)&#10;        self._started = False&#10;&#10;    def start(self) -&gt; None:&#10;        if self._started:&#10;            return&#10;        self._started = True&#10;        self._thread.start()&#10;        log.info(&quot;OrderExecutor thread started.&quot;)&#10;&#10;    def stop(self) -&gt; None:&#10;        self._stop_event.set()&#10;        self._queue.put(None)&#10;        if self._thread.is_alive():&#10;            self._thread.join(timeout=3)&#10;        log.info(&quot;OrderExecutor thread stopped.&quot;)&#10;&#10;    def submit(self, request: OrderRequest) -&gt; None:&#10;        if request.action not in (&quot;BUY&quot;, &quot;SELL&quot;):&#10;            log.warning(f&quot;Unsupported order action: {request.action}&quot;)&#10;            return&#10;        self._queue.put(request)&#10;        log.info(f&quot;OrderRequest queued: {request.action} {request.symbol}&quot;)&#10;&#10;    def _run(self) -&gt; None:&#10;        while not self._stop_event.is_set():&#10;            try:&#10;                request = self._queue.get(timeout=1)&#10;            except queue.Empty:&#10;                continue&#10;            if request is None:&#10;                break&#10;            result = self._process_request(request)&#10;            self._queue.task_done()&#10;            if request.callback:&#10;                try:&#10;                    request.callback(result.get(&quot;success&quot;, False), result)&#10;                except Exception as exc:&#10;                    log.warning(f&quot;Order callback failed: {exc}&quot;)&#10;&#10;    def _process_request(self, request: OrderRequest) -&gt; Dict[str, Any]:&#10;        entry: Dict[str, Any] = {&#10;            &quot;ts&quot;: time.time(),&#10;            &quot;action&quot;: request.action,&#10;            &quot;symbol&quot;: request.symbol,&#10;            &quot;amount_krw&quot;: request.amount_krw,&#10;            &quot;volume&quot;: request.volume,&#10;            &quot;reason&quot;: request.reason,&#10;            &quot;metadata&quot;: request.metadata,&#10;            &quot;trade_amount&quot;: request.trade_amount,&#10;            &quot;target_quantity&quot;: request.target_quantity,&#10;            &quot;entry_price&quot;: request.entry_price,&#10;            &quot;stop_loss_price&quot;: request.stop_loss_price,&#10;            &quot;take_profit_price&quot;: request.take_profit_price,&#10;            &quot;market_factor&quot;: request.market_factor,&#10;            &quot;risk_amount&quot;: request.risk_amount,&#10;        }&#10;&#10;        if request.action == &quot;BUY&quot;:&#10;            payload = self._handle_buy(request)&#10;        else:&#10;            payload = self._handle_sell(request)&#10;&#10;        entry[&quot;success&quot;] = payload.get(&quot;success&quot;, False)&#10;        entry[&quot;details&quot;] = payload.get(&quot;message&quot;)&#10;        entry[&quot;response&quot;] = payload.get(&quot;response&quot;)&#10;        order_history_store.record(entry)&#10;        return payload&#10;&#10;    def _handle_buy(self, request: OrderRequest) -&gt; Dict[str, Any]:&#10;        if request.amount_krw &lt; self.min_order_amount:&#10;            msg = f&quot;주문금액({request.amount_krw:.0f} KRW)이 최소 주문금액({self.min_order_amount:.0f} KRW)보다 작습니다.&quot;&#10;            log.warning(msg)&#10;            return {&quot;success&quot;: False, &quot;message&quot;: msg}&#10;&#10;        available_krw = self.api.get_balance(&quot;KRW&quot;) or 0.0&#10;        if available_krw &lt; request.amount_krw:&#10;            msg = f&quot;원화 잔액 부족. 필요: {request.amount_krw:.0f}, 현재: {available_krw:.0f}&quot;&#10;            log.warning(msg)&#10;            return {&quot;success&quot;: False, &quot;message&quot;: msg}&#10;&#10;        if request.entry_price:&#10;            log.info(&#10;                &quot;[Bracket] entry=%.0f stop=%.0f take=%.0f qty=%.6f risk=%.0f factor=%.2f&quot;&#10;                % (&#10;                    request.entry_price,&#10;                    request.stop_loss_price or 0,&#10;                    request.take_profit_price or 0,&#10;                    request.target_quantity or 0,&#10;                    request.risk_amount or 0,&#10;                    request.market_factor or 0,&#10;                )&#10;            )&#10;&#10;        try:&#10;            response = self.api.place_order(request.symbol, &quot;bid&quot;, ord_type=&quot;price&quot;, price=request.amount_krw)&#10;            log.info(f&quot;BUY order executed: {request.symbol} {request.amount_krw:.0f} KRW&quot;)&#10;            return {&quot;success&quot;: True, &quot;message&quot;: &quot;BUY order executed&quot;, &quot;response&quot;: response}&#10;        except Exception as exc:&#10;            msg = f&quot;BUY 주문 실패: {exc}&quot;&#10;            log.error(msg, exc_info=True)&#10;            return {&quot;success&quot;: False, &quot;message&quot;: msg}&#10;&#10;    def _handle_sell(self, request: OrderRequest) -&gt; Dict[str, Any]:&#10;        coin_symbol = request.symbol.split(&quot;-&quot;)[-1]&#10;        total_volume = self.api.get_balance(coin_symbol)&#10;        &#10;        if not total_volume or math.isclose(total_volume, 0.0):&#10;            msg = f&quot;{coin_symbol} 잔고가 없습니다.&quot;&#10;            log.warning(msg)&#10;            return {&quot;success&quot;: False, &quot;message&quot;: msg}&#10;        &#10;        # 매도 비율 결정 (기본값: 30% 매도, 나머지 70% 보유)&#10;        sell_ratio = float(request.metadata.get('sell_ratio', 0.3)) if request.metadata else 0.3&#10;        sell_ratio = max(0.1, min(1.0, sell_ratio))  # 10%~100% 범위로 제한&#10;        &#10;        volume = request.volume&#10;        if not volume or math.isclose(volume, 0.0):&#10;            volume = total_volume * sell_ratio&#10;        &#10;        # 최소 거래 가능 수량 체크 (보통 0.0001 이상)&#10;        if volume &lt; 0.0001:&#10;            msg = f&quot;매도 수량이 너무 적습니다: {volume:.8f}&quot;&#10;            log.warning(msg)&#10;            return {&quot;success&quot;: False, &quot;message&quot;: msg}&#10;        &#10;        try:&#10;            # 진입가 조회 (이전 매수 기록에서)&#10;            entry_price = request.entry_price or request.metadata.get('entry_price', 0.0)&#10;            &#10;            response = self.api.place_order(request.symbol, &quot;ask&quot;, ord_type=&quot;market&quot;, volume=volume)&#10;            &#10;            # 매도가 계산 (응답에서 평균 체결가 추출)&#10;            avg_price = 0.0&#10;            if isinstance(response, dict):&#10;                avg_price = float(response.get('avg_price', 0) or response.get('price', 0) or 0)&#10;            &#10;            # 손익 계산&#10;            profit_loss = 0.0&#10;            profit_loss_pct = 0.0&#10;            if entry_price &gt; 0 and avg_price &gt; 0:&#10;                profit_loss = (avg_price - entry_price) * volume&#10;                profit_loss_pct = ((avg_price / entry_price) - 1) * 100&#10;            &#10;            log.info(&#10;                f&quot;SELL order executed: {request.symbol} {volume:.8f} units &quot;&#10;                f&quot;(전체의 {sell_ratio*100:.0f}%, 남은 수량: {total_volume - volume:.8f})&quot;&#10;            )&#10;            &#10;            if profit_loss != 0:&#10;                log.info(&#10;                    f&quot;매매 손익: {profit_loss:+.2f} KRW ({profit_loss_pct:+.2f}%) &quot;&#10;                    f&quot;[진입가: {entry_price:.0f}, 매도가: {avg_price:.0f}]&quot;&#10;                )&#10;            &#10;            return {&#10;                &quot;success&quot;: True, &#10;                &quot;message&quot;: &quot;SELL order executed&quot;, &#10;                &quot;response&quot;: response,&#10;                &quot;profit_loss&quot;: profit_loss,&#10;                &quot;profit_loss_pct&quot;: profit_loss_pct,&#10;                &quot;entry_price&quot;: entry_price,&#10;                &quot;exit_price&quot;: avg_price,&#10;                &quot;volume&quot;: volume,&#10;                &quot;total_volume&quot;: total_volume,&#10;                &quot;sell_ratio&quot;: sell_ratio,&#10;            }&#10;        except Exception as exc:&#10;            msg = f&quot;SELL 주문 실패: {exc}&quot;&#10;            log.error(msg, exc_info=True)&#10;            return {&quot;success&quot;: False, &quot;message&quot;: msg}&#10;" />
              <option name="updatedContent" value="from dataclasses import dataclass, field&#10;import math&#10;import queue&#10;import threading&#10;import time&#10;from typing import Any, Callable, Dict, Optional&#10;&#10;import server.config as config&#10;from server.history import order_history_store&#10;from server.logger import log&#10;from server.upbit_api import UpbitAPI&#10;&#10;&#10;@dataclass&#10;class OrderRequest:&#10;    action: str&#10;    symbol: str&#10;    amount_krw: float = 0.0&#10;    volume: float = 0.0&#10;    reason: str = &quot;&quot;&#10;    callback: Optional[Callable[[bool, Dict[str, Any]], None]] = None&#10;    metadata: Dict[str, Any] = field(default_factory=dict)&#10;    trade_amount: Optional[float] = None&#10;    target_quantity: Optional[float] = None&#10;    entry_price: Optional[float] = None&#10;    stop_loss_price: Optional[float] = None&#10;    take_profit_price: Optional[float] = None&#10;    market_factor: Optional[float] = None&#10;    risk_amount: Optional[float] = None&#10;&#10;&#10;class OrderExecutor:&#10;    def __init__(self, api: UpbitAPI, min_order_amount: float = config.MIN_ORDER_AMOUNT):&#10;        self.api = api&#10;        self.min_order_amount = float(min_order_amount)&#10;        self._queue: queue.Queue[Optional[OrderRequest]] = queue.Queue()&#10;        self._stop_event = threading.Event()&#10;        self._thread = threading.Thread(target=self._run, daemon=True)&#10;        self._started = False&#10;&#10;    def start(self) -&gt; None:&#10;        if self._started:&#10;            return&#10;        self._started = True&#10;        self._thread.start()&#10;        log.info(&quot;OrderExecutor thread started.&quot;)&#10;&#10;    def stop(self) -&gt; None:&#10;        self._stop_event.set()&#10;        self._queue.put(None)&#10;        if self._thread.is_alive():&#10;            self._thread.join(timeout=3)&#10;        log.info(&quot;OrderExecutor thread stopped.&quot;)&#10;&#10;    def submit(self, request: OrderRequest) -&gt; None:&#10;        if request.action not in (&quot;BUY&quot;, &quot;SELL&quot;):&#10;            log.warning(f&quot;Unsupported order action: {request.action}&quot;)&#10;            return&#10;        self._queue.put(request)&#10;        log.info(f&quot;OrderRequest queued: {request.action} {request.symbol}&quot;)&#10;&#10;    def _run(self) -&gt; None:&#10;        while not self._stop_event.is_set():&#10;            try:&#10;                request = self._queue.get(timeout=1)&#10;            except queue.Empty:&#10;                continue&#10;            if request is None:&#10;                break&#10;            result = self._process_request(request)&#10;            self._queue.task_done()&#10;            if request.callback:&#10;                try:&#10;                    request.callback(result.get(&quot;success&quot;, False), result)&#10;                except Exception as exc:&#10;                    log.warning(f&quot;Order callback failed: {exc}&quot;)&#10;&#10;    def _process_request(self, request: OrderRequest) -&gt; Dict[str, Any]:&#10;        entry: Dict[str, Any] = {&#10;            &quot;ts&quot;: time.time(),&#10;            &quot;action&quot;: request.action,&#10;            &quot;symbol&quot;: request.symbol,&#10;            &quot;amount_krw&quot;: request.amount_krw,&#10;            &quot;volume&quot;: request.volume,&#10;            &quot;reason&quot;: request.reason,&#10;            &quot;metadata&quot;: request.metadata,&#10;            &quot;trade_amount&quot;: request.trade_amount,&#10;            &quot;target_quantity&quot;: request.target_quantity,&#10;            &quot;entry_price&quot;: request.entry_price,&#10;            &quot;stop_loss_price&quot;: request.stop_loss_price,&#10;            &quot;take_profit_price&quot;: request.take_profit_price,&#10;            &quot;market_factor&quot;: request.market_factor,&#10;            &quot;risk_amount&quot;: request.risk_amount,&#10;        }&#10;&#10;        if request.action == &quot;BUY&quot;:&#10;            payload = self._handle_buy(request)&#10;        else:&#10;            payload = self._handle_sell(request)&#10;&#10;        entry[&quot;success&quot;] = payload.get(&quot;success&quot;, False)&#10;        entry[&quot;details&quot;] = payload.get(&quot;message&quot;)&#10;        entry[&quot;response&quot;] = payload.get(&quot;response&quot;)&#10;        order_history_store.record(entry)&#10;        return payload&#10;&#10;    def _handle_buy(self, request: OrderRequest) -&gt; Dict[str, Any]:&#10;        if request.amount_krw &lt; self.min_order_amount:&#10;            msg = f&quot;주문금액({request.amount_krw:.0f} KRW)이 최소 주문금액({self.min_order_amount:.0f} KRW)보다 작습니다.&quot;&#10;            log.warning(msg)&#10;            return {&quot;success&quot;: False, &quot;message&quot;: msg}&#10;&#10;        available_krw = self.api.get_balance(&quot;KRW&quot;) or 0.0&#10;        if available_krw &lt; request.amount_krw:&#10;            msg = f&quot;원화 잔액 부족. 필요: {request.amount_krw:.0f}, 현재: {available_krw:.0f}&quot;&#10;            log.warning(msg)&#10;            return {&quot;success&quot;: False, &quot;message&quot;: msg}&#10;&#10;        if request.entry_price:&#10;            log.info(&#10;                &quot;[Bracket] entry=%.0f stop=%.0f take=%.0f qty=%.6f risk=%.0f factor=%.2f&quot;&#10;                % (&#10;                    request.entry_price,&#10;                    request.stop_loss_price or 0,&#10;                    request.take_profit_price or 0,&#10;                    request.target_quantity or 0,&#10;                    request.risk_amount or 0,&#10;                    request.market_factor or 0,&#10;                )&#10;            )&#10;&#10;        try:&#10;            response = self.api.place_order(request.symbol, &quot;bid&quot;, ord_type=&quot;price&quot;, price=request.amount_krw)&#10;            log.info(f&quot;BUY order executed: {request.symbol} {request.amount_krw:.0f} KRW&quot;)&#10;            return {&quot;success&quot;: True, &quot;message&quot;: &quot;BUY order executed&quot;, &quot;response&quot;: response}&#10;        except Exception as exc:&#10;            msg = f&quot;BUY 주문 실패: {exc}&quot;&#10;            log.error(msg, exc_info=True)&#10;            return {&quot;success&quot;: False, &quot;message&quot;: msg}&#10;&#10;    def _handle_sell(self, request: OrderRequest) -&gt; Dict[str, Any]:&#10;        coin_symbol = request.symbol.split(&quot;-&quot;)[-1]&#10;        total_volume = self.api.get_balance(coin_symbol)&#10;        &#10;        if not total_volume or math.isclose(total_volume, 0.0):&#10;            msg = f&quot;{coin_symbol} 잔고가 없습니다.&quot;&#10;            log.warning(msg)&#10;            return {&quot;success&quot;: False, &quot;message&quot;: msg}&#10;        &#10;        # 매도 비율 결정 (기본값: 30% 매도, 나머지 70% 보유)&#10;        sell_ratio = float(request.metadata.get('sell_ratio', 0.3)) if request.metadata else 0.3&#10;        sell_ratio = max(0.1, min(1.0, sell_ratio))  # 10%~100% 범위로 제한&#10;        &#10;        volume = request.volume&#10;        if not volume or math.isclose(volume, 0.0):&#10;            volume = total_volume * sell_ratio&#10;        &#10;        # 최소 거래 가능 수량 체크 (보통 0.0001 이상)&#10;        if volume &lt; 0.0001:&#10;            msg = f&quot;매도 수량이 너무 적습니다: {volume:.8f}&quot;&#10;            log.warning(msg)&#10;            return {&quot;success&quot;: False, &quot;message&quot;: msg}&#10;        &#10;        try:&#10;            # 진입가 조회 (이전 매수 기록에서)&#10;            entry_price = request.entry_price or request.metadata.get('entry_price', 0.0)&#10;            &#10;            response = self.api.place_order(request.symbol, &quot;ask&quot;, ord_type=&quot;market&quot;, volume=volume)&#10;            &#10;            # 매도가 계산 (응답에서 평균 체결가 추출)&#10;            avg_price = 0.0&#10;            if isinstance(response, dict):&#10;                avg_price = float(response.get('avg_price', 0) or response.get('price', 0) or 0)&#10;            &#10;            # 손익 계산&#10;            profit_loss = 0.0&#10;            profit_loss_pct = 0.0&#10;            if entry_price &gt; 0 and avg_price &gt; 0:&#10;                profit_loss = (avg_price - entry_price) * volume&#10;                profit_loss_pct = ((avg_price / entry_price) - 1) * 100&#10;            &#10;            log.info(&#10;                f&quot;SELL order executed: {request.symbol} {volume:.8f} units &quot;&#10;                f&quot;(전체의 {sell_ratio*100:.0f}%, 남은 수량: {total_volume - volume:.8f})&quot;&#10;            )&#10;            &#10;            if profit_loss != 0:&#10;                log.info(&#10;                    f&quot;매매 손익: {profit_loss:+.2f} KRW ({profit_loss_pct:+.2f}%) &quot;&#10;                    f&quot;[진입가: {entry_price:.0f}, 매도가: {avg_price:.0f}]&quot;&#10;                )&#10;            &#10;            return {&#10;                &quot;success&quot;: True, &#10;                &quot;message&quot;: &quot;SELL order executed&quot;, &#10;                &quot;response&quot;: response,&#10;                &quot;profit_loss&quot;: profit_loss,&#10;                &quot;profit_loss_pct&quot;: profit_loss_pct,&#10;                &quot;entry_price&quot;: entry_price,&#10;                &quot;exit_price&quot;: avg_price,&#10;                &quot;volume&quot;: volume,&#10;                &quot;total_volume&quot;: total_volume,&#10;                &quot;sell_ratio&quot;: sell_ratio,&#10;            }&#10;        except Exception as exc:&#10;            msg = f&quot;SELL 주문 실패: {exc}&quot;&#10;            log.error(msg, exc_info=True)&#10;            return {&quot;success&quot;: False, &quot;message&quot;: msg}&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/server/upbit_api.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/server/upbit_api.py" />
              <option name="originalContent" value="import jwt&#10;import uuid&#10;import hashlib&#10;from urllib.parse import urlencode&#10;import requests&#10;import time&#10;import random&#10;from typing import Optional&#10;from server.logger import log&#10;try:&#10;    import pyupbit&#10;    _HAS_PYUPBIT = True&#10;except Exception:&#10;    pyupbit = None&#10;    _HAS_PYUPBIT = False&#10;&#10;# pandas and pytz may be available via pyupbit dependencies; import safely&#10;try:&#10;    import pandas as pd&#10;    import pytz&#10;    _HAS_PANDAS = True&#10;except Exception:&#10;    pd = None&#10;    pytz = None&#10;    _HAS_PANDAS = False&#10;&#10;&#10;class UpbitAPI:&#10;    &quot;&quot;&quot;&#10;    업비트 API 연동 클래스&#10;    JWT 인증 및 주요 API 호출 기능&#10;    &quot;&quot;&quot;&#10;&#10;    def __init__(self, access_key=None, secret_key=None):&#10;        self.access_key = access_key&#10;        self.secret_key = secret_key&#10;        self.server_url = &quot;https://api.upbit.com&quot;&#10;&#10;    def _generate_auth_token(self, query_params=None):&#10;        &quot;&quot;&quot;&#10;        API 요청을 위한 JWT 인증 토큰 생성 (키가 없으면 None 반환)&#10;        &quot;&quot;&quot;&#10;        if not self.access_key or not self.secret_key:&#10;            return None&#10;&#10;        payload = {&#10;            'access_key': self.access_key,&#10;            'nonce': str(uuid.uuid4()),&#10;        }&#10;&#10;        # 쿼리 파라미터가 있는 경우, 페이로드에 해시값 추가&#10;        if query_params:&#10;            query_string = urlencode(query_params, doseq=True).encode(&quot;utf-8&quot;)&#10;            m = hashlib.sha512()&#10;            m.update(query_string)&#10;            query_hash = m.hexdigest()&#10;            payload['query_hash'] = query_hash&#10;            payload['query_hash_alg'] = 'SHA512'&#10;&#10;        # JWT 생성&#10;        jwt_token = jwt.encode(payload, self.secret_key, algorithm=&quot;HS256&quot;)&#10;        authorize_token = f&quot;Bearer {jwt_token}&quot;&#10;        return authorize_token&#10;&#10;    def _send_request(self, method, endpoint, params=None, data=None, headers=None):&#10;        &quot;&quot;&quot;&#10;        업비트 API에 요청 전송&#10;        &quot;&quot;&quot;&#10;        url = self.server_url + endpoint&#10;&#10;        # 바디 및 쿼리 설정&#10;        query = params if method in ['GET', 'DELETE'] else None&#10;        body = data if method in ['POST', 'PUT'] else None&#10;&#10;        auth_token = self._generate_auth_token(query or body)&#10;&#10;        if headers is None:&#10;            headers = {}&#10;        if auth_token:&#10;            headers['Authorization'] = auth_token&#10;&#10;        # Implement retry on 429 and some transient network errors&#10;        max_retries = 5&#10;        backoff_base = 0.5&#10;        last_exc = None&#10;        for attempt in range(1, max_retries + 1):&#10;            try:&#10;                if method == 'GET':&#10;                    response = requests.get(url, headers=headers, params=params, timeout=10)&#10;                elif method == 'POST':&#10;                    headers['Content-Type'] = 'application/json'&#10;                    response = requests.post(url, headers=headers, json=data, timeout=10)&#10;                elif method == 'DELETE':&#10;                    response = requests.delete(url, headers=headers, params=params, timeout=10)&#10;                else:&#10;                    raise ValueError(f&quot;Unsupported HTTP method: {method}&quot;)&#10;&#10;                # If rate-limited, backoff and retry&#10;                if response.status_code == 429:&#10;                    wait = backoff_base * (2 ** (attempt - 1))&#10;                    jitter = random.uniform(0, 0.5)&#10;                    total_wait = wait + jitter&#10;                    log.warning(f'Upbit API rate limit hit (429). retry {attempt}/{max_retries} after {total_wait:.2f}s')&#10;                    time.sleep(total_wait)&#10;                    last_exc = requests.exceptions.HTTPError('429 Too Many Requests')&#10;                    continue&#10;&#10;                response.raise_for_status()&#10;                # small pause to avoid tight loops&#10;                time.sleep(0.12)&#10;                return response.json()&#10;            except requests.exceptions.HTTPError as http_err:&#10;                last_exc = http_err&#10;                status = getattr(getattr(http_err, 'response', None), 'status_code', None)&#10;                # if not rate-limited, don't retry further&#10;                if status != 429:&#10;                    txt = getattr(http_err, 'response', None)&#10;                    extra = ''&#10;                    try:&#10;                        if txt is not None:&#10;                            extra = f&quot; - {txt.text}&quot;&#10;                    except Exception:&#10;                        extra = ''&#10;                    # 404 에러는 경고 레벨로만 기록 (거래 중단된 종목일 수 있음)&#10;                    if status == 404:&#10;                        log.warning(f&quot;HTTP 404 (Not Found) occurred: {http_err}{extra}&quot;)&#10;                    else:&#10;                        log.error(f&quot;HTTP error occurred: {http_err}{extra}&quot;)&#10;                    break&#10;                # else loop will retry&#10;            except requests.exceptions.RequestException as req_e:&#10;                last_exc = req_e&#10;                # transient network error -&gt; backoff and retry&#10;                wait = backoff_base * (2 ** (attempt - 1)) + random.uniform(0, 0.5)&#10;                log.warning(f'Network error during Upbit API call: {req_e}. retry {attempt}/{max_retries} after {wait:.2f}s')&#10;                time.sleep(wait)&#10;                continue&#10;            except Exception as e:&#10;                last_exc = e&#10;                log.error(f&quot;An error occurred: {e}&quot;)&#10;                break&#10;&#10;        # Retries exhausted or non-retryable error&#10;        return None&#10;&#10;    # --- Public API Methods ---&#10;&#10;    def get_balances(self):&#10;        &quot;&quot;&quot;&#10;        전체 계좌 잔고 조회 (인증 필요)&#10;        &quot;&quot;&quot;&#10;        endpoint = &quot;/v1/accounts&quot;&#10;        return self._send_request('GET', endpoint)&#10;&#10;    def get_balance(self, ticker=&quot;KRW&quot;):&#10;        &quot;&quot;&quot;&#10;        특정 화폐/코인의 잔고 조회&#10;        &quot;&quot;&quot;&#10;        balances = self.get_balances()&#10;        if balances:&#10;            for b in balances:&#10;                if b.get('currency') == ticker:&#10;                    try:&#10;                        return float(b.get('balance', 0))&#10;                    except Exception:&#10;                        return 0.0&#10;        return 0.0&#10;&#10;    def get_klines(self, market, timeframe=&quot;minute1&quot;, count=200):&#10;        &quot;&quot;&quot;&#10;        캔들(시세) 조회: timeframe 문자열을 Upbit 엔드포인트로 매핑하여 호출합니다.&#10;        지원 예: 'minute1', 'minute3', 'minute5', 'minute15', 'minute60', 'day'&#10;        &quot;&quot;&quot;&#10;        # 매핑&#10;        tf = timeframe.lower()&#10;        if tf.startswith('minute'):&#10;            # minuteN -&gt; /v1/candles/minutes/N&#10;            try:&#10;                n = int(tf.replace('minute', ''))&#10;                endpoint = f&quot;/v1/candles/minutes/{n}&quot;&#10;            except Exception:&#10;                endpoint = &quot;/v1/candles/minutes/1&quot;&#10;        elif tf in ('day', 'days'):&#10;            endpoint = &quot;/v1/candles/days&quot;&#10;        elif tf in ('week', 'weeks'):&#10;            endpoint = &quot;/v1/candles/weeks&quot;&#10;        elif tf in ('month', 'months'):&#10;            endpoint = &quot;/v1/candles/months&quot;&#10;        else:&#10;            # fallback&#10;            endpoint = f&quot;/v1/candles/{tf}&quot;&#10;&#10;        # Try pyupbit if available for convenience and reliability&#10;        tf = timeframe.lower()&#10;        if _HAS_PYUPBIT:&#10;            try:&#10;                # pyupbit uses periods like &quot;minute&quot; string: use the numeric mapping&#10;                if tf.startswith('minute'):&#10;                    n = int(tf.replace('minute',''))&#10;                    interval_str = f&quot;minute{n}&quot;&#10;                    df = pyupbit.get_ohlcv(market, interval=interval_str, count=count)&#10;                elif tf in ('day','days'):&#10;                    df = pyupbit.get_ohlcv(market, interval='day', count=count)&#10;                elif tf in ('week','weeks'):&#10;                    df = pyupbit.get_ohlcv(market, interval='week', count=count)&#10;                elif tf in ('month','months'):&#10;                    df = pyupbit.get_ohlcv(market, interval='month', count=count)&#10;                else:&#10;                    # fallback to requests-based endpoint&#10;                    df = None&#10;                if df is not None:&#10;                    records = []&#10;                    # convert index to KST-aware ISO strings when possible&#10;                    for idx, row in df.iterrows():&#10;                        ts_str = None&#10;                        try:&#10;                            if _HAS_PANDAS and isinstance(idx, pd.Timestamp):&#10;                                # if naive, assume UTC and localize; then convert to Asia/Seoul&#10;                                if idx.tzinfo is None:&#10;                                    idx_utc = idx.tz_localize('UTC')&#10;                                else:&#10;                                    idx_utc = idx.tz_convert('UTC') if idx.tzinfo else idx.tz_localize('UTC')&#10;                                if pytz:&#10;                                    kst = pytz.timezone('Asia/Seoul')&#10;                                    idx_kst = idx_utc.tz_convert(kst)&#10;                                    ts_str = idx_kst.isoformat()&#10;                                else:&#10;                                    ts_str = idx_utc.isoformat()&#10;                            else:&#10;                                # fallback: str(idx)&#10;                                ts_str = str(idx)&#10;                        except Exception:&#10;                            ts_str = str(idx)&#10;                        records.append({'candle_date_time_kst': ts_str, 'opening_price': row['open'], 'high_price': row['high'], 'low_price': row['low'], 'trade_price': row['close'], 'candle_acc_trade_volume': row['volume']})&#10;                    return records&#10;            except Exception as e:&#10;                log.warning(f'pyupbit get_klines failed, falling back to HTTP: {e}')&#10;&#10;        params = {'market': market, 'count': count}&#10;        return self._send_request('GET', endpoint, params=params)&#10;&#10;    def get_orderbook(self, markets):&#10;        if isinstance(markets, (list, tuple)):&#10;            market_param = ','.join(markets)&#10;        else:&#10;            market_param = markets&#10;        data = self._send_request('GET', '/v1/orderbook', params={'markets': market_param})&#10;        if data and isinstance(data, list):&#10;            return data&#10;        return None&#10;&#10;    def place_order(self, market: str, side: str, ord_type: str = 'price', price: Optional[float] = None, volume: Optional[float] = None):&#10;        payload = {&#10;            'market': market,&#10;            'side': side,&#10;            'ord_type': ord_type,&#10;        }&#10;        if ord_type == 'price':&#10;            if price is None:&#10;                raise ValueError('price is required for ord_type=&quot;price&quot;')&#10;            payload['price'] = price&#10;        elif ord_type == 'market':&#10;            if volume is None:&#10;                raise ValueError(&quot;volume is required for market sell (ord_type='market')&quot;)&#10;            payload[&quot;volume&quot;] = str(volume)&#10;        elif ord_type == 'limit':&#10;            if price is None or volume is None:&#10;                raise ValueError('price and volume are required for ord_type=&quot;limit&quot;')&#10;            payload['price'] = price&#10;            payload['volume'] = volume&#10;        else:&#10;            raise ValueError(f&quot;Unsupported ord_type: {ord_type}&quot;)&#10;&#10;        return self._send_request('POST', '/v1/orders', data=payload)&#10;" />
              <option name="updatedContent" value="import jwt&#10;import uuid&#10;import hashlib&#10;from urllib.parse import urlencode&#10;import requests&#10;import time&#10;import random&#10;from typing import Optional&#10;from server.logger import log&#10;try:&#10;    import pyupbit&#10;    _HAS_PYUPBIT = True&#10;except Exception:&#10;    pyupbit = None&#10;    _HAS_PYUPBIT = False&#10;&#10;# pandas and pytz may be available via pyupbit dependencies; import safely&#10;try:&#10;    import pandas as pd&#10;    import pytz&#10;    _HAS_PANDAS = True&#10;except Exception:&#10;    pd = None&#10;    pytz = None&#10;    _HAS_PANDAS = False&#10;&#10;&#10;class UpbitAPI:&#10;    &quot;&quot;&quot;&#10;    업비트 API 연동 클래스&#10;    JWT 인증 및 주요 API 호출 기능&#10;    &quot;&quot;&quot;&#10;&#10;    def __init__(self, access_key=None, secret_key=None):&#10;        self.access_key = access_key&#10;        self.secret_key = secret_key&#10;        self.server_url = &quot;https://api.upbit.com&quot;&#10;&#10;    def _generate_auth_token(self, query_params=None):&#10;        &quot;&quot;&quot;&#10;        API 요청을 위한 JWT 인증 토큰 생성 (키가 없으면 None 반환)&#10;        &quot;&quot;&quot;&#10;        if not self.access_key or not self.secret_key:&#10;            return None&#10;&#10;        payload = {&#10;            'access_key': self.access_key,&#10;            'nonce': str(uuid.uuid4()),&#10;        }&#10;&#10;        # 쿼리 파라미터가 있는 경우, 페이로드에 해시값 추가&#10;        if query_params:&#10;            query_string = urlencode(query_params, doseq=True).encode(&quot;utf-8&quot;)&#10;            m = hashlib.sha512()&#10;            m.update(query_string)&#10;            query_hash = m.hexdigest()&#10;            payload['query_hash'] = query_hash&#10;            payload['query_hash_alg'] = 'SHA512'&#10;&#10;        # JWT 생성&#10;        jwt_token = jwt.encode(payload, self.secret_key, algorithm=&quot;HS256&quot;)&#10;        authorize_token = f&quot;Bearer {jwt_token}&quot;&#10;        return authorize_token&#10;&#10;    def _send_request(self, method, endpoint, params=None, data=None, headers=None):&#10;        &quot;&quot;&quot;&#10;        업비트 API에 요청 전송&#10;        &quot;&quot;&quot;&#10;        url = self.server_url + endpoint&#10;&#10;        # 바디 및 쿼리 설정&#10;        query = params if method in ['GET', 'DELETE'] else None&#10;        body = data if method in ['POST', 'PUT'] else None&#10;&#10;        auth_token = self._generate_auth_token(query or body)&#10;&#10;        if headers is None:&#10;            headers = {}&#10;        if auth_token:&#10;            headers['Authorization'] = auth_token&#10;&#10;        # Implement retry on 429 and some transient network errors&#10;        max_retries = 5&#10;        backoff_base = 0.5&#10;        last_exc = None&#10;        for attempt in range(1, max_retries + 1):&#10;            try:&#10;                if method == 'GET':&#10;                    response = requests.get(url, headers=headers, params=params, timeout=10)&#10;                elif method == 'POST':&#10;                    headers['Content-Type'] = 'application/json'&#10;                    response = requests.post(url, headers=headers, json=data, timeout=10)&#10;                elif method == 'DELETE':&#10;                    response = requests.delete(url, headers=headers, params=params, timeout=10)&#10;                else:&#10;                    raise ValueError(f&quot;Unsupported HTTP method: {method}&quot;)&#10;&#10;                # If rate-limited, backoff and retry&#10;                if response.status_code == 429:&#10;                    wait = backoff_base * (2 ** (attempt - 1))&#10;                    jitter = random.uniform(0, 0.5)&#10;                    total_wait = wait + jitter&#10;                    log.warning(f'Upbit API rate limit hit (429). retry {attempt}/{max_retries} after {total_wait:.2f}s')&#10;                    time.sleep(total_wait)&#10;                    last_exc = requests.exceptions.HTTPError('429 Too Many Requests')&#10;                    continue&#10;&#10;                response.raise_for_status()&#10;                # small pause to avoid tight loops&#10;                time.sleep(0.12)&#10;                return response.json()&#10;            except requests.exceptions.HTTPError as http_err:&#10;                last_exc = http_err&#10;                status = getattr(getattr(http_err, 'response', None), 'status_code', None)&#10;                # if not rate-limited, don't retry further&#10;                if status != 429:&#10;                    txt = getattr(http_err, 'response', None)&#10;                    extra = ''&#10;                    try:&#10;                        if txt is not None:&#10;                            extra = f&quot; - {txt.text}&quot;&#10;                    except Exception:&#10;                        extra = ''&#10;                    # 404 에러는 경고 레벨로만 기록 (거래 중단된 종목일 수 있음)&#10;                    if status == 404:&#10;                        log.warning(f&quot;HTTP 404 (Not Found) occurred: {http_err}{extra}&quot;)&#10;                    else:&#10;                        log.error(f&quot;HTTP error occurred: {http_err}{extra}&quot;)&#10;                    break&#10;                # else loop will retry&#10;            except requests.exceptions.RequestException as req_e:&#10;                last_exc = req_e&#10;                # transient network error -&gt; backoff and retry&#10;                wait = backoff_base * (2 ** (attempt - 1)) + random.uniform(0, 0.5)&#10;                log.warning(f'Network error during Upbit API call: {req_e}. retry {attempt}/{max_retries} after {wait:.2f}s')&#10;                time.sleep(wait)&#10;                continue&#10;            except Exception as e:&#10;                last_exc = e&#10;                log.error(f&quot;An error occurred: {e}&quot;)&#10;                break&#10;&#10;        # Retries exhausted or non-retryable error&#10;        return None&#10;&#10;    # --- Public API Methods ---&#10;&#10;    def get_balances(self):&#10;        &quot;&quot;&quot;&#10;        전체 계좌 잔고 조회 (인증 필요)&#10;        &quot;&quot;&quot;&#10;        endpoint = &quot;/v1/accounts&quot;&#10;        return self._send_request('GET', endpoint)&#10;&#10;    def get_balance(self, ticker=&quot;KRW&quot;):&#10;        &quot;&quot;&quot;&#10;        특정 화폐/코인의 잔고 조회&#10;        &quot;&quot;&quot;&#10;        balances = self.get_balances()&#10;        if balances:&#10;            for b in balances:&#10;                if b.get('currency') == ticker:&#10;                    try:&#10;                        return float(b.get('balance', 0))&#10;                    except Exception:&#10;                        return 0.0&#10;        return 0.0&#10;&#10;    def get_klines(self, market, timeframe=&quot;minute1&quot;, count=200):&#10;        &quot;&quot;&quot;&#10;        캔들(시세) 조회: timeframe 문자열을 Upbit 엔드포인트로 매핑하여 호출합니다.&#10;        지원 예: 'minute1', 'minute3', 'minute5', 'minute15', 'minute60', 'day'&#10;        &quot;&quot;&quot;&#10;        # 매핑&#10;        tf = timeframe.lower()&#10;        if tf.startswith('minute'):&#10;            # minuteN -&gt; /v1/candles/minutes/N&#10;            try:&#10;                n = int(tf.replace('minute', ''))&#10;                endpoint = f&quot;/v1/candles/minutes/{n}&quot;&#10;            except Exception:&#10;                endpoint = &quot;/v1/candles/minutes/1&quot;&#10;        elif tf in ('day', 'days'):&#10;            endpoint = &quot;/v1/candles/days&quot;&#10;        elif tf in ('week', 'weeks'):&#10;            endpoint = &quot;/v1/candles/weeks&quot;&#10;        elif tf in ('month', 'months'):&#10;            endpoint = &quot;/v1/candles/months&quot;&#10;        else:&#10;            # fallback&#10;            endpoint = f&quot;/v1/candles/{tf}&quot;&#10;&#10;        # Try pyupbit if available for convenience and reliability&#10;        tf = timeframe.lower()&#10;        if _HAS_PYUPBIT:&#10;            try:&#10;                # pyupbit uses periods like &quot;minute&quot; string: use the numeric mapping&#10;                if tf.startswith('minute'):&#10;                    n = int(tf.replace('minute',''))&#10;                    interval_str = f&quot;minute{n}&quot;&#10;                    df = pyupbit.get_ohlcv(market, interval=interval_str, count=count)&#10;                elif tf in ('day','days'):&#10;                    df = pyupbit.get_ohlcv(market, interval='day', count=count)&#10;                elif tf in ('week','weeks'):&#10;                    df = pyupbit.get_ohlcv(market, interval='week', count=count)&#10;                elif tf in ('month','months'):&#10;                    df = pyupbit.get_ohlcv(market, interval='month', count=count)&#10;                else:&#10;                    # fallback to requests-based endpoint&#10;                    df = None&#10;                if df is not None:&#10;                    records = []&#10;                    # convert index to KST-aware ISO strings when possible&#10;                    for idx, row in df.iterrows():&#10;                        ts_str = None&#10;                        try:&#10;                            if _HAS_PANDAS and isinstance(idx, pd.Timestamp):&#10;                                # if naive, assume UTC and localize; then convert to Asia/Seoul&#10;                                if idx.tzinfo is None:&#10;                                    idx_utc = idx.tz_localize('UTC')&#10;                                else:&#10;                                    idx_utc = idx.tz_convert('UTC') if idx.tzinfo else idx.tz_localize('UTC')&#10;                                if pytz:&#10;                                    kst = pytz.timezone('Asia/Seoul')&#10;                                    idx_kst = idx_utc.tz_convert(kst)&#10;                                    ts_str = idx_kst.isoformat()&#10;                                else:&#10;                                    ts_str = idx_utc.isoformat()&#10;                            else:&#10;                                # fallback: str(idx)&#10;                                ts_str = str(idx)&#10;                        except Exception:&#10;                            ts_str = str(idx)&#10;                        records.append({'candle_date_time_kst': ts_str, 'opening_price': row['open'], 'high_price': row['high'], 'low_price': row['low'], 'trade_price': row['close'], 'candle_acc_trade_volume': row['volume']})&#10;                    return records&#10;            except Exception as e:&#10;                log.warning(f'pyupbit get_klines failed, falling back to HTTP: {e}')&#10;&#10;        params = {'market': market, 'count': count}&#10;        return self._send_request('GET', endpoint, params=params)&#10;&#10;    def get_orderbook(self, markets):&#10;        if isinstance(markets, (list, tuple)):&#10;            market_param = ','.join(markets)&#10;        else:&#10;            market_param = markets&#10;        data = self._send_request('GET', '/v1/orderbook', params={'markets': market_param})&#10;        if data and isinstance(data, list):&#10;            return data&#10;        return None&#10;&#10;    def place_order(self, market: str, side: str, ord_type: str = 'price', price: Optional[float] = None, volume: Optional[float] = None):&#10;        payload = {&#10;            'market': market,&#10;            'side': side,&#10;            'ord_type': ord_type,&#10;        }&#10;        if ord_type == 'price':&#10;            if price is None:&#10;                raise ValueError('price is required for ord_type=&quot;price&quot;')&#10;            payload['price'] = price&#10;        elif ord_type == 'market':&#10;            if volume is None:&#10;                raise ValueError(&quot;volume is required for market sell (ord_type='market')&quot;)&#10;            payload[&quot;volume&quot;] = str(volume)&#10;        elif ord_type == 'limit':&#10;            if price is None or volume is None:&#10;                raise ValueError('price and volume are required for ord_type=&quot;limit&quot;')&#10;            payload['price'] = price&#10;            payload['volume'] = volume&#10;        else:&#10;            raise ValueError(f&quot;Unsupported ord_type: {ord_type}&quot;)&#10;&#10;        return self._send_request('POST', '/v1/orders', data=payload)&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/server/ws_listener.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/server/ws_listener.py" />
              <option name="originalContent" value="import json&#10;import os&#10;import threading&#10;import time&#10;import logging&#10;import uuid&#10;from collections import deque&#10;from datetime import datetime, timezone, timedelta&#10;from pathlib import Path&#10;from typing import Any, Dict, List, Optional&#10;&#10;import jwt&#10;import websocket  # websocket-client&#10;&#10;from server import config&#10;from server.logger import log, get_logger&#10;from server.config import get_setting&#10;&#10;UPBIT_WS_URL = &quot;wss://api.upbit.com/websocket/v1&quot;&#10;EXEC_HISTORY_DIR = Path(__file__).resolve().parents[1] / &quot;runtime&quot; / &quot;history&quot;&#10;EXEC_HISTORY_FILE = EXEC_HISTORY_DIR / &quot;exec_history.json&quot;&#10;EXEC_HISTORY_MAX = int(os.getenv(&quot;EXEC_HISTORY_MAX_ENTRIES&quot;, &quot;1024&quot;))&#10;EXEC_HISTORY_LOCK = threading.Lock()&#10;WS_STATS_FILE = EXEC_HISTORY_DIR / &quot;ws_stats.json&quot;&#10;KST = timezone(timedelta(hours=9))&#10;logger = get_logger(name='UpbitWSListener', log_file='ws_listener.log', level=logging.INFO)&#10;&#10;&#10;def _timeframe_to_seconds(timeframe: str) -&gt; int:&#10;    if not isinstance(timeframe, str):&#10;        return 60&#10;    tf = timeframe.lower()&#10;    if tf.startswith(&quot;minute&quot;):&#10;        try:&#10;            return max(int(tf.replace(&quot;minute&quot;, &quot;&quot;)) * 60, 60)&#10;        except ValueError:&#10;            return 60&#10;    if tf.startswith(&quot;hour&quot;):&#10;        try:&#10;            return max(int(tf.replace(&quot;hour&quot;, &quot;&quot;)) * 3600, 3600)&#10;        except ValueError:&#10;            return 3600&#10;    if tf.startswith(&quot;day&quot;):&#10;        return 86400&#10;    return 60&#10;&#10;&#10;def _ensure_exec_history_dir() -&gt; None:&#10;    EXEC_HISTORY_DIR.mkdir(parents=True, exist_ok=True)&#10;&#10;&#10;def _load_ws_stats_file() -&gt; Dict[str, Any]:&#10;    _ensure_exec_history_dir()&#10;    if not WS_STATS_FILE.exists():&#10;        return {'total_success': 0, 'total_failure': 0, 'history': []}&#10;    try:&#10;        with WS_STATS_FILE.open('r', encoding='utf-8') as fp:&#10;            return json.load(fp)&#10;    except Exception:&#10;        return {'total_success': 0, 'total_failure': 0, 'history': []}&#10;&#10;&#10;def summarize_ws_stats(raw_stats: Dict[str, Any], last_hour_secs: int = 3600, recent_limit: int = 10) -&gt; Dict[str, Any]:&#10;    totals = {&#10;        'total_success': int(raw_stats.get('total_success', 0)),&#10;        'total_failure': int(raw_stats.get('total_failure', 0)),&#10;    }&#10;    history = raw_stats.get('history') or []&#10;    now_ms = int(time.time() * 1000)&#10;    since_ms = now_ms - int(last_hour_secs * 1000) if last_hour_secs &gt; 0 else 0&#10;&#10;    def _filter_since(entries: List[Dict[str, Any]]) -&gt; List[Dict[str, Any]]:&#10;        if since_ms &lt;= 0:&#10;            return entries[:]&#10;        return [item for item in entries if item.get('ts', 0) &gt;= since_ms]&#10;&#10;    ticker_events = [item for item in history if (item.get('type') or '').lower() == 'ticker']&#10;    order_events = [item for item in history if (item.get('type') or '').lower() == 'order']&#10;&#10;    ticker_success = sum(1 for item in ticker_events if item.get('success'))&#10;    ticker_failure = len(ticker_events) - ticker_success&#10;    order_success = sum(1 for item in order_events if item.get('success'))&#10;    order_failure = len(order_events) - order_success&#10;&#10;    ticker_last_hour = _filter_since(ticker_events)&#10;    order_last_hour = _filter_since(order_events)&#10;&#10;    ticker_last_hour_success = sum(1 for item in ticker_last_hour if item.get('success'))&#10;    ticker_last_hour_failure = len(ticker_last_hour) - ticker_last_hour_success&#10;    order_last_hour_success = sum(1 for item in order_last_hour if item.get('success'))&#10;    order_last_hour_failure = len(order_last_hour) - order_last_hour_success&#10;&#10;    if recent_limit &gt; 0:&#10;        recent_ticker_events = ticker_events[-recent_limit:]&#10;    else:&#10;        recent_ticker_events = ticker_events[:]&#10;&#10;    return {&#10;        'total_success': totals['total_success'],&#10;        'total_failure': totals['total_failure'],&#10;        'ticker_success': ticker_success,&#10;        'ticker_failure': ticker_failure,&#10;        'order_success': order_success,&#10;        'order_failure': order_failure,&#10;        'last_hour_ticker_success': ticker_last_hour_success,&#10;        'last_hour_ticker_failure': ticker_last_hour_failure,&#10;        'last_hour_order_success': order_last_hour_success,&#10;        'last_hour_order_failure': order_last_hour_failure,&#10;        'recent_ticker_events': recent_ticker_events,&#10;    }&#10;&#10;&#10;def read_exec_history(limit: int = 200) -&gt; List[Dict[str, Any]]:&#10;    store = ExecHistoryStore()&#10;    return store.read_recent(limit)&#10;&#10;&#10;class ExecHistoryStore:&#10;    def __init__(self, path: Path = EXEC_HISTORY_FILE, max_entries: int = EXEC_HISTORY_MAX):&#10;        self.path = path&#10;        self.max_entries = max_entries&#10;        _ensure_exec_history_dir()&#10;&#10;    def _load(self) -&gt; List[Dict[str, Any]]:&#10;        if not self.path.exists():&#10;            return []&#10;        try:&#10;            with self.path.open(&quot;r&quot;, encoding=&quot;utf-8&quot;) as fp:&#10;                return json.load(fp)&#10;        except Exception as exc:&#10;            log.warning(f&quot;Failed to load exec history: {exc}&quot;)&#10;            return []&#10;&#10;    def _save(self, data: List[Dict[str, Any]]) -&gt; None:&#10;        try:&#10;            with self.path.open(&quot;w&quot;, encoding=&quot;utf-8&quot;) as fp:&#10;                json.dump(data, fp, ensure_ascii=False)&#10;        except Exception as exc:&#10;            log.warning(f&quot;Failed to write exec history: {exc}&quot;)&#10;&#10;    def record(self, entry: Dict[str, Any]) -&gt; None:&#10;        with EXEC_HISTORY_LOCK:&#10;            data = self._load()&#10;            data.append(entry)&#10;            if len(data) &gt; self.max_entries:&#10;                data = data[-self.max_entries :]&#10;            self._save(data)&#10;&#10;    def read_recent(self, limit: int = 200) -&gt; List[Dict[str, Any]]:&#10;        data = self._load()&#10;        if limit &lt;= 0:&#10;            return data[:]&#10;        return data[-limit:]&#10;&#10;&#10;class WebsocketListener:&#10;    def __init__(self, redis_client: Optional[Any] = None):&#10;        self.redis_client = redis_client&#10;        self._jwt_token = _generate_ws_token()&#10;        universe = get_setting(&quot;universe&quot;)&#10;        if isinstance(universe, list) and universe:&#10;            self.targets = universe&#10;        else:&#10;            # fallback sample list&#10;            self.targets = [&quot;KRW-BTC&quot;, &quot;KRW-ETH&quot;, &quot;KRW-ADA&quot;, &quot;KRW-XRP&quot;, &quot;KRW-SOL&quot;]&#10;        self.history_store = ExecHistoryStore()&#10;        self._stop_event = threading.Event()&#10;        self._thread: Optional[threading.Thread] = None&#10;        self._ws: Optional[websocket.WebSocketApp] = None&#10;        self._candle_state: Dict[str, Dict[str, Any]] = {}&#10;        self._candle_history_limit = int(os.getenv('WS_CANDLE_HISTORY_LIMIT', '240'))&#10;        self._last_acc_volume: Dict[str, float] = {}&#10;        self._entry_prices: Dict[str, float] = {}&#10;        self._timeframes = self._resolve_timeframes()&#10;        self._tf_state: Dict[str, Dict[str, Dict[str, Any]]] = {}&#10;        self._stats_history_limit = int(os.getenv('WS_STATS_HISTORY_LIMIT', '4000'))&#10;        self._stats_lock = threading.Lock()&#10;        stats = self._load_stats()&#10;        self._stats_totals = {&#10;            'success': stats.get('total_success', 0),&#10;            'failure': stats.get('total_failure', 0),&#10;        }&#10;        history_entries = stats.get('history', [])&#10;        self._stats_history: deque[Dict[str, Any]] = deque(history_entries[-self._stats_history_limit :], maxlen=self._stats_history_limit)&#10;&#10;    def _load_stats(self) -&gt; Dict[str, Any]:&#10;        if not WS_STATS_FILE.exists():&#10;            return {'total_success': 0, 'total_failure': 0, 'history': []}&#10;        try:&#10;            with WS_STATS_FILE.open('r', encoding='utf-8') as fp:&#10;                return json.load(fp)&#10;        except Exception:&#10;            return {'total_success': 0, 'total_failure': 0, 'history': []}&#10;&#10;    def _save_stats(self) -&gt; None:&#10;        try:&#10;            temp = WS_STATS_FILE.with_suffix('.tmp')&#10;            with temp.open('w', encoding='utf-8') as fp:&#10;                json.dump({&#10;                    'total_success': self._stats_totals['success'],&#10;                    'total_failure': self._stats_totals['failure'],&#10;                    'history': list(self._stats_history),&#10;                }, fp)&#10;            temp.replace(WS_STATS_FILE)&#10;        except Exception as exc:&#10;            log.warning(f'Failed to save websocket stats: {exc}')&#10;&#10;    def _register_reception(self, success: bool, payload: Dict[str, Any]) -&gt; None:&#10;        with self._stats_lock:&#10;            key = 'ticker' if payload.get('type') == 'ticker' else 'order'&#10;            ts = payload.get('trade_timestamp') or payload.get('timestamp') or int(time.time() * 1000)&#10;            entry = {&#10;                'ts': ts,&#10;                'type': payload.get('type'),&#10;                'symbol': payload.get('code') or payload.get('symbol'),&#10;                'success': success,&#10;            }&#10;            if success:&#10;                self._stats_totals['success'] += 1&#10;            else:&#10;                self._stats_totals['failure'] += 1&#10;            self._stats_history.append(entry)&#10;            self._save_stats()&#10;&#10;    def _payload_for_subscription(self) -&gt; str:&#10;        message = [&#10;            {&quot;ticket&quot;: self._jwt_token},&#10;            {&quot;type&quot;: &quot;MyOrder&quot;, &quot;codes&quot;: [&quot;KRW-&quot; + t.split('-')[-1] if not t.startswith('KRW-') else t for t in self.targets]},&#10;        ]&#10;        return json.dumps(message)&#10;&#10;    def _push_candle(self, ticker: str, timeframe: str, candle: Dict[str, Any]) -&gt; None:&#10;        if self.redis_client is None:&#10;            return&#10;        try:&#10;            key = f&quot;ws:candles:{timeframe}:{ticker}&quot;&#10;            candle = candle.copy()&#10;            ts = candle.get(&quot;timestamp&quot;)&#10;            if ts:&#10;                try:&#10;                    qualifier = datetime.fromtimestamp(ts / 1000.0, KST)&#10;                    candle[&quot;candle_date_time_kst&quot;] = qualifier.strftime(&quot;%Y-%m-%dT%H:%M:%S%z&quot;)&#10;                except Exception:&#10;                    pass&#10;            candle.setdefault(&quot;candle_acc_trade_volume&quot;, candle.get(&quot;volume&quot;, 0.0))&#10;            self.redis_client.lpush(key, json.dumps(candle))&#10;            self.redis_client.ltrim(key, 0, self._candle_history_limit - 1)&#10;        except Exception as exc:&#10;            log.warning(f&quot;Redis candle push failed: {exc}&quot;)&#10;&#10;    def _read_cached_candles(self, ticker: str, timeframe: str = 'minute1', limit: int = 200) -&gt; List[Dict[str, Any]]:&#10;        if self.redis_client is None:&#10;            return []&#10;        key = f&quot;ws:candles:{timeframe}:{ticker}&quot;&#10;        try:&#10;            raw = self.redis_client.lrange(key, 0, limit - 1)&#10;        except Exception:&#10;            return []&#10;        result = []&#10;        for raw_item in reversed(raw):&#10;            try:&#10;                payload = json.loads(raw_item)&#10;                result.append(payload)&#10;            except Exception:&#10;                continue&#10;        return result&#10;&#10;    def _aggregate_candle(self, payload: Dict[str, Any]) -&gt; None:&#10;        ticker = payload.get(&quot;code&quot;) or payload.get(&quot;symbol&quot;)&#10;        if not ticker:&#10;            return&#10;        ts = payload.get(&quot;trade_timestamp&quot;) or payload.get(&quot;timestamp&quot;) or int(time.time() * 1000)&#10;        try:&#10;            ts_val = float(ts)&#10;        except Exception:&#10;            ts_val = float(time.time() * 1000)&#10;        minute_ts = int(ts_val // 60000 * 60000)&#10;        price = float(payload.get(&quot;trade_price&quot;) or payload.get(&quot;price&quot;) or 0.0)&#10;        if price &lt;= 0:&#10;            return&#10;        state = self._candle_state.get(ticker)&#10;        if not state or state.get(&quot;minute&quot;) != minute_ts:&#10;            if state:&#10;                self._push_candle(ticker, 'minute1', {&#10;                    &quot;ticker&quot;: ticker,&#10;                    &quot;timestamp&quot;: state[&quot;minute&quot;],&#10;                    &quot;open&quot;: state[&quot;open&quot;],&#10;                    &quot;high&quot;: state[&quot;high&quot;],&#10;                    &quot;low&quot;: state[&quot;low&quot;],&#10;                    &quot;close&quot;: state[&quot;close&quot;],&#10;                    &quot;volume&quot;: state[&quot;volume&quot;],&#10;                })&#10;                self._emit_to_timeframes(ticker, state[&quot;minute&quot;], state)&#10;            self._candle_state[ticker] = {&#10;                &quot;minute&quot;: minute_ts,&#10;                &quot;open&quot;: price,&#10;                &quot;high&quot;: price,&#10;                &quot;low&quot;: price,&#10;                &quot;close&quot;: price,&#10;                &quot;volume&quot;: 0.0,&#10;            }&#10;            self._last_acc_volume[ticker] = float(payload.get(&quot;acc_trade_volume&quot;, 0) or 0)&#10;            return&#10;        if price &gt; state[&quot;high&quot;]:&#10;            state[&quot;high&quot;] = price&#10;        if price &lt; state[&quot;low&quot;]:&#10;            state[&quot;low&quot;] = price&#10;        state[&quot;close&quot;] = price&#10;        acc_vol = float(payload.get(&quot;acc_trade_volume&quot;, 0) or 0)&#10;        prev_acc = self._last_acc_volume.get(ticker, 0.0)&#10;        if acc_vol &gt;= prev_acc:&#10;            state[&quot;volume&quot;] += acc_vol - prev_acc&#10;        else:&#10;            state[&quot;volume&quot;] += acc_vol&#10;        self._last_acc_volume[ticker] = acc_vol&#10;&#10;    def _store_to_redis(self, payload: Dict[str, Any]) -&gt; None:&#10;        if self.redis_client is None:&#10;            return&#10;        try:&#10;            code = payload.get(&quot;code&quot;) or payload.get(&quot;symbol&quot;)&#10;            if not code:&#10;                return&#10;            key_base = f&quot;ws:{payload.get('type', 'unknown')}:{code}&quot;&#10;            self.redis_client.set(key_base, json.dumps(payload))&#10;            if payload.get(&quot;type&quot;) == &quot;trade&quot;:&#10;                list_key = f&quot;ws:trades:{code}&quot;&#10;                self.redis_client.lpush(list_key, json.dumps(payload))&#10;                self.redis_client.ltrim(list_key, 0, 200)&#10;            if payload.get(&quot;type&quot;) == &quot;ticker&quot;:&#10;                self._aggregate_candle(payload)&#10;        except Exception as exc:&#10;            log.warning(f&quot;Redis write failed for websocket payload: {exc}&quot;)&#10;&#10;    def _record_exec_history(self, payload: Dict[str, Any]) -&gt; None:&#10;        if payload.get(&quot;type&quot;) != &quot;order&quot;:&#10;            return&#10;        entry = {&#10;            &quot;ts&quot;: float(payload.get(&quot;timestamp&quot;, payload.get(&quot;trade_timestamp&quot;, time.time())) / 1000.0)&#10;            if payload.get(&quot;timestamp&quot;)&#10;            else time.time(),&#10;            &quot;symbol&quot;: payload.get(&quot;code&quot;) or payload.get(&quot;symbol&quot;),&#10;            &quot;price&quot;: payload.get(&quot;price&quot;) or payload.get(&quot;order_price&quot;) or 0,&#10;            &quot;size&quot;: payload.get(&quot;trade_volume&quot;, payload.get(&quot;volume&quot;) or 0),&#10;            &quot;side&quot;: payload.get(&quot;side&quot;) or payload.get(&quot;order_side&quot;) or payload.get(&quot;ask_bid&quot;),&#10;            &quot;order_id&quot;: payload.get(&quot;uuid&quot;) or payload.get(&quot;order_id&quot;),&#10;        }&#10;        side = (entry.get(&quot;side&quot;) or &quot;&quot;).lower()&#10;        symbol = entry.get(&quot;symbol&quot;)&#10;        avg_price = payload.get(&quot;avg_price&quot;) or payload.get(&quot;avg_buy_price&quot;) or payload.get(&quot;order_price&quot;) or payload.get(&quot;price&quot;)&#10;        try:&#10;            avg_price_val = float(avg_price) if avg_price is not None else 0.0&#10;        except Exception:&#10;            avg_price_val = 0.0&#10;&#10;        entry_price_value = 0.0&#10;        if side in (&quot;bid&quot;, &quot;buy&quot;, &quot;매수&quot;):&#10;            self._entry_prices[symbol] = avg_price_val or self._entry_prices.get(symbol, 0.0)&#10;        else:&#10;            entry_price_value = self._entry_prices.get(symbol, avg_price_val)&#10;        entry[&quot;entry_price&quot;] = entry_price_value or 0.0&#10;        if entry[&quot;symbol&quot;]:&#10;            self.history_store.record(entry)&#10;&#10;    def _on_message(self, _, message: str) -&gt; None:&#10;        try:&#10;            payloads = json.loads(message)&#10;            if isinstance(payloads, list):&#10;                for payload in payloads:&#10;                    self._handle_payload(payload)&#10;            elif isinstance(payloads, dict):&#10;                self._handle_payload(payloads)&#10;        except Exception as exc:&#10;            log.warning(f&quot;Failed to parse websocket message: {exc}&quot;)&#10;&#10;    def _handle_payload(self, payload: Dict[str, Any]) -&gt; None:&#10;        success = True&#10;        try:&#10;            self._store_to_redis(payload)&#10;            self._record_exec_history(payload)&#10;        except Exception as exc:&#10;            success = False&#10;            log.warning(f&quot;Websocket payload handling failed: {exc}&quot;)&#10;        finally:&#10;            self._register_reception(success, payload)&#10;&#10;    def _resolve_timeframes(self) -&gt; List[str]:&#10;        cfg_frames = get_setting('ws_timeframes')&#10;        frames: List[str] = []&#10;        if isinstance(cfg_frames, list):&#10;            for tf in cfg_frames:&#10;                if isinstance(tf, str) and tf.strip():&#10;                    frames.append(tf.strip())&#10;        primary = get_setting('timeframe') or 'minute5'&#10;        if primary not in frames:&#10;            frames.append(primary)&#10;        if 'minute1' not in frames:&#10;            frames.insert(0, 'minute1')&#10;        seen: List[str] = []&#10;        for tf in frames:&#10;            if tf not in seen:&#10;                seen.append(tf)&#10;        return seen&#10;&#10;    def _emit_to_timeframes(self, ticker: str, base_ts: float, candle: Dict[str, Any]) -&gt; None:&#10;        bucket_map = self._tf_state.setdefault(ticker, {})&#10;        for timeframe in self._timeframes:&#10;            if timeframe == 'minute1':&#10;                continue&#10;            duration = _timeframe_to_seconds(timeframe) * 1000&#10;            bucket_start = int(base_ts // duration) * duration&#10;            state = bucket_map.get(timeframe)&#10;            if not state or state.get('start') != bucket_start:&#10;                if state:&#10;                    self._push_candle(ticker, timeframe, state)&#10;                bucket_map[timeframe] = {&#10;                    'ticker': ticker,&#10;                    'timeframe': timeframe,&#10;                    'timestamp': bucket_start,&#10;                    'start': bucket_start,&#10;                    'open': candle.get('open'),&#10;                    'high': candle.get('high'),&#10;                    'low': candle.get('low'),&#10;                    'close': candle.get('close'),&#10;                    'volume': candle.get('volume', 0.0),&#10;                }&#10;            else:&#10;                state['high'] = max(state.get('high', 0.0), candle.get('high', 0.0))&#10;                state['low'] = min(state.get('low', state.get('high', 0.0)), candle.get('low', 0.0))&#10;                state['close'] = candle.get('close')&#10;                state['volume'] = state.get('volume', 0.0) + candle.get('volume', 0.0)&#10;&#10;    def _extract_message_payload(self, value: Any) -&gt; Optional[str]:&#10;        if value is None:&#10;            return None&#10;        if isinstance(value, dict):&#10;            return value.get('message') or value.get('errorMessage') or value.get('errorMsg')&#10;        if isinstance(value, str):&#10;            try:&#10;                parsed = json.loads(value)&#10;                if isinstance(parsed, dict):&#10;                    return parsed.get('message') or parsed.get('errorMessage') or parsed.get('errorMsg')&#10;            except json.JSONDecodeError:&#10;                return value&#10;        try:&#10;            return str(value)&#10;        except Exception:&#10;            return None&#10;&#10;    def _format_close_info(self, code: Any, msg: Any) -&gt; str:&#10;        parts: list[str] = []&#10;        if code is not None:&#10;            parts.append(f&quot;code={code}&quot;)&#10;        message = self._extract_message_payload(msg)&#10;        if message:&#10;            parts.append(f&quot;msg={message}&quot;)&#10;        elif msg is not None:&#10;            try:&#10;                decoded = msg.decode() if isinstance(msg, bytes) else str(msg)&#10;            except Exception:&#10;                decoded = str(msg)&#10;            parts.append(f&quot;msg={decoded}&quot;)&#10;        return &quot;, &quot;.join(parts) if parts else &quot;no details&quot;&#10;&#10;    def _on_error(self, _, error: Any) -&gt; None:&#10;        detail = self._extract_message_payload(error)&#10;        if detail:&#10;            logger.warning(f&quot;Websocket listener error: {detail}&quot;)&#10;        else:&#10;            logger.warning(f&quot;Websocket listener error: {error}&quot;)&#10;&#10;    def _on_close(self, _, close_status_code, close_msg) -&gt; None:&#10;        close_info = self._format_close_info(close_status_code, close_msg)&#10;        logger.info(f&quot;Websocket connection closed ({close_info})&quot;)&#10;&#10;    def _on_open(self, ws: websocket.WebSocketApp) -&gt; None:&#10;        self._ws = ws&#10;        try:&#10;            logger.info(f&quot;Sending subscription payload: {self._payload_for_subscription()}&quot;)&#10;            ws.send(self._payload_for_subscription())&#10;        except Exception as exc:&#10;            logger.warning(f&quot;Failed to send websocket subscription: {exc}&quot;)&#10;&#10;    def _run(self) -&gt; None:&#10;        while not self._stop_event.is_set():&#10;            if not self._jwt_token:&#10;                time.sleep(5)&#10;                continue&#10;            try:&#10;                headers = []&#10;                if self._jwt_token:&#10;                    headers.append(f&quot;Authorization: Bearer {self._jwt_token}&quot;)&#10;                ws_app = websocket.WebSocketApp(&#10;                    UPBIT_WS_URL,&#10;                    on_open=self._on_open,&#10;                    on_message=self._on_message,&#10;                    on_error=self._on_error,&#10;                    on_close=self._on_close,&#10;                    header=headers if headers else None,&#10;                 )&#10;                ws_app.run_forever(ping_interval=20, ping_timeout=10)&#10;            except Exception as exc:&#10;                logger.warning(f&quot;Websocket listener restart: {exc}&quot;)&#10;            time.sleep(2)&#10;&#10;    def start(self) -&gt; None:&#10;        if self._thread and self._thread.is_alive():&#10;            return&#10;        self._stop_event.clear()&#10;        self._thread = threading.Thread(target=self._run, daemon=True)&#10;        self._thread.start()&#10;        logger.info(&quot;Websocket listener started.&quot;)&#10;&#10;    def stop(self) -&gt; None:&#10;        self._stop_event.set()&#10;        if self._ws:&#10;            try:&#10;                self._ws.close()&#10;            except Exception:&#10;                pass&#10;        if self._thread:&#10;            self._thread.join(timeout=2)&#10;        logger.info(&quot;Websocket listener stopped.&quot;)&#10;&#10;&#10;def _get_universe_targets() -&gt; List[str]:&#10;    universe = get_setting('universe')&#10;    if isinstance(universe, list) and universe:&#10;        return universe&#10;    return [&quot;KRW-BTC&quot;, &quot;KRW-ETH&quot;, &quot;KRW-ADA&quot;, &quot;KRW-XRP&quot;, &quot;KRW-SOL&quot;]&#10;&#10;&#10;def _generate_ws_token() -&gt; Optional[str]:&#10;    access_key = config.UPBIT_ACCESS_KEY&#10;    secret_key = config.UPBIT_SECRET_KEY&#10;    if not access_key or not secret_key:&#10;        logger.warning('UPBIT_ACCESS_KEY/UPBIT_SECRET_KEY missing; MyOrder websocket authentication skipped.')&#10;        return None&#10;    payload = {'access_key': access_key, 'nonce': str(uuid.uuid4())}&#10;    try:&#10;        token = jwt.encode(payload, secret_key, algorithm='HS256')&#10;        return token.decode() if isinstance(token, bytes) else token&#10;    except Exception as exc:&#10;        logger.warning(f'Failed to create websocket JWT: {exc}')&#10;        return None&#10;" />
              <option name="updatedContent" value="import json&#10;import os&#10;import threading&#10;import time&#10;import logging&#10;import uuid&#10;from collections import deque&#10;from datetime import datetime, timezone, timedelta&#10;from pathlib import Path&#10;from typing import Any, Dict, List, Optional&#10;&#10;import jwt&#10;import websocket  # websocket-client&#10;&#10;from server import config&#10;from server.logger import log, get_logger&#10;from server.config import get_setting&#10;&#10;UPBIT_WS_URL = &quot;wss://api.upbit.com/websocket/v1&quot;&#10;EXEC_HISTORY_DIR = Path(__file__).resolve().parents[1] / &quot;runtime&quot; / &quot;history&quot;&#10;EXEC_HISTORY_FILE = EXEC_HISTORY_DIR / &quot;exec_history.json&quot;&#10;EXEC_HISTORY_MAX = int(os.getenv(&quot;EXEC_HISTORY_MAX_ENTRIES&quot;, &quot;1024&quot;))&#10;EXEC_HISTORY_LOCK = threading.Lock()&#10;WS_STATS_FILE = EXEC_HISTORY_DIR / &quot;ws_stats.json&quot;&#10;KST = timezone(timedelta(hours=9))&#10;logger = get_logger(name='UpbitWSListener', log_file='ws_listener.log', level=logging.INFO)&#10;&#10;&#10;def _timeframe_to_seconds(timeframe: str) -&gt; int:&#10;    if not isinstance(timeframe, str):&#10;        return 60&#10;    tf = timeframe.lower()&#10;    if tf.startswith(&quot;minute&quot;):&#10;        try:&#10;            return max(int(tf.replace(&quot;minute&quot;, &quot;&quot;)) * 60, 60)&#10;        except ValueError:&#10;            return 60&#10;    if tf.startswith(&quot;hour&quot;):&#10;        try:&#10;            return max(int(tf.replace(&quot;hour&quot;, &quot;&quot;)) * 3600, 3600)&#10;        except ValueError:&#10;            return 3600&#10;    if tf.startswith(&quot;day&quot;):&#10;        return 86400&#10;    return 60&#10;&#10;&#10;def _ensure_exec_history_dir() -&gt; None:&#10;    EXEC_HISTORY_DIR.mkdir(parents=True, exist_ok=True)&#10;&#10;&#10;def _load_ws_stats_file() -&gt; Dict[str, Any]:&#10;    _ensure_exec_history_dir()&#10;    if not WS_STATS_FILE.exists():&#10;        return {'total_success': 0, 'total_failure': 0, 'history': []}&#10;    try:&#10;        with WS_STATS_FILE.open('r', encoding='utf-8') as fp:&#10;            return json.load(fp)&#10;    except Exception:&#10;        return {'total_success': 0, 'total_failure': 0, 'history': []}&#10;&#10;&#10;def summarize_ws_stats(raw_stats: Dict[str, Any], last_hour_secs: int = 3600, recent_limit: int = 10) -&gt; Dict[str, Any]:&#10;    totals = {&#10;        'total_success': int(raw_stats.get('total_success', 0)),&#10;        'total_failure': int(raw_stats.get('total_failure', 0)),&#10;    }&#10;    history = raw_stats.get('history') or []&#10;    now_ms = int(time.time() * 1000)&#10;    since_ms = now_ms - int(last_hour_secs * 1000) if last_hour_secs &gt; 0 else 0&#10;&#10;    def _filter_since(entries: List[Dict[str, Any]]) -&gt; List[Dict[str, Any]]:&#10;        if since_ms &lt;= 0:&#10;            return entries[:]&#10;        return [item for item in entries if item.get('ts', 0) &gt;= since_ms]&#10;&#10;    ticker_events = [item for item in history if (item.get('type') or '').lower() == 'ticker']&#10;    order_events = [item for item in history if (item.get('type') or '').lower() == 'order']&#10;&#10;    ticker_success = sum(1 for item in ticker_events if item.get('success'))&#10;    ticker_failure = len(ticker_events) - ticker_success&#10;    order_success = sum(1 for item in order_events if item.get('success'))&#10;    order_failure = len(order_events) - order_success&#10;&#10;    ticker_last_hour = _filter_since(ticker_events)&#10;    order_last_hour = _filter_since(order_events)&#10;&#10;    ticker_last_hour_success = sum(1 for item in ticker_last_hour if item.get('success'))&#10;    ticker_last_hour_failure = len(ticker_last_hour) - ticker_last_hour_success&#10;    order_last_hour_success = sum(1 for item in order_last_hour if item.get('success'))&#10;    order_last_hour_failure = len(order_last_hour) - order_last_hour_success&#10;&#10;    if recent_limit &gt; 0:&#10;        recent_ticker_events = ticker_events[-recent_limit:]&#10;    else:&#10;        recent_ticker_events = ticker_events[:]&#10;&#10;    return {&#10;        'total_success': totals['total_success'],&#10;        'total_failure': totals['total_failure'],&#10;        'ticker_success': ticker_success,&#10;        'ticker_failure': ticker_failure,&#10;        'order_success': order_success,&#10;        'order_failure': order_failure,&#10;        'last_hour_ticker_success': ticker_last_hour_success,&#10;        'last_hour_ticker_failure': ticker_last_hour_failure,&#10;        'last_hour_order_success': order_last_hour_success,&#10;        'last_hour_order_failure': order_last_hour_failure,&#10;        'recent_ticker_events': recent_ticker_events,&#10;    }&#10;&#10;&#10;def read_exec_history(limit: int = 200) -&gt; List[Dict[str, Any]]:&#10;    store = ExecHistoryStore()&#10;    return store.read_recent(limit)&#10;&#10;&#10;class ExecHistoryStore:&#10;    def __init__(self, path: Path = EXEC_HISTORY_FILE, max_entries: int = EXEC_HISTORY_MAX):&#10;        self.path = path&#10;        self.max_entries = max_entries&#10;        _ensure_exec_history_dir()&#10;&#10;    def _load(self) -&gt; List[Dict[str, Any]]:&#10;        if not self.path.exists():&#10;            return []&#10;        try:&#10;            with self.path.open(&quot;r&quot;, encoding=&quot;utf-8&quot;) as fp:&#10;                return json.load(fp)&#10;        except Exception as exc:&#10;            log.warning(f&quot;Failed to load exec history: {exc}&quot;)&#10;            return []&#10;&#10;    def _save(self, data: List[Dict[str, Any]]) -&gt; None:&#10;        try:&#10;            with self.path.open(&quot;w&quot;, encoding=&quot;utf-8&quot;) as fp:&#10;                json.dump(data, fp, ensure_ascii=False)&#10;        except Exception as exc:&#10;            log.warning(f&quot;Failed to write exec history: {exc}&quot;)&#10;&#10;    def record(self, entry: Dict[str, Any]) -&gt; None:&#10;        with EXEC_HISTORY_LOCK:&#10;            data = self._load()&#10;            data.append(entry)&#10;            if len(data) &gt; self.max_entries:&#10;                data = data[-self.max_entries :]&#10;            self._save(data)&#10;&#10;    def read_recent(self, limit: int = 200) -&gt; List[Dict[str, Any]]:&#10;        data = self._load()&#10;        if limit &lt;= 0:&#10;            return data[:]&#10;        return data[-limit:]&#10;&#10;&#10;class WebsocketListener:&#10;    def __init__(self, redis_client: Optional[Any] = None):&#10;        self.redis_client = redis_client&#10;        self._jwt_token = _generate_ws_token()&#10;        universe = get_setting(&quot;universe&quot;)&#10;        if isinstance(universe, list) and universe:&#10;            self.targets = universe&#10;        else:&#10;            # fallback sample list&#10;            self.targets = [&quot;KRW-BTC&quot;, &quot;KRW-ETH&quot;, &quot;KRW-ADA&quot;, &quot;KRW-XRP&quot;, &quot;KRW-SOL&quot;]&#10;        self.history_store = ExecHistoryStore()&#10;        self._stop_event = threading.Event()&#10;        self._thread: Optional[threading.Thread] = None&#10;        self._ws: Optional[websocket.WebSocketApp] = None&#10;        self._candle_state: Dict[str, Dict[str, Any]] = {}&#10;        self._candle_history_limit = int(os.getenv('WS_CANDLE_HISTORY_LIMIT', '240'))&#10;        self._last_acc_volume: Dict[str, float] = {}&#10;        self._entry_prices: Dict[str, float] = {}&#10;        self._timeframes = self._resolve_timeframes()&#10;        self._tf_state: Dict[str, Dict[str, Dict[str, Any]]] = {}&#10;        self._stats_history_limit = int(os.getenv('WS_STATS_HISTORY_LIMIT', '4000'))&#10;        self._stats_lock = threading.Lock()&#10;        stats = self._load_stats()&#10;        self._stats_totals = {&#10;            'success': stats.get('total_success', 0),&#10;            'failure': stats.get('total_failure', 0),&#10;        }&#10;        history_entries = stats.get('history', [])&#10;        self._stats_history: deque[Dict[str, Any]] = deque(history_entries[-self._stats_history_limit :], maxlen=self._stats_history_limit)&#10;&#10;    def _load_stats(self) -&gt; Dict[str, Any]:&#10;        if not WS_STATS_FILE.exists():&#10;            return {'total_success': 0, 'total_failure': 0, 'history': []}&#10;        try:&#10;            with WS_STATS_FILE.open('r', encoding='utf-8') as fp:&#10;                return json.load(fp)&#10;        except Exception:&#10;            return {'total_success': 0, 'total_failure': 0, 'history': []}&#10;&#10;    def _save_stats(self) -&gt; None:&#10;        try:&#10;            temp = WS_STATS_FILE.with_suffix('.tmp')&#10;            with temp.open('w', encoding='utf-8') as fp:&#10;                json.dump({&#10;                    'total_success': self._stats_totals['success'],&#10;                    'total_failure': self._stats_totals['failure'],&#10;                    'history': list(self._stats_history),&#10;                }, fp)&#10;            temp.replace(WS_STATS_FILE)&#10;        except Exception as exc:&#10;            log.warning(f'Failed to save websocket stats: {exc}')&#10;&#10;    def _register_reception(self, success: bool, payload: Dict[str, Any]) -&gt; None:&#10;        with self._stats_lock:&#10;            key = 'ticker' if payload.get('type') == 'ticker' else 'order'&#10;            ts = payload.get('trade_timestamp') or payload.get('timestamp') or int(time.time() * 1000)&#10;            entry = {&#10;                'ts': ts,&#10;                'type': payload.get('type'),&#10;                'symbol': payload.get('code') or payload.get('symbol'),&#10;                'success': success,&#10;            }&#10;            if success:&#10;                self._stats_totals['success'] += 1&#10;            else:&#10;                self._stats_totals['failure'] += 1&#10;            self._stats_history.append(entry)&#10;            self._save_stats()&#10;&#10;    def _payload_for_subscription(self) -&gt; str:&#10;        message = [&#10;            {&quot;ticket&quot;: self._jwt_token},&#10;            {&quot;type&quot;: &quot;MyOrder&quot;, &quot;codes&quot;: [&quot;KRW-&quot; + t.split('-')[-1] if not t.startswith('KRW-') else t for t in self.targets]},&#10;        ]&#10;        return json.dumps(message)&#10;&#10;    def _push_candle(self, ticker: str, timeframe: str, candle: Dict[str, Any]) -&gt; None:&#10;        if self.redis_client is None:&#10;            return&#10;        try:&#10;            key = f&quot;ws:candles:{timeframe}:{ticker}&quot;&#10;            candle = candle.copy()&#10;            ts = candle.get(&quot;timestamp&quot;)&#10;            if ts:&#10;                try:&#10;                    qualifier = datetime.fromtimestamp(ts / 1000.0, KST)&#10;                    candle[&quot;candle_date_time_kst&quot;] = qualifier.strftime(&quot;%Y-%m-%dT%H:%M:%S%z&quot;)&#10;                except Exception:&#10;                    pass&#10;            candle.setdefault(&quot;candle_acc_trade_volume&quot;, candle.get(&quot;volume&quot;, 0.0))&#10;            self.redis_client.lpush(key, json.dumps(candle))&#10;            self.redis_client.ltrim(key, 0, self._candle_history_limit - 1)&#10;        except Exception as exc:&#10;            log.warning(f&quot;Redis candle push failed: {exc}&quot;)&#10;&#10;    def _read_cached_candles(self, ticker: str, timeframe: str = 'minute1', limit: int = 200) -&gt; List[Dict[str, Any]]:&#10;        if self.redis_client is None:&#10;            return []&#10;        key = f&quot;ws:candles:{timeframe}:{ticker}&quot;&#10;        try:&#10;            raw = self.redis_client.lrange(key, 0, limit - 1)&#10;        except Exception:&#10;            return []&#10;        result = []&#10;        for raw_item in reversed(raw):&#10;            try:&#10;                payload = json.loads(raw_item)&#10;                result.append(payload)&#10;            except Exception:&#10;                continue&#10;        return result&#10;&#10;    def _aggregate_candle(self, payload: Dict[str, Any]) -&gt; None:&#10;        ticker = payload.get(&quot;code&quot;) or payload.get(&quot;symbol&quot;)&#10;        if not ticker:&#10;            return&#10;        ts = payload.get(&quot;trade_timestamp&quot;) or payload.get(&quot;timestamp&quot;) or int(time.time() * 1000)&#10;        try:&#10;            ts_val = float(ts)&#10;        except Exception:&#10;            ts_val = float(time.time() * 1000)&#10;        minute_ts = int(ts_val // 60000 * 60000)&#10;        price = float(payload.get(&quot;trade_price&quot;) or payload.get(&quot;price&quot;) or 0.0)&#10;        if price &lt;= 0:&#10;            return&#10;        state = self._candle_state.get(ticker)&#10;        if not state or state.get(&quot;minute&quot;) != minute_ts:&#10;            if state:&#10;                self._push_candle(ticker, 'minute1', {&#10;                    &quot;ticker&quot;: ticker,&#10;                    &quot;timestamp&quot;: state[&quot;minute&quot;],&#10;                    &quot;open&quot;: state[&quot;open&quot;],&#10;                    &quot;high&quot;: state[&quot;high&quot;],&#10;                    &quot;low&quot;: state[&quot;low&quot;],&#10;                    &quot;close&quot;: state[&quot;close&quot;],&#10;                    &quot;volume&quot;: state[&quot;volume&quot;],&#10;                })&#10;                self._emit_to_timeframes(ticker, state[&quot;minute&quot;], state)&#10;            self._candle_state[ticker] = {&#10;                &quot;minute&quot;: minute_ts,&#10;                &quot;open&quot;: price,&#10;                &quot;high&quot;: price,&#10;                &quot;low&quot;: price,&#10;                &quot;close&quot;: price,&#10;                &quot;volume&quot;: 0.0,&#10;            }&#10;            self._last_acc_volume[ticker] = float(payload.get(&quot;acc_trade_volume&quot;, 0) or 0)&#10;            return&#10;        if price &gt; state[&quot;high&quot;]:&#10;            state[&quot;high&quot;] = price&#10;        if price &lt; state[&quot;low&quot;]:&#10;            state[&quot;low&quot;] = price&#10;        state[&quot;close&quot;] = price&#10;        acc_vol = float(payload.get(&quot;acc_trade_volume&quot;, 0) or 0)&#10;        prev_acc = self._last_acc_volume.get(ticker, 0.0)&#10;        if acc_vol &gt;= prev_acc:&#10;            state[&quot;volume&quot;] += acc_vol - prev_acc&#10;        else:&#10;            state[&quot;volume&quot;] += acc_vol&#10;        self._last_acc_volume[ticker] = acc_vol&#10;&#10;    def _store_to_redis(self, payload: Dict[str, Any]) -&gt; None:&#10;        if self.redis_client is None:&#10;            return&#10;        try:&#10;            code = payload.get(&quot;code&quot;) or payload.get(&quot;symbol&quot;)&#10;            if not code:&#10;                return&#10;            key_base = f&quot;ws:{payload.get('type', 'unknown')}:{code}&quot;&#10;            self.redis_client.set(key_base, json.dumps(payload))&#10;            if payload.get(&quot;type&quot;) == &quot;trade&quot;:&#10;                list_key = f&quot;ws:trades:{code}&quot;&#10;                self.redis_client.lpush(list_key, json.dumps(payload))&#10;                self.redis_client.ltrim(list_key, 0, 200)&#10;            if payload.get(&quot;type&quot;) == &quot;ticker&quot;:&#10;                self._aggregate_candle(payload)&#10;        except Exception as exc:&#10;            log.warning(f&quot;Redis write failed for websocket payload: {exc}&quot;)&#10;&#10;    def _record_exec_history(self, payload: Dict[str, Any]) -&gt; None:&#10;        if payload.get(&quot;type&quot;) != &quot;order&quot;:&#10;            return&#10;        entry = {&#10;            &quot;ts&quot;: float(payload.get(&quot;timestamp&quot;, payload.get(&quot;trade_timestamp&quot;, time.time())) / 1000.0)&#10;            if payload.get(&quot;timestamp&quot;)&#10;            else time.time(),&#10;            &quot;symbol&quot;: payload.get(&quot;code&quot;) or payload.get(&quot;symbol&quot;),&#10;            &quot;price&quot;: payload.get(&quot;price&quot;) or payload.get(&quot;order_price&quot;) or 0,&#10;            &quot;size&quot;: payload.get(&quot;trade_volume&quot;, payload.get(&quot;volume&quot;) or 0),&#10;            &quot;side&quot;: payload.get(&quot;side&quot;) or payload.get(&quot;order_side&quot;) or payload.get(&quot;ask_bid&quot;),&#10;            &quot;order_id&quot;: payload.get(&quot;uuid&quot;) or payload.get(&quot;order_id&quot;),&#10;        }&#10;        side = (entry.get(&quot;side&quot;) or &quot;&quot;).lower()&#10;        symbol = entry.get(&quot;symbol&quot;)&#10;        avg_price = payload.get(&quot;avg_price&quot;) or payload.get(&quot;avg_buy_price&quot;) or payload.get(&quot;order_price&quot;) or payload.get(&quot;price&quot;)&#10;        try:&#10;            avg_price_val = float(avg_price) if avg_price is not None else 0.0&#10;        except Exception:&#10;            avg_price_val = 0.0&#10;&#10;        entry_price_value = 0.0&#10;        if side in (&quot;bid&quot;, &quot;buy&quot;, &quot;매수&quot;):&#10;            self._entry_prices[symbol] = avg_price_val or self._entry_prices.get(symbol, 0.0)&#10;        else:&#10;            entry_price_value = self._entry_prices.get(symbol, avg_price_val)&#10;        entry[&quot;entry_price&quot;] = entry_price_value or 0.0&#10;        if entry[&quot;symbol&quot;]:&#10;            self.history_store.record(entry)&#10;&#10;    def _on_message(self, _, message: str) -&gt; None:&#10;        try:&#10;            payloads = json.loads(message)&#10;            if isinstance(payloads, list):&#10;                for payload in payloads:&#10;                    self._handle_payload(payload)&#10;            elif isinstance(payloads, dict):&#10;                self._handle_payload(payloads)&#10;        except Exception as exc:&#10;            log.warning(f&quot;Failed to parse websocket message: {exc}&quot;)&#10;&#10;    def _handle_payload(self, payload: Dict[str, Any]) -&gt; None:&#10;        success = True&#10;        try:&#10;            self._store_to_redis(payload)&#10;            self._record_exec_history(payload)&#10;        except Exception as exc:&#10;            success = False&#10;            log.warning(f&quot;Websocket payload handling failed: {exc}&quot;)&#10;        finally:&#10;            self._register_reception(success, payload)&#10;&#10;    def _resolve_timeframes(self) -&gt; List[str]:&#10;        cfg_frames = get_setting('ws_timeframes')&#10;        frames: List[str] = []&#10;        if isinstance(cfg_frames, list):&#10;            for tf in cfg_frames:&#10;                if isinstance(tf, str) and tf.strip():&#10;                    frames.append(tf.strip())&#10;        primary = get_setting('timeframe') or 'minute5'&#10;        if primary not in frames:&#10;            frames.append(primary)&#10;        if 'minute1' not in frames:&#10;            frames.insert(0, 'minute1')&#10;        seen: List[str] = []&#10;        for tf in frames:&#10;            if tf not in seen:&#10;                seen.append(tf)&#10;        return seen&#10;&#10;    def _emit_to_timeframes(self, ticker: str, base_ts: float, candle: Dict[str, Any]) -&gt; None:&#10;        bucket_map = self._tf_state.setdefault(ticker, {})&#10;        for timeframe in self._timeframes:&#10;            if timeframe == 'minute1':&#10;                continue&#10;            duration = _timeframe_to_seconds(timeframe) * 1000&#10;            bucket_start = int(base_ts // duration) * duration&#10;            state = bucket_map.get(timeframe)&#10;            if not state or state.get('start') != bucket_start:&#10;                if state:&#10;                    self._push_candle(ticker, timeframe, state)&#10;                bucket_map[timeframe] = {&#10;                    'ticker': ticker,&#10;                    'timeframe': timeframe,&#10;                    'timestamp': bucket_start,&#10;                    'start': bucket_start,&#10;                    'open': candle.get('open'),&#10;                    'high': candle.get('high'),&#10;                    'low': candle.get('low'),&#10;                    'close': candle.get('close'),&#10;                    'volume': candle.get('volume', 0.0),&#10;                }&#10;            else:&#10;                state['high'] = max(state.get('high', 0.0), candle.get('high', 0.0))&#10;                state['low'] = min(state.get('low', state.get('high', 0.0)), candle.get('low', 0.0))&#10;                state['close'] = candle.get('close')&#10;                state['volume'] = state.get('volume', 0.0) + candle.get('volume', 0.0)&#10;&#10;    def _extract_message_payload(self, value: Any) -&gt; Optional[str]:&#10;        if value is None:&#10;            return None&#10;        if isinstance(value, dict):&#10;            return value.get('message') or value.get('errorMessage') or value.get('errorMsg')&#10;        if isinstance(value, str):&#10;            try:&#10;                parsed = json.loads(value)&#10;                if isinstance(parsed, dict):&#10;                    return parsed.get('message') or parsed.get('errorMessage') or parsed.get('errorMsg')&#10;            except json.JSONDecodeError:&#10;                return value&#10;        try:&#10;            return str(value)&#10;        except Exception:&#10;            return None&#10;&#10;    def _format_close_info(self, code: Any, msg: Any) -&gt; str:&#10;        parts: list[str] = []&#10;        if code is not None:&#10;            parts.append(f&quot;code={code}&quot;)&#10;        message = self._extract_message_payload(msg)&#10;        if message:&#10;            parts.append(f&quot;msg={message}&quot;)&#10;        elif msg is not None:&#10;            try:&#10;                decoded = msg.decode() if isinstance(msg, bytes) else str(msg)&#10;            except Exception:&#10;                decoded = str(msg)&#10;            parts.append(f&quot;msg={decoded}&quot;)&#10;        return &quot;, &quot;.join(parts) if parts else &quot;no details&quot;&#10;&#10;    def _on_error(self, _, error: Any) -&gt; None:&#10;        detail = self._extract_message_payload(error)&#10;        if detail:&#10;            logger.warning(f&quot;Websocket listener error: {detail}&quot;)&#10;        else:&#10;            logger.warning(f&quot;Websocket listener error: {error}&quot;)&#10;&#10;    def _on_close(self, _, close_status_code, close_msg) -&gt; None:&#10;        close_info = self._format_close_info(close_status_code, close_msg)&#10;        logger.info(f&quot;Websocket connection closed ({close_info})&quot;)&#10;&#10;    def _on_open(self, ws: websocket.WebSocketApp) -&gt; None:&#10;        self._ws = ws&#10;        try:&#10;            logger.info(f&quot;Sending subscription payload: {self._payload_for_subscription()}&quot;)&#10;            ws.send(self._payload_for_subscription())&#10;        except Exception as exc:&#10;            logger.warning(f&quot;Failed to send websocket subscription: {exc}&quot;)&#10;&#10;    def _run(self) -&gt; None:&#10;        while not self._stop_event.is_set():&#10;            if not self._jwt_token:&#10;                time.sleep(5)&#10;                continue&#10;            try:&#10;                headers = []&#10;                if self._jwt_token:&#10;                    headers.append(f&quot;Authorization: Bearer {self._jwt_token}&quot;)&#10;                ws_app = websocket.WebSocketApp(&#10;                    UPBIT_WS_URL,&#10;                    on_open=self._on_open,&#10;                    on_message=self._on_message,&#10;                    on_error=self._on_error,&#10;                    on_close=self._on_close,&#10;                    header=headers if headers else None,&#10;                 )&#10;                ws_app.run_forever(ping_interval=20, ping_timeout=10)&#10;            except Exception as exc:&#10;                logger.warning(f&quot;Websocket listener restart: {exc}&quot;)&#10;            time.sleep(2)&#10;&#10;    def start(self) -&gt; None:&#10;        if self._thread and self._thread.is_alive():&#10;            return&#10;        self._stop_event.clear()&#10;        self._thread = threading.Thread(target=self._run, daemon=True)&#10;        self._thread.start()&#10;        logger.info(&quot;Websocket listener started.&quot;)&#10;&#10;    def stop(self) -&gt; None:&#10;        self._stop_event.set()&#10;        if self._ws:&#10;            try:&#10;                self._ws.close()&#10;            except Exception:&#10;                pass&#10;        if self._thread:&#10;            self._thread.join(timeout=2)&#10;        logger.info(&quot;Websocket listener stopped.&quot;)&#10;&#10;&#10;def _get_universe_targets() -&gt; List[str]:&#10;    universe = get_setting('universe')&#10;    if isinstance(universe, list) and universe:&#10;        return universe&#10;    return [&quot;KRW-BTC&quot;, &quot;KRW-ETH&quot;, &quot;KRW-ADA&quot;, &quot;KRW-XRP&quot;, &quot;KRW-SOL&quot;]&#10;&#10;&#10;def _generate_ws_token() -&gt; Optional[str]:&#10;    access_key = config.UPBIT_ACCESS_KEY&#10;    secret_key = config.UPBIT_SECRET_KEY&#10;    if not access_key or not secret_key:&#10;        logger.warning('UPBIT_ACCESS_KEY/UPBIT_SECRET_KEY missing; MyOrder websocket authentication skipped.')&#10;        return None&#10;    payload = {'access_key': access_key, 'nonce': str(uuid.uuid4())}&#10;    try:&#10;        token = jwt.encode(payload, secret_key, algorithm='HS256')&#10;        return token.decode() if isinstance(token, bytes) else token&#10;    except Exception as exc:&#10;        logger.warning(f'Failed to create websocket JWT: {exc}')&#10;        return None&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>