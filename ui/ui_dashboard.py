import streamlit as st
try:
    from streamlit_autorefresh import st_autorefresh as _autorefresh_component
except ImportError:
    _autorefresh_component = None
import sys
# reload-test: touch ui file to verify backend reload behavior (do not remove)
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from pathlib import Path
from typing import Any, Dict, Tuple, Optional
from copy import deepcopy
import pandas as pd
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import time
import os
import json

project_root = Path(__file__).resolve().parents[1]
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))
try:
    from server.config import load_config, save_config as save_local
except Exception as err:
    raise RuntimeError(f'server.config.load_config import failed: {err}')


def validate_config(cfg: Dict[str, Any]) -> Tuple[bool, str]:
    """Basic validation for runtime config used by the UI form.
    Returns (True, '') if valid, otherwise (False, 'reason').
    """
    if not isinstance(cfg, dict):
        return False, 'ì„¤ì • ë°ì´í„°ê°€ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤.'
    if not cfg.get('market'):
        return False, 'Market ê°’ì´ í•„ìš”í•©ë‹ˆë‹¤.'
    if not isinstance(cfg.get('candle_count', 0), int) or cfg.get('candle_count', 0) <= 0:
        return False, 'Candle count ëŠ” 1 ì´ìƒì˜ ì •ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤.'
    order = cfg.get('order_settings', {})
    if not isinstance(order.get('trade_amount_krw', 0), (int, float)) or order.get('trade_amount_krw', 0) <= 0:
        return False, 'Trade amount_krw ëŠ” 0ë³´ë‹¤ í° ìˆ«ìì—¬ì•¼ í•©ë‹ˆë‹¤.'
    sell_ratio = order.get('sell_ratio', 0.3)
    if not isinstance(sell_ratio, (int, float)) or not (0.1 <= sell_ratio <= 1.0):
        return False, 'sell_ratioëŠ” 0.1~1.0 ë²”ìœ„ì˜ ìˆ«ìì—¬ì•¼ í•©ë‹ˆë‹¤.'
    kelly = cfg.get('kelly_criterion', {})
    if cfg.get('use_kelly_criterion'):
        wr = float(kelly.get('win_rate', 0))
        pr = float(kelly.get('payoff_ratio', 0))
        frac = float(kelly.get('fraction', 0))
        if not (0 <= wr <= 1):
            return False, 'Kelly win_rate ëŠ” 0~1 ë²”ìœ„ì—¬ì•¼ í•©ë‹ˆë‹¤.'
        if pr <= 0:
            return False, 'Kelly payoff_ratio ëŠ” ì–‘ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤.'
        if not (0 <= frac <= 1):
            return False, 'Kelly fraction ì€ 0~1 ë²”ìœ„ì—¬ì•¼ í•©ë‹ˆë‹¤.'
    return True, ''


def _refresh_config_cache() -> Dict[str, Any]:
    cfg_data = load_config()
    st.session_state['config_cache'] = cfg_data
    return cfg_data


def _get_active_config() -> Dict[str, Any]:
    if 'config_cache' not in st.session_state:
        return _refresh_config_cache()
    return st.session_state['config_cache']


RUNTIME_CONFIG = Path(__file__).resolve().parents[1] / 'runtime' / 'config.json'

st.set_page_config(page_title='Upbit Trader', layout='wide')

# Helper to render DataFrame safely across Streamlit versions and hide index when requested
def _safe_dataframe(df: 'pd.DataFrame', hide_index: bool = False, **kwargs):
    """Render a pandas DataFrame while attempting to hide the index and use full width.
    Tries the newer `width='stretch'` API first, then falls back to `use_container_width=True`,
    and finally to the basic st.dataframe if needed.
    """
    try:
        return st.dataframe(df, hide_index=hide_index, width='stretch', **kwargs)
    except TypeError:
        try:
            return st.dataframe(df, hide_index=hide_index, use_container_width=True, **kwargs)
        except TypeError:
            # Older Streamlit may not support hide_index; fallback to st.table (no hide)
            try:
                return st.table(df)
            except Exception:
                return st.write(df)


def _safe_plotly_chart(fig, **kwargs):
    """Render a plotly figure using newer width='stretch' API if available, otherwise fall back to use_container_width."""
    try:
        return st.plotly_chart(fig, width='stretch', **kwargs)
    except TypeError:
        try:
            return st.plotly_chart(fig, use_container_width=True, **kwargs)
        except Exception:
            return st.write('ì°¨íŠ¸ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')


# Callback for strategy selectbox to trigger immediate rerun so fields update
def _on_strategy_change():
    # mark change and request a rerun so Streamlit re-renders dynamic fields immediately
    st.session_state['_strategy_changed'] = True
    _trigger_rerun()


def _trigger_rerun() -> None:
    rerun = getattr(st, 'rerun', None) or getattr(st, 'experimental_rerun', None)
    if rerun:
        try:
            rerun()
        except Exception:
            pass


# API base URL for backend calls: read from env var STREAMLIT_API_BASE (set by docker-compose)
# If not set, fall back to localhost for local development.
API_BASE = os.getenv('STREAMLIT_API_BASE', 'http://127.0.0.1:8000')
AUTO_REFRESH_KEY = 'ws_auto_refresh_enabled'


# Create a requests session with retry/backoff to make UI-server comms more resilient
def _build_session():
    session = requests.Session()
    retries = Retry(
        total=3,
        backoff_factor=0.6,
        status_forcelist=(429, 500, 502, 503, 504),
        allowed_methods=("GET", "POST"),
        raise_on_status=False,
    )
    adapter = HTTPAdapter(max_retries=retries)
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    return session

_API_SESSION = _build_session()

def api_request(method: str, path: str, params=None, json=None, timeout=10):
    """Call server API with retries and return requests.Response or raise Exception with friendly message."""
    if not API_BASE:
        raise RuntimeError("API Base URL is not set in the sidebar")
    url = API_BASE.rstrip("/") + "/" + path.lstrip("/")
    try:
        if method.lower() == "get":
            resp = _API_SESSION.get(url, params=params, timeout=timeout)
        else:
            resp = _API_SESSION.post(url, json=json, timeout=timeout)
        resp.raise_for_status()
        return resp
    except requests.exceptions.RequestException as e:
        # Wrap low-level error to present user-friendly message in UI
        raise RuntimeError(f"ì„œë²„ í˜¸ì¶œ ì‹¤íŒ¨: {e}") from e


def fetch_ws_status():
    try:
        resp = api_request('get', '/ws/status', timeout=5)
        return resp.json(), None
    except Exception as exc:
        return None, exc


def fetch_ws_trades(symbol: str, limit: int = 20):
    try:
        resp = api_request('get', '/ws/trades', params={'symbol': symbol, 'limit': limit}, timeout=5)
        return resp.json(), None
    except Exception as exc:
        return None, exc


def _format_ws_ts(ts: Any) -> str:
    if ts is None:
        return '-'
    try:
        value = float(ts)
    except Exception:
        return '-'
    if value > 1e12:
        value /= 1000.0
    dt = pd.to_datetime(value, unit='s', utc=True)
    try:
        dt = dt.tz_convert('Asia/Seoul')
    except Exception:
        dt = dt.tz_localize('Asia/Seoul', ambiguous='NaT', nonexistent='shift_forward')
    return dt.strftime('%Y-%m-%d %H:%M:%S')


def fetch_ws_stats(last_hour_sec: int = 3600, recent_limit: int = 10):
    try:
        resp = api_request('get', '/ws/stats', params={'last_hour_sec': last_hour_sec, 'recent_limit': recent_limit}, timeout=5)
        return resp.json(), None
    except Exception as exc:
        return None, exc


def fetch_ws_executions(limit: int = 0):
    try:
        params = {'limit': limit} if limit else {}
        resp = api_request('get', '/ws/executions', params=params, timeout=10)
        return resp.json(), None
    except Exception as exc:
        return None, exc


def _format_ws_trade_timestamp(payload: Dict[str, Any]) -> str:
    ts = payload.get('trade_timestamp') or payload.get('timestamp')
    try:
        if ts is None:
            return '-'
        tsf = float(ts) / 1000.0 if ts > 1e12 else float(ts)
        dt = pd.to_datetime(tsf, unit='s', utc=True)
        try:
            dt = dt.tz_convert('Asia/Seoul')
        except Exception:
            dt = dt.tz_localize('Asia/Seoul', ambiguous='NaT', nonexistent='shift_forward')
        return dt.strftime('%H:%M:%S')
    except Exception:
        return '-'


def fetch_ws_ticker_data():
    try:
        resp = api_request('get', '/ws/ticker_data', timeout=5)
        return resp.json(), None
    except Exception as exc:
        return None, exc


def _render_autorefresh_button() -> bool:
    enabled = st.session_state.get(AUTO_REFRESH_KEY, False)
    status_label = 'ON' if enabled else 'OFF'
    icon = 'ğŸŸ¥' if enabled else 'âšª'
    label = f"{icon} 5ì´ˆ ìë™ ìƒˆë¡œê³ ì¹¨ ({status_label})"
    clicked = st.button(label, key='ws_autorefresh_toggle', help='í´ë¦­í•˜ë©´ ìë™ ìƒˆë¡œê³ ì¹¨ì„ ì¼œê±°ë‚˜ ë•ë‹ˆë‹¤.')
    if clicked:
        enabled = not enabled
        st.session_state[AUTO_REFRESH_KEY] = enabled
        _trigger_rerun()
    return enabled


def _apply_autorefresh_if_enabled():
    enabled = st.session_state.get(AUTO_REFRESH_KEY, False)
    if not enabled:
        return
    if _autorefresh_component is None:
        st.caption('streamlit-autorefresh ëª¨ë“ˆì´ ì—†ì–´ ìë™ ê°±ì‹ ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
        return
    _autorefresh_component(interval=5000, key='ws_ticker_autorefresh')


# --- Upbit public klines helper (cached) ---
@st.cache_data(ttl=10)
def fetch_klines_cached(market: str, timeframe: str = 'minute1', count: int = 200) -> pd.DataFrame | None:
    """
    UI-side fetch function disabled.
    The UI must not call Upbit public API directly â€” always go through the backend `/klines_batch` endpoint.
    This function returns None to force the UI to rely on backend data and avoid causing 429 Too Many Requests.
    """
    # Return None immediately to prevent direct Upbit calls from the UI.
    st.warning('UIëŠ” ì§ì ‘ Upbit í˜¸ì¶œì„ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë°±ì—”ë“œì˜ prefetchê°€ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°í•˜ì„¸ìš”.')
    return None


def fetch_klines_batch_from_backend(tickers: list[str], timeframe: str = 'minute15', count: int = 100) -> Dict[str, pd.DataFrame | None]:
    """Call server /klines_batch to get klines for multiple tickers. Returns mapping ticker->DataFrame or None.
    Falls back to empty dict on error.
    """
    url = f"{API_BASE.rstrip('/')}/klines_batch"
    try:
        resp = requests.post(url, json={'tickers': tickers, 'timeframe': timeframe, 'count': count}, timeout=15)
        resp.raise_for_status()
        data = resp.json().get('klines', {})
        result = {}
        for t, v in data.items():
            if not v:
                result[t] = None
                continue
            df = pd.DataFrame(v)
            df = df.rename(columns={
                'candle_date_time_kst': 'time',
                'opening_price': 'open',
                'high_price': 'high',
                'low_price': 'low',
                'trade_price': 'close',
                'candle_acc_trade_volume': 'volume'
            })
            cols = [c for c in ['time','open','high','low','close','volume'] if c in df.columns]
            df = df[cols]
            if 'time' in df.columns:
                df['time'] = pd.to_datetime(df['time'], utc=True)
                try:
                    df['time'] = df['time'].dt.tz_convert('Asia/Seoul')
                except Exception:
                    df['time'] = df['time'].dt.tz_localize('Asia/Seoul', ambiguous='NaT', nonexistent='shift_forward')
            for col in ['open','high','low','close','volume']:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
            df = df.sort_values('time', ascending=True).reset_index(drop=True)
            result[t] = df
        return result
    except Exception as e:
        st.warning(f'ë°±ì—”ë“œ batch klines í˜¸ì¶œ ì‹¤íŒ¨: {e}')
        return {}


def compute_volatility_from_df(df: pd.DataFrame | None) -> float | None:
    """Compute volatility as (max_high - min_low) / mean_close * 100.
    Returns percent float or None if cannot compute.
    """
    if df is None:
        return None
    try:
        if not hasattr(df, 'empty') or df.empty:
            return None
        if 'high' not in df.columns or 'low' not in df.columns or 'close' not in df.columns:
            return None
        max_high = float(df['high'].max())
        min_low = float(df['low'].min())
        mean_close = float(df['close'].mean()) if float(df['close'].mean() or 0) != 0 else None
        if mean_close is None or mean_close == 0:
            return None
        vol = (max_high - min_low) / mean_close * 100.0
        return float(vol)
    except Exception:
        return None


def _normalize_klines_df(df: pd.DataFrame | None, min_length: int = 30) -> pd.DataFrame | None:
    """Validate and normalize a kline DataFrame for plotting.
    - Ensures time column exists and is datetime
    - Renames common Upbit keys if needed
    - Sorts ascending by time, drops duplicate timestamps
    - Converts numeric columns and fills small gaps
    - Returns None if data is invalid
    """
    if df is None:
        return None
    # Accept list-of-dicts as well
    if not isinstance(df, pd.DataFrame):
        try:
            df = pd.DataFrame(df)
        except Exception:
            return None

    # Map common Upbit field names to expected ones
    rename_map = {
        'candle_date_time_kst': 'time',
        'opening_price': 'open',
        'high_price': 'high',
        'low_price': 'low',
        'trade_price': 'close',
        'candle_acc_trade_volume': 'volume'
    }
    df = df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns})

    # required columns
    required = ['time', 'open', 'high', 'low', 'close', 'volume']
    if 'time' not in df.columns:
        return None

    # time -> datetime with Asia/Seoul timezone
    try:
        df['time'] = pd.to_datetime(df['time'], utc=True)
        try:
            df['time'] = df['time'].dt.tz_convert('Asia/Seoul')
        except Exception:
            df['time'] = df['time'].dt.tz_localize('Asia/Seoul', ambiguous='NaT', nonexistent='shift_forward')
    except Exception:
        try:
            df['time'] = pd.to_datetime(df['time'].astype(str), utc=True)
            try:
                df['time'] = df['time'].dt.tz_convert('Asia/Seoul')
            except Exception:
                df['time'] = df['time'].dt.tz_localize('Asia/Seoul', ambiguous='NaT', nonexistent='shift_forward')
        except Exception:
            return None

    # sort ascending and dedupe
    df = df.sort_values('time', ascending=True).reset_index(drop=True)
    if df['time'].duplicated().any():
        df = df[~df['time'].duplicated(keep='last')].reset_index(drop=True)

    # ensure numeric
    for col in ['open', 'high', 'low', 'close', 'volume']:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        else:
            df[col] = pd.NA

    # fill small gaps for price columns
    try:
        df[['open', 'high', 'low', 'close']] = df[['open', 'high', 'low', 'close']].ffill().bfill()
        df['volume'] = df['volume'].fillna(0)
    except Exception:
        pass

    if len(df) < min_length:
        st.warning(f'ì°¨íŠ¸ì— í•„ìš”í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤: {len(df)}ê°œ (ìµœì†Œ {min_length} í•„ìš”)')
        return df
    return df


# --- Indicator helpers and plotting ---
def compute_rsi(series: pd.Series, period: int = 14) -> pd.Series:
    # Standard Wilder's RSI calculation without forcing initial values to 0.
    delta = series.diff()
    up = delta.clip(lower=0)
    down = -1 * delta.clip(upper=0)
    ma_up = up.rolling(period, min_periods=period).mean()
    ma_down = down.rolling(period, min_periods=period).mean()
    rs = ma_up / ma_down
    rsi = 100 - (100 / (1 + rs))
    return rsi


def plot_candles_with_indicators(df: pd.DataFrame, ticker: str, ma_windows: list[int], rsi_period: int):
    # Create subplot: row1 = candlestick+MA, row2 = volume bars, row3 = RSI
    fig = make_subplots(rows=3, cols=1, shared_xaxes=True, row_heights=[0.6, 0.2, 0.2], vertical_spacing=0.03)

    # Row 1: Candlestick â€” set colors: rising(red), falling(blue)
    fig.add_trace(go.Candlestick(x=df['time'], open=df['open'], high=df['high'], low=df['low'], close=df['close'], name='OHLC', increasing=dict(line=dict(color='red'), fillcolor='red'), decreasing=dict(line=dict(color='blue'), fillcolor='blue')), row=1, col=1)

    # moving averages on top
    for w in ma_windows:
        ma = df['close'].rolling(w).mean()
        fig.add_trace(go.Scatter(x=df['time'], y=ma, mode='lines', name=f'MA{w}', line=dict(width=1.2)), row=1, col=1)

    # Row 2: Volume bars
    # color volume bars green when close >= open else red
    try:
        # rising -> red, falling -> blue
        colors = ['red' if c >= o else 'blue' for o, c in zip(df['open'], df['close'])]
    except Exception:
        colors = 'gray'
    if 'volume' not in df.columns:
        df['volume'] = 0
    fig.add_trace(go.Bar(x=df['time'], y=df['volume'], name='Volume', marker=dict(color=colors), hovertemplate='Volume: %{y:,.0f}<extra></extra>'), row=2, col=1)
    # Keep volume axis independent
    fig.update_yaxes(title_text='Volume', row=2, col=1)

    # Row 3: RSI
    rsi = compute_rsi(df['close'], period=rsi_period)
    fig.add_trace(go.Scatter(x=df['time'], y=rsi, mode='lines', name=f'RSI({rsi_period})', line=dict(color='purple', width=2.0), connectgaps=False, hovertemplate='RSI: %{y:.2f}<extra></extra>'), row=3, col=1)
    # RSI bands (draw as shapes for visibility)
    fig.add_hline(y=70, line=dict(color='red', dash='dash'), row=3, col=1)
    fig.add_hline(y=30, line=dict(color='green', dash='dash'), row=3, col=1)
    fig.update_yaxes(range=[0,100], row=3, col=1)

    # layout tweaks
    fig.update_layout(height=520, margin=dict(l=10, r=10, t=30, b=20), showlegend=True, hovermode='x unified')
    fig.update_xaxes(rangebreaks=[dict(bounds=["sat","mon"])], rangeslider_visible=False)
    return fig


# Load existing config
cfg = _get_active_config()

# --- Page renderers ---

def render_config_page(cfg_data: Dict[str, Any]):
    st.title('ì„¤ì • í¸ì§‘')

    cfg_snapshot = deepcopy(cfg_data) if isinstance(cfg_data, dict) else {}
    # Strategy selector placed outside the form so changes immediately re-render detail fields.
    _strategy_opts = ['VolatilityBreakout', 'DualMomentum', 'RSI']
    _default = cfg_snapshot.get('strategy_name', 'VolatilityBreakout')
    try:
        _default_idx = _strategy_opts.index(_default) if _default in _strategy_opts else 0
    except Exception:
        _default_idx = 0
    # initialize session state key if missing so we can read it inside the form
    if 'cfg_strategy' not in st.session_state:
        st.session_state['cfg_strategy'] = _strategy_opts[_default_idx]
    strategy_name = st.selectbox('ì „ëµ (ì–´ë–¤ ë°©ì‹ì„ ì“¸ê¹Œìš”?)', options=_strategy_opts, index=_default_idx, key='cfg_strategy', help='ì–´ë–¤ ê±°ë˜ ì „ëµì„ ì“¸ì§€ ê³¨ë¼ìš”. ì˜ˆ: ë³€ë™ì„± ëŒíŒŒ, ëª¨ë©˜í…€, RSI')

    # Now the form (other widgets and save buttons). Inside the form read the currently selected strategy
    with st.form('config_form', clear_on_submit=False):
        # use the session_state value so fields update immediately when the selectbox changes
        strategy_name = st.session_state.get('cfg_strategy', _strategy_opts[_default_idx])

        # --- ì „ëµë³„ ìƒì„¸ ì„¤ì •: ì „ëµ ì„ íƒ ë°”ë¡œ ì•„ë˜ì— ìœ„ì¹˜í•˜ë„ë¡ í•¨ ---
        st.caption('ì„ íƒí•œ ì „ëµì— ë”°ë¼ ì—¬ê¸°ì„œ ì„¸ë¶€ ì˜µì…˜ì„ ì •í•´ìš”.')
        strategy_params = cfg_snapshot.get('strategy_params', {}) if isinstance(cfg_snapshot, dict) else {}
        if strategy_name == 'RSI':
            rsi = strategy_params.get('RSI', {})
            rsi_period = st.number_input('RSI ê¸°ê°„ (ëª‡ê°œ ìº”ë“¤ë¡œ ê³„ì‚°í• ì§€)', min_value=1, value=int(rsi.get('period', 14)), help='RSIë¥¼ ê³„ì‚°í•  ë•Œ ëª‡ ê°œì˜ ìº”ë“¤ì„ ë³¼ì§€ ì •í•´ìš”. ë³´í†µ 14')
            rsi_oversold = st.number_input('ê³¼ë§¤ë„ ê¸°ì¤€ (0~100)', min_value=0, max_value=100, value=int(rsi.get('oversold', 30)), help='ì´ ê°’ ì•„ë˜ë©´ ë„ˆë¬´ ì‹¸ê²Œ íŒ”ë ¤ì„œ ì‚¬ë„ ë˜ëŠ” ìƒíƒœì˜ˆìš”.')
            rsi_overbought = st.number_input('ê³¼ë§¤ìˆ˜ ê¸°ì¤€ (0~100)', min_value=0, max_value=100, value=int(rsi.get('overbought', 70)), help='ì´ ê°’ ìœ„ë©´ ë„ˆë¬´ ë¹„ì‹¸ê²Œ ì‚¬ì ¸ì„œ íŒ”ì•„ì•¼ í•  ìˆ˜ë„ ìˆì–´ìš”.')
        elif strategy_name == 'VolatilityBreakout':
            vb = strategy_params.get('VolatilityBreakout', {})
            k_value = st.number_input('ë³€ë™ì„± ë¹„ìœ¨ k (0~1)', min_value=0.0, max_value=1.0, value=float(vb.get('k_value', 0.5)), help='ì§€ë‚œ ê¸°ê°„ì˜ ë³€ë™ì„±ì—ì„œ ëª‡ í¼ì„¼íŠ¸ë§Œí¼ ëŒíŒŒë¥¼ ë³´ë©´ ì§„ì…í• ì§€ ì •í•˜ëŠ” ìˆ˜ì¹˜ì˜ˆìš”. 0.5ê°€ ë³´í†µ ì‚¬ìš©ë©ë‹ˆë‹¤.')
            target_vol_pct_default = vb.get('target_vol_pct', cfg_snapshot.get('vb_target_vol_pct', 30.0))
            target_vol_pct = st.number_input('ëª©í‘œ ë³€ë™ì„± ë¹„ìœ¨ (%)', min_value=1.0, max_value=100.0, value=float(target_vol_pct_default), help='ì‹œì¥ ë³€ë™ì„±ì´ ì´ ê°’ ì´ìƒì¸ì§€ ë³´ê³  ë§¤ë§¤ ì—¬ë¶€ë¥¼ íŒë‹¨í•´ìš”.')
        elif strategy_name == 'DualMomentum':
            dm = strategy_params.get('DualMomentum', {})
            window = st.number_input('ëª¨ë©˜í…€ ê³„ì‚° ì°½ ê¸¸ì´', min_value=1, value=int(dm.get('window', 12)), help='ëª¨ë©˜í…€ì„ ê³„ì‚°í•  ë•Œ ëª‡ ê¸°ê°„ì„ ë³¼ì§€ ì •í•´ìš”. ìˆ«ìê°€ í¬ë©´ ë” ê¸´ íë¦„ì„ ë´ìš”.')

        # ê¸°ë³¸ ì •ë³´(ì „ëµ ìƒì„¸ ë°”ë¡œ ì•„ë˜ì— ìœ„ì¹˜)
        market = st.text_input('ê±°ë˜í•  ë§ˆì¼“ (ì˜ˆ: KRW-BTC)', value=cfg_snapshot.get('market', 'KRW-BTC'), help='ì–´ë–¤ ì½”ì¸ì„ ê±°ë˜í• ì§€ ì ì–´ìš”. ì˜ˆ: KRW-BTCëŠ” ë¹„íŠ¸ì½”ì¸ì…ë‹ˆë‹¤.')
        timeframe = st.text_input('ìº”ë“¤ ì‹œê°„ ë‹¨ìœ„ (ì˜ˆ: minute5)', value=cfg_snapshot.get('timeframe', 'minute5'), help='í•œ ê°œì˜ ìº”ë“¤ì´ ëª‡ ë¶„/ì‹œê°„ì¸ì§€ ì ì–´ìš”. ì˜ˆ: minute5 = 5ë¶„')
        candle_count = st.number_input('ìº”ë“¤ ê°œìˆ˜(ê·¸ë˜í”„ í‘œì‹œ ê¸¸ì´)', min_value=1, value=int(cfg_snapshot.get('candle_count', 200)), help='ì°¨íŠ¸ì— ë³´ì—¬ì¤„ ê³¼ê±° ë°ì´í„°ì˜ ê°œìˆ˜ì˜ˆìš”. ìˆ«ìê°€ í¬ë©´ ê¸´ ê¸°ê°„ì„ ë³´ì—¬ì¤˜ìš”.')
        loop_interval_sec = st.number_input('ë£¨í”„ ì‹¤í–‰ ê°„ê²©(ì´ˆ)', min_value=1, value=int(cfg_snapshot.get('loop_interval_sec', 5)), help='ìë™ìœ¼ë¡œ í™•ì¸í•  ë•Œ ëª‡ ì´ˆë§ˆë‹¤ í• ì§€ ì •í•´ìš”.')

        st.subheader('ì£¼ë¬¸ ê´€ë ¨ ì„¤ì • (ëˆ/ìˆ˜ëŸ‰)')
        order_settings = cfg_snapshot.get('order_settings', {})
        min_order_amount = st.number_input('ìµœì†Œ ì£¼ë¬¸ ê¸ˆì•¡ (ì›)', min_value=1000, value=int(order_settings.get('min_order_amount', 5500)), help='ê±°ë˜ì†Œì—ì„œ í—ˆìš©í•˜ëŠ” ìµœì†Œ ì£¼ë¬¸ ê¸ˆì•¡ì´ì—ìš”. ì´ ê°’ë³´ë‹¤ ì‘ìœ¼ë©´ ì£¼ë¬¸ ëª»í•´ìš”.')
        trade_amount_krw = st.number_input('í•œ ë²ˆ ê±°ë˜í•  ê¸ˆì•¡ (ì›)', min_value=1000, value=int(order_settings.get('trade_amount_krw', 6000)), help='í•œ ë²ˆ ë§¤ìˆ˜í•  ë•Œ ì“°ëŠ” ëˆì´ì—ìš”. ì˜ˆ: 6000ì›')
        sell_ratio = st.slider('ë§¤ë„ ë¹„ìœ¨ (0.1~1.0)', min_value=0.1, max_value=1.0, value=float(order_settings.get('sell_ratio', 0.3)), step=0.1, help='ë§¤ë„ ì‹ í˜¸ê°€ ë‚˜ì™”ì„ ë•Œ ì „ì²´ ì”ê³  ì¤‘ ëª‡ %ë¥¼ ë§¤ë„í• ì§€ ì •í•´ìš”. 0.3=30%, 1.0=ì „ëŸ‰ ë§¤ë„')

        st.subheader('ì¼ˆë¦¬ê³µì‹ (ëˆì„ ì–¼ë§ˆë‚˜ ì“¸ì§€ ê³„ì‚°í•˜ëŠ” ë°©ë²•)')
        use_kelly = st.checkbox('ì¼ˆë¦¬ê³µì‹ ì‚¬ìš©í•˜ê¸°', value=bool(cfg_snapshot.get('use_kelly_criterion', True)), help='ì¼ˆë¦¬ê³µì‹ì„ ì‚¬ìš©í•˜ë©´ ì´ê¸¸ í™•ë¥ ê³¼ ìˆ˜ìµë¹„ìœ¨ë¡œ í•œ ë²ˆì— íˆ¬ìí•  ëˆì„ ê³„ì‚°í•´ì¤˜ìš”.')
        kelly = cfg_snapshot.get('kelly_criterion', {})
        win_rate = st.number_input('ìŠ¹ë¥  (0~1)', min_value=0.0, max_value=1.0, value=float(kelly.get('win_rate', 0.65)), help='ê±°ë˜í–ˆì„ ë•Œ ì´ê¸¸ í™•ë¥ ì„ 0ë¶€í„° 1 ì‚¬ì´ë¡œ ì ì–´ìš”. ì˜ˆ: 0.65 = 65%')
        payoff_ratio = st.number_input('í‰ê·  ì´ìµ/ì†ì‹¤ ë¹„ìœ¨', min_value=0.0, value=float(kelly.get('payoff_ratio', 1.2)), help='ì´ê¸¸ ë•Œ í‰ê·  ì´ìµì´ ì†ì‹¤ë³´ë‹¤ ëª‡ ë°°ì¸ì§€ ì ì–´ìš”. ì˜ˆ: 1.2ë©´ ì´ìµì´ ì†ì‹¤ì˜ 1.2ë°°')
        fraction = st.number_input('ì ìš© ë¹„ìœ¨ (0~1)', min_value=0.0, max_value=1.0, value=float(kelly.get('fraction', 0.5)), help='ì¼ˆë¦¬ë¡œ ê³„ì‚°í•œ ê¸ˆì•¡ ì¤‘ ì–¼ë§ˆë§Œ ì‹¤ì œë¡œ ì“¸ì§€ 0~1ë¡œ ì ì–´ìš”. ì˜ˆ: 0.5ëŠ” ë°˜ë§Œ ì‚¬ìš©')

        form_submitted = st.form_submit_button('ë¯¸ë¦¬ë³´ê¸° ì—…ë°ì´íŠ¸', type='primary', help='ì„¤ì •ì„ ë°”ê¾¼ ë’¤ ì—”í„°(ë˜ëŠ” ì´ ë²„íŠ¼)ë¥¼ ëˆ„ë¥´ë©´ ìµœì‹  ê°’ì´ ë°˜ì˜ë¼ìš”.')

        # --- Prefetch & Cache settings ---
        st.subheader('ë¯¸ë¦¬ë°›ê¸°(ìºì‹œ) ì„¤ì • â€” ì„œë²„ê°€ ë°ì´í„°ë¥¼ ë¯¸ë¦¬ ëª¨ì•„ë†“ëŠ” ë°©ë²•')
        prefetch_cfg = cfg_snapshot.get('prefetch', {}) if isinstance(cfg_snapshot.get('prefetch'), dict) else {}
        # Top-level prefetch keys (stored at root level, not inside 'prefetch' for backward compatibility)
        prefetch_count = st.number_input('ë¯¸ë¦¬ ë°›ì„ ìº”ë“¤ ìˆ˜ (ì¢…ëª©ë‹¹)', min_value=1, value=int(cfg_snapshot.get('prefetch_count', cfg_snapshot.get('candle_count', 200))), help='ì„œë²„ê°€ ê° ì¢…ëª©ì—ì„œ ë¯¸ë¦¬ ë°›ì•„ë‘˜ ìº”ë“¤ ìˆ˜ì˜ˆìš”. ê·¸ë˜í”„ ê¸¸ì´ì— ì˜í–¥ì„ ì¤ë‹ˆë‹¤.')
        prefetch_interval_sec = st.number_input('ë¯¸ë¦¬ìˆ˜ì§‘ ë°˜ë³µ ê°„ê²©(ì´ˆ)', min_value=1, value=int(cfg_snapshot.get('prefetch_interval_sec', 30)), help='ì„œë²„ê°€ ë¯¸ë¦¬ ë°ì´í„°ë¥¼ ëª¨ìœ¼ëŠ” ê°„ê²©ì´ì—ìš”. ìˆ«ìê°€ ì‘ìœ¼ë©´ ë” ìì£¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.')
        prefetch_batch_size = st.number_input('í•œë²ˆì— ëª¨ì„ ì¢…ëª© ìˆ˜', min_value=1, value=int(cfg_snapshot.get('prefetch_batch_size', 5)), help='í•œ ë²ˆì— ëª‡ ì¢…ëª©ì”© ëª¨ì„ì§€ ì •í•´ìš”. ë„ˆë¬´ í¬ë©´ í˜¸ì¶œì´ ëª°ë ¤ì„œ ì‹¤íŒ¨í•  ìˆ˜ ìˆì–´ìš”.')
        prefetch_parallelism = st.number_input('ë™ì‹œ ì‘ì—… ìˆ˜(ìŠ¤ë ˆë“œ)', min_value=1, value=int(cfg_snapshot.get('prefetch_parallelism', 3)), help='ëª‡ ê°œì˜ ì‘ì—…ì„ ë™ì‹œì— ì‹¤í–‰í• ì§€ ì •í•´ìš”. ìˆ«ìê°€ í¬ë©´ ë¹¨ë¼ì§€ì§€ë§Œ ì»´í“¨í„°ì— ë¶€ë‹´ì´ ë“¤ì–´ìš”.')
        prefetch_sleep_sec = st.number_input('ì¢…ëª© ì‚¬ì´ ì‰¬ëŠ” ì‹œê°„(ì´ˆ)', min_value=0.0, value=float(cfg_snapshot.get('prefetch_sleep_sec', 0.2)), help='í•œ ì¢…ëª©ì„ ì²˜ë¦¬í•œ ë’¤ ì ê¹ ì‰¬ëŠ” ì‹œê°„ì´ì—ìš”. ì„œë²„ ê³¼ë¶€í•˜ë¥¼ ì¤„ì—¬ìš”.')
        prefetch_min_interval_sec = st.number_input('Redis ì—†ì„ ë•Œ ìµœì†Œ ê°„ê²©(ì´ˆ)', min_value=1, value=int(cfg_snapshot.get('prefetch_min_interval_sec', 60)), help='Redisê°€ ì—†ìœ¼ë©´ ë¯¸ë¦¬ë°›ê¸° ì‚¬ì´ ê°„ê²©ì„ ë” ê¸¸ê²Œ í•´ìš”.')
        prefetch_no_redis_max_count = st.number_input('Redis ì—†ì„ ë•Œ ìµœëŒ€ ìº”ë“¤ ìˆ˜', min_value=1, value=int(cfg_snapshot.get('prefetch_no_redis_max_count', 120)), help='Redisê°€ ì—†ì„ ë•ŒëŠ” ë„ˆë¬´ ë§ì´ ê°€ì ¸ì˜¤ì§€ ì•Šë„ë¡ ì œí•œí•´ìš”.')
        prefetch_rate_per_sec = st.number_input('ì´ˆë‹¹ í—ˆìš© í˜¸ì¶œ(í† í°)', min_value=0.0, value=float(cfg_snapshot.get('prefetch_rate_per_sec', 5)), help='ì´ˆë‹¹ ëª‡ ë²ˆì˜ í˜¸ì¶œì„ í—ˆìš©í• ì§€ í† í°ìœ¼ë¡œ ì •í•´ìš”.')
        prefetch_rate_capacity = st.number_input('ë²„ìŠ¤íŠ¸ í—ˆìš© í† í°(ì¶”ê°€ ì—¬ìœ )', min_value=1, value=int(cfg_snapshot.get('prefetch_rate_capacity', int(prefetch_rate_per_sec or 1))), help='ì ê¹ ë™ì•ˆ ë” ë§ì€ í˜¸ì¶œì„ í—ˆìš©í•  ìˆ˜ ìˆëŠ” ì—¬ìœ ëŸ‰ì´ì—ìš”.')
        prefetch_max_concurrent = st.number_input('ìµœëŒ€ ë™ì‹œ ì‘ì—… ìˆ˜', min_value=1, value=int(cfg_snapshot.get('prefetch_max_concurrent', 3)), help='í•œ ë²ˆì— ë³‘ë ¬ë¡œ ìˆ˜í–‰í•  ìµœëŒ€ ì‘ì—… ìˆ˜ì˜ˆìš”.')
        prefetch_token_wait_timeout = st.number_input('í† í° ëŒ€ê¸° ìµœëŒ€ ì‹œê°„(ì´ˆ)', min_value=0.0, value=float(cfg_snapshot.get('prefetch_token_wait_timeout', 10.0)), help='í† í°ì„ ê¸°ë‹¤ë¦¬ëŠ” ìµœëŒ€ ì‹œê°„ì´ì—ìš”. ë„ˆë¬´ ì‘ìœ¼ë©´ ì‹¤íŒ¨í•  ìˆ˜ ìˆì–´ìš”.')
        # Cache TTL
        klines_cache_ttl = st.number_input('ì°¨íŠ¸ ë°ì´í„° ìºì‹œ ìœ ì§€ì‹œê°„(ì´ˆ)', min_value=1, value=int(cfg_snapshot.get('KLINES_CACHE_TTL', os.getenv('KLINES_CACHE_TTL', '600'))), help='ì„œë²„ê°€ ì €ì¥í•´ë‘ëŠ” ë°ì´í„°ê°€ ì–¼ë§ˆë‚˜ ì˜¤ë˜ ìœ ì§€ë ì§€ ì´ˆ ë‹¨ìœ„ë¡œ ì ì–´ìš”.')

        # AI ensemble settings
        st.subheader('AI ì¡°í•© ë°©ë²• (ì—¬ëŸ¬ AIë¥¼ ì–´ë–»ê²Œ í•©ì¹ ê¹Œ?)')
        ai_ensemble = cfg_snapshot.get('ai_ensemble', {}) if isinstance(cfg_snapshot.get('ai_ensemble', {}), dict) else {}
        ai_strategy_opts = ['UNANIMOUS', 'MAJORITY', 'AVERAGE']
        current_ai_strategy = ai_ensemble.get('strategy', 'UNANIMOUS')
        try:
            ai_strategy_idx = ai_strategy_opts.index(current_ai_strategy)
        except ValueError:
            ai_strategy_idx = 0
        ai_strategy = st.selectbox('AI í•©ì¹˜ëŠ” ë°©ì‹', options=ai_strategy_opts, index=ai_strategy_idx, help='ì—¬ëŸ¬ AIê°€ ëª¨ë‘ ê°™ì€ ì˜ê²¬ì¼ ë•Œë§Œ ë”°ë¥¼ì§€(UNANIMOUS), ê³¼ë°˜ìˆ˜ ì˜ê²¬ì„ ë”°ë¥¼ì§€(MAJORITY), í‰ê· ì„ ë‚¼ì§€(AVERAGE) ê³¨ë¼ìš”.')
        buy_strategy = st.selectbox('ë§¤ìˆ˜ ì‹œ ì ìš©í•  ì „ëµ', options=ai_strategy_opts, index=ai_strategy_opts.index(ai_ensemble.get('buy_strategy', ai_strategy)), help='ë§¤ìˆ˜ ê²°ì •ì„ ë‚´ë¦´ ë•Œ ì‚¬ìš©í•  ì•™ìƒë¸” ë°©ì‹ì…ë‹ˆë‹¤.')
        sell_strategy = st.selectbox('ë§¤ë„ ì‹œ ì ìš©í•  ì „ëµ', options=ai_strategy_opts, index=ai_strategy_opts.index(ai_ensemble.get('sell_strategy', ai_strategy)), help='ë§¤ë„ ê²°ì •ì„ ë‚´ë¦´ ë•Œ ì‚¬ìš©í•  ì•™ìƒë¸” ë°©ì‹ì…ë‹ˆë‹¤.')
        average_threshold = st.slider('AVERAGE ì „ëµ ê¸°ì¤€ ì‹ ë¢°ë„', min_value=0.0, max_value=1.0, value=float(ai_ensemble.get('average_threshold', 0.5)), step=0.05, help='AVERAGE ì „ëµ ì„ íƒ ì‹œ ë‘ ëª¨ë¸ì˜ ì‹ ë¢°ë„ í‰ê· ì´ ì´ ê°’ ì´ìƒì¼ ë•Œë§Œ ì‹¤í–‰í•©ë‹ˆë‹¤.')
        ai_reject_cooldown_candles = st.number_input('AI ê±°ì ˆ í›„ ì¿¨ë‹¤ìš´ ìº”ë“¤ ìˆ˜', min_value=0, value=int(ai_ensemble.get('ai_reject_cooldown_candles', 3)), help='AIê°€ ë§¤ë§¤ ì‹ í˜¸ë¥¼ ê±°ì ˆí•˜ë©´ ëª‡ ê°œ ìº”ë“¤ë™ì•ˆ ë‹¤ì‹œ AIì—ê²Œ ë¬¼ì–´ë³´ì§€ ì•Šì„ì§€ ì •í•´ìš”. 0ì´ë©´ ë°”ë¡œ ì¬ì‹œë„í•©ë‹ˆë‹¤.')
        openai_model = st.text_input('OpenAI ëª¨ë¸ ì´ë¦„', value=ai_ensemble.get('openai_model', cfg_snapshot.get('OPENAI_MODEL', 'gpt-5.1-nano')), help='OpenAIì—ì„œ ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„ì„ ì ì–´ìš”. íŠ¹ë³„íˆ ëª¨ë¥´ë©´ ê¸°ë³¸ê°’ ê·¸ëŒ€ë¡œ ë‘ì„¸ìš”.')
        gemini_model = st.text_input('Gemini ëª¨ë¸ ì´ë¦„', value=ai_ensemble.get('gemini_model', cfg_snapshot.get('GEMINI_MODEL', 'gemini-2.5-flash')), help='Geminiì—ì„œ ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„ì„ ì ì–´ìš”. ëª¨ë¥´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©')

        # Bot control settings
        st.subheader('ë´‡ ì œì–´ ì„¤ì • (ìë™ë§¤ë§¤ ë´‡ ë™ì‘ ì œì–´)')
        bot_enabled = st.checkbox('ìë™ë§¤ë§¤ ë´‡ í™œì„±í™”', value=bool(cfg_snapshot.get('bot_enabled', True)), help='ì²´í¬í•˜ë©´ ë´‡ì´ ìë™ìœ¼ë¡œ ë§¤ë§¤ë¥¼ ì‹œë„í•©ë‹ˆë‹¤. í•´ì œí•˜ë©´ ë´‡ì´ ì¼ì‹œì •ì§€ë©ë‹ˆë‹¤.')
        bot_interval_sec = st.number_input('ë´‡ ì²´í¬ ì£¼ê¸° (ì´ˆ)', min_value=1, value=int(cfg_snapshot.get('bot_interval_sec', loop_interval_sec)), help='ë´‡ì´ ëª‡ ì´ˆë§ˆë‹¤ ì‹œì¥ì„ í™•ì¸í• ì§€ ì •í•´ìš”. ê¸°ë³¸ì€ ë£¨í”„ ê°„ê²©ê³¼ ë™ì¼í•©ë‹ˆë‹¤.')
        bot_sell_cooldown_sec = st.number_input('ë§¤ë„ í›„ ì¿¨ë‹¤ìš´ ì‹œê°„ (ì´ˆ)', min_value=0, value=int(cfg_snapshot.get('bot_sell_cooldown_sec', 120)), help='ë§¤ë„ í›„ ë‹¤ì‹œ ë§¤ë„ ì‹ í˜¸ê°€ ë‚˜ì™€ë„ ì´ ì‹œê°„ë™ì•ˆì€ ë¬´ì‹œí•©ë‹ˆë‹¤. 0ì´ë©´ ì¿¨ë‹¤ìš´ ì—†ìŒ.')

        # Universe (comma separated tickers)
        st.subheader('ê´€ì‹¬ ì¢…ëª© ëª©ë¡ (ìš°ë¦¬ê°€ ë³¼ ì¢…ëª©ë“¤)')
        universe_list = cfg_snapshot.get('universe')
        if isinstance(universe_list, list):
            universe_str = ','.join(universe_list)
        else:
            universe_str = str(universe_list or '')
        universe_input = st.text_area('ê´€ì‹¬ ì¢…ëª© (ì½¤ë§ˆë¡œ êµ¬ë¶„, ì˜ˆ: KRW-BTC,KRW-ETH)', value=universe_str, height=80, help='ì—¬ê¸°ì— ë³´ê³  ì‹¶ì€ ì¢…ëª©ë“¤ì„ ì‰¼í‘œë¡œ êµ¬ë¶„í•´ì„œ ì ì–´ìš”. ì˜ˆ: KRW-BTC,KRW-ETH')

    if form_submitted:
        st.success('ì…ë ¥ê°’ì´ ìµœì‹  ìƒíƒœë¡œ ê°±ì‹ ëì–´ìš”. ì•„ë˜ "ë¡œì»¬ì— ì €ì¥" ë˜ëŠ” "ì„œë²„ì— ì „ì†¡" ë²„íŠ¼ìœ¼ë¡œ ì ìš©ì„ ì™„ë£Œí•´ ì£¼ì„¸ìš”.')

    if not isinstance(cfg_snapshot, dict):
        base_cfg = {}
    else:
        base_cfg = deepcopy(cfg_snapshot)

    new_cfg = deepcopy(base_cfg)
    new_cfg.update({
        'strategy_name': strategy_name,
        'market': market,
        'timeframe': timeframe,
        'candle_count': int(candle_count),
        'loop_interval_sec': int(loop_interval_sec),
        'order_settings': {
            'min_order_amount': int(min_order_amount),
            'trade_amount_krw': int(trade_amount_krw),
            'sell_ratio': float(sell_ratio),
        },
        'use_kelly_criterion': bool(use_kelly),
        'kelly_criterion': {
            'win_rate': float(win_rate),
            'payoff_ratio': float(payoff_ratio),
            'fraction': float(fraction),
        },
    })

    new_cfg['strategy_params'] = new_cfg.get('strategy_params', {})
    if strategy_name == 'RSI':
        new_cfg['strategy_params']['RSI'] = {
            'period': int(rsi_period),
            'oversold': int(rsi_oversold),
            'overbought': int(rsi_overbought),
        }
    elif strategy_name == 'VolatilityBreakout':
        new_cfg['strategy_params']['VolatilityBreakout'] = {
            'k_value': float(k_value),
            'target_vol_pct': float(target_vol_pct),
        }
    elif strategy_name == 'DualMomentum':
        new_cfg['strategy_params']['DualMomentum'] = {'window': int(window)}

    new_cfg.update({
        'prefetch_count': int(prefetch_count),
        'prefetch_interval_sec': int(prefetch_interval_sec),
        'prefetch_batch_size': int(prefetch_batch_size),
        'prefetch_parallelism': int(prefetch_parallelism),
        'prefetch_sleep_sec': float(prefetch_sleep_sec),
        'prefetch_min_interval_sec': int(prefetch_min_interval_sec),
        'prefetch_no_redis_max_count': int(prefetch_no_redis_max_count),
        'prefetch_rate_per_sec': float(prefetch_rate_per_sec),
        'prefetch_rate_capacity': int(prefetch_rate_capacity),
        'prefetch_max_concurrent': int(prefetch_max_concurrent),
        'prefetch_token_wait_timeout': float(prefetch_token_wait_timeout),
        'KLINES_CACHE_TTL': int(klines_cache_ttl),
    })

    new_cfg['ai_ensemble'] = {
        'strategy': ai_strategy,
        'buy_strategy': buy_strategy,
        'sell_strategy': sell_strategy,
        'average_threshold': float(average_threshold),
        'ai_reject_cooldown_candles': int(ai_reject_cooldown_candles),
        'openai_model': openai_model,
        'gemini_model': gemini_model,
    }

    # Bot control settings
    new_cfg['bot_enabled'] = bool(bot_enabled)
    new_cfg['bot_interval_sec'] = int(bot_interval_sec)
    new_cfg['bot_sell_cooldown_sec'] = int(bot_sell_cooldown_sec)

    universe_parsed = [s.strip() for s in universe_input.split(',') if s.strip()]
    if universe_parsed:
        new_cfg['universe'] = universe_parsed
    elif 'universe' not in new_cfg:
        new_cfg['universe'] = []

    st.divider()
    st.header('ì„¤ì • ì•¡ì…˜')
    valid, message = validate_config(new_cfg)
    if not valid:
        st.error('ìœ íš¨ì„± ê²€ì‚¬ ì‹¤íŒ¨: ' + message)

    col_a, col_b, col_c = st.columns(3)
    with col_a:
        if st.button('ë¡œì»¬ì— ì €ì¥'):
            if not valid:
                st.error('ì €ì¥ ì‹¤íŒ¨: ìœ íš¨ì„± ê²€ì‚¬ ì‹¤íŒ¨ - ' + message)
            else:
                try:
                    if save_local(new_cfg):
                        st.success('ì €ì¥ ì™„ë£Œ: runtime/config.json')
                        _refresh_config_cache()
                        st.rerun()
                    else:
                        st.error('ë¡œì»¬ ì €ì¥ ì‹¤íŒ¨: ì €ì¥ í•¨ìˆ˜ì—ì„œ Falseê°€ ë°˜í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.')
                except Exception as e:
                    st.error('ë¡œì»¬ ì €ì¥ ì‹¤íŒ¨: ' + str(e))
    with col_b:
        if st.button('ì„œë²„ì— ì „ì†¡'):
            if not valid:
                st.error('ì „ì†¡ ì‹¤íŒ¨: ìœ íš¨ì„± ê²€ì‚¬ ì‹¤íŒ¨ - ' + message)
            else:
                try:
                    resp = api_request('post', '/config', json={'config': new_cfg}, timeout=10)
                    st.success('ì„œë²„ì— ì „ì†¡ ì™„ë£Œ')
                except Exception as e:
                    st.error(str(e))
    with col_c:
        if st.button('ì„œë²„ ì¬ë¡œë”© ìš”ì²­'):
            try:
                resp = api_request('post', '/reload', timeout=5)
                st.success('ì„œë²„ ì¬ë¡œë”© ìš”ì²­ ì„±ê³µ')
            except Exception as e:
                st.error(str(e))


def render_ws_monitoring_page():
    st.title('WebSocket ëª¨ë‹ˆí„°ë§')
    st.write('ì‹¤ì‹œê°„ WebSocket ìŠ¤íŠ¸ë¦¬ë° í˜„í™©ê³¼ ì²´ê²° ê¸°ë¡ì„ í•œëˆˆì— í™•ì¸í•©ë‹ˆë‹¤.')

    stats, stats_err = fetch_ws_stats()
    if stats_err:
        st.warning(f'WebSocket í†µê³„ ìˆ˜ì§‘ ì˜¤ë¥˜: {stats_err}')
        stats = None

    if stats:
        cols = st.columns(4)
        metrics = (
            ('ì‹œì„¸ ìˆ˜ì‹  ì„±ê³µ', stats.get('ticker_success', 0)),
            ('ì‹œì„¸ ìˆ˜ì‹  ì‹¤íŒ¨', stats.get('ticker_failure', 0)),
            ('ì²´ê²° ìˆ˜ì‹  ì„±ê³µ', stats.get('order_success', 0)),
            ('ì²´ê²° ìˆ˜ì‹  ì‹¤íŒ¨', stats.get('order_failure', 0)),
        )
        for col, (label, value) in zip(cols, metrics):
            col.metric(label, f"{int(value):,}")
        status_text = 'ì‹¤í–‰ ì¤‘' if stats.get('running') else 'ëŒ€ê¸° ì¤‘'
        st.caption(
            f"WebSocket ìƒíƒœ: {status_text} Â· êµ¬ë… ì¢…ëª©: {len(stats.get('targets', []))} Â· "
            f"ìµœê·¼ 1ì‹œê°„ ì‹œì„¸ ì„±ê³µ:{stats.get('last_hour_ticker_success', 0)}, ì‹¤íŒ¨:{stats.get('last_hour_ticker_failure', 0)} / "
            f"ì²´ê²° ì„±ê³µ:{stats.get('last_hour_order_success', 0)}, ì‹¤íŒ¨:{stats.get('last_hour_order_failure', 0)}"
        )
    else:
        st.info('WebSocket í†µê³„ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¦¬ìŠ¤ë„ˆ ì‹¤í–‰ ì—¬ë¶€ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.')

    st.divider()
    st.subheader('WebSocket ì œì–´')
    btn_col1, btn_col2, btn_col3 = st.columns(3)
    with btn_col1:
        if st.button('WebSocket ì‹œì‘', key='ws_ctrl_start'):
            try:
                api_request('post', '/ws/start', timeout=5)
                st.success('WebSocket ë¦¬ìŠ¤ë„ˆ ì‹œì‘ ìš”ì²­ì´ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤.')
            except Exception as exc:
                st.error(f'WebSocket ì‹œì‘ ì‹¤íŒ¨: {exc}')
    with btn_col2:
        if st.button('WebSocket ì¤‘ì§€', key='ws_ctrl_stop'):
            try:
                api_request('post', '/ws/stop', timeout=5)
                st.success('WebSocket ë¦¬ìŠ¤ë„ˆ ì¤‘ì§€ ìš”ì²­ì´ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤.')
            except Exception as exc:
                st.error(f'WebSocket ì¤‘ì§€ ì‹¤íŒ¨: {exc}')
    with btn_col3:
        if st.button('ìƒíƒœ ìƒˆë¡œ ê³ ì¹¨', key='ws_ctrl_refresh'):
            _trigger_rerun()

    st.divider()
    enabled = st.session_state.get(AUTO_REFRESH_KEY, False)
    enabled = _render_autorefresh_button()
    st.session_state[AUTO_REFRESH_KEY] = enabled
    _apply_autorefresh_if_enabled()

    st.subheader('ë¶„ë´‰ ìˆ˜ì‹  í˜„í™© (ìµœê·¼ 10ê°œ)')
    rows = []
    if stats:
        for item in stats.get('recent_ticker_events', []):
            rows.append({
                'ì‹œê°„': _format_ws_ts(item.get('ts')),
                'ì¢…ëª©': item.get('symbol') or '-',
                'íƒ€ì…': item.get('type') or '-',
                'í˜„ì¬ê°€' : item.get('trade_price') or '-',
                'ê²°ê³¼': 'ì„±ê³µ' if item.get('success') else 'ì‹¤íŒ¨',
            })
    if rows:
        _safe_dataframe(pd.DataFrame(rows), hide_index=True)
    else:
        st.info('ìµœê·¼ ë¶„ë´‰ ìˆ˜ì‹  ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.')

    st.subheader('ì‹¬ë³¼ë³„ ìµœì‹  í‹°ì»¤ ì •ë³´ (5ì´ˆ ìë™ ê°±ì‹ )')
    ticker_data, ticker_err = fetch_ws_ticker_data()
    if ticker_err:
        st.warning(f'í‹°ì»¤ ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {ticker_err}')
    elif ticker_data and isinstance(ticker_data.get('tickers'), list):
        df_tickers = pd.DataFrame(ticker_data['tickers'])
        if not df_tickers.empty:
            df_tickers = df_tickers.rename(columns={
                'symbol': 'ì‹¬ë³¼',
                'opening_price': 'ì‹œê°€',
                'high_price': 'ê³ ê°€',
                'low_price': 'ì €ê°€',
                'trade_price': 'í˜„ì¬ê°€',
                'prev_closing_price': 'ì „ì¼ì¢…ê°€',
                'change': 'ì „ì¼ëŒ€ë¹„ë³€ë™',
            })
            if 'timestamp' in df_tickers.columns:
                df_tickers['ìµœê·¼ ìˆ˜ì‹ '] = df_tickers['timestamp'].apply(_format_ws_ts)
            display_cols = ['ì‹¬ë³¼', 'ì‹œê°€', 'ê³ ê°€', 'ì €ê°€', 'í˜„ì¬ê°€', 'ì „ì¼ì¢…ê°€', 'ì „ì¼ëŒ€ë¹„ë³€ë™', 'ìµœê·¼ ìˆ˜ì‹ ']
            available_cols = [c for c in display_cols if c in df_tickers.columns]
            df_display = df_tickers[available_cols]
            _safe_dataframe(df_display.fillna('-'), hide_index=True)
        else:
            st.info('í‹°ì»¤ ë°ì´í„°ê°€ ì•„ì§ ì—†ìŠµë‹ˆë‹¤.')
    else:
        if ticker_err is None:
            st.info('í‹°ì»¤ ë°ì´í„° ë¡œë”© ëŒ€ê¸° ì¤‘ì…ë‹ˆë‹¤.')

    st.subheader('ì²´ê²° ìˆ˜ì‹  í˜„í™© (exec_history)')
    executions, exec_err = fetch_ws_executions()
    exec_table = []
    if exec_err:
        st.warning(f'ì²´ê²° ê¸°ë¡ ì¡°íšŒ ì˜¤ë¥˜: {exec_err}')
    elif executions and isinstance(executions.get('executions'), list):
        data = executions['executions']
        for entry in sorted(data, key=lambda e: e.get('ts', 0), reverse=True):
            profit_loss = entry.get('profit_loss')
            profit_loss_pct = entry.get('profit_loss_pct')

            row = {
                'ì‹œê°„': _format_ws_ts(entry.get('ts')),
                'ì‹¬ë³¼': entry.get('symbol') or '-',
                'ì‚¬ì´ë“œ': entry.get('side') or entry.get('ask_bid') or '-',
                'ì²´ê²°ê°€': entry.get('price') or entry.get('order_price') or '-',
                'ìˆ˜ëŸ‰': entry.get('size') or entry.get('trade_volume') or '-',
                'ì§„ì…ê°€': entry.get('entry_price') or '-',
            }

            # ì†ìµ ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶”ê°€
            if profit_loss is not None:
                row['ì†ìµ(KRW)'] = f"{profit_loss:+,.2f}"
            else:
                row['ì†ìµ(KRW)'] = '-'

            if profit_loss_pct is not None:
                row['ì†ìµ(%)'] = f"{profit_loss_pct:+.2f}%"
            else:
                row['ì†ìµ(%)'] = '-'

            exec_table.append(row)
    if exec_table:
        try:
            df_exec = pd.DataFrame(exec_table)
            def _format_side(label: str) -> str:
                try:
                    key = str(label or '').strip().lower()
                except Exception:
                    return label
                if key in ('ask', 'sell', 'ë§¤ë„'):
                    return 'ë§¤ë„'
                if key in ('bid', 'buy', 'ë§¤ìˆ˜'):
                    return 'ë§¤ìˆ˜'
                return label
            if 'ì‚¬ì´ë“œ' in df_exec.columns:
                df_exec['ì‚¬ì´ë“œ'] = df_exec['ì‚¬ì´ë“œ'].map(_format_side)
            _safe_dataframe(df_exec, hide_index=True)
        except Exception:
            st.write(exec_table)
    else:
        if not exec_err:
            st.info('ì²´ê²° ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤. WebSocket ë¦¬ìŠ¤ë„ˆê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.')


def render_screening_page():
    st.title('ì¢…ëª© ìŠ¤í¬ë¦¬ë‹')
    st.caption('ë³€ë™ì„± TOP ì¢…ëª©ì„ ì¡°íšŒí•©ë‹ˆë‹¤. (ìµœê·¼ ìº”ë“¤ ê¸°ì¤€)')
    st.code('ë³€ë™ì„±ì€ (max_high - min_low) / mean_close ë¡œ ê³„ì‚°ë©ë‹ˆë‹¤.')

    # Controls moved into the page (previously in sidebar)
    ctrl_col1, ctrl_col2, ctrl_col3 = st.columns([1,1,1])
    market_prefix = ctrl_col1.text_input('ë§ˆì¼“ ì ‘ë‘ì‚¬ (ì˜ˆ: KRW)', value='KRW', key='scr_market_prefix')
    top_n = ctrl_col2.number_input('Top N', min_value=1, max_value=50, value=10, key='scr_top_n')
    # timeframe placed in the third column for grouping
    timeframe = ctrl_col3.selectbox('Timeframe', options=['minute5','minute15','minute60','day'], index=1, key='scr_timeframe')

    # Place the search button in a dedicated full-width row so it spans the page
    full_row = st.columns([1])[0]
    try:
        # Use width='stretch' when supported
        search_clicked = full_row.button('ì¡°íšŒ', key='scr_search', width='stretch')
    except TypeError:
        # Fallback for older Streamlit versions
        search_clicked = full_row.button('ì¡°íšŒ', key='scr_search')

    # When search clicked, fetch data and then render charts below
    if 'search_clicked' not in st.session_state:
        st.session_state['search_clicked'] = False
    if search_clicked:
        st.session_state['search_clicked'] = True
        st.session_state['screening_query'] = {
            'market_prefix': market_prefix,
            'top_n': top_n,
            'timeframe': timeframe,
        }

    if not st.session_state.get('search_clicked'):
        st.info('ì¡°íšŒ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë³€ë™ì„± TOP ì¢…ëª©ì„ ê²€ìƒ‰í•˜ì„¸ìš”.')
        return

    # read query
    query = st.session_state.get('screening_query', {})
    market_prefix = query.get('market_prefix', 'KRW')
    requested_n = int(query.get('top_n', 10))
    timeframe = query.get('timeframe', 'minute15')

    with st.spinner('ë³€ë™ì„± TOP ì¢…ëª© ì¡°íšŒ ì¤‘...'):
        # Try multiple backend endpoints for compatibility
        candidate_paths = [
            ('post', '/screening/top_volatility'),
            ('get', '/screen/volatility_top'),
            ('get', '/screen/volatility_top'),
        ]
        tickers = []
        last_exception = None
        for method, path in candidate_paths:
            try:
                if method == 'get':
                    resp = api_request('get', path, params={'market_prefix': market_prefix, 'top_n': requested_n, 'timeframe': timeframe}, timeout=8)
                else:
                    resp = api_request('post', path, json={'market_prefix': market_prefix, 'top_n': requested_n, 'timeframe': timeframe}, timeout=10)
                j = resp.json()
                # support different key names
                tickers = j.get('tickers') or j.get('top') or j.get('top_tickers') or j.get('top', [])
                # if server returns objects, try to extract ticker strings
                if tickers and isinstance(tickers, list) and isinstance(tickers[0], dict):
                    # expect dict with 'ticker' or 'symbol'
                    tickers = [it.get('ticker') or it.get('symbol') or it.get('market') for it in tickers]
                # filter empties
                tickers = [t for t in (tickers or []) if t]
                if tickers:
                    break
            except Exception as e:
                last_exception = e
                continue

        if not tickers:
            if last_exception:
                st.error(f'ìŠ¤ì¼€ë¦¬ë‹ ì¡°íšŒ ì‹¤íŒ¨: {last_exception}')
            else:
                st.warning('ì¡°ê±´ì— ë§ëŠ” ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.')
            return

        # fetch klines in batch
        backend_data = fetch_klines_batch_from_backend(tickers, timeframe=timeframe, count=200)

        # Compute volatility (%) per ticker from backend_data and show a ranked table
        vol_rows = []
        for t in tickers:
            dfk = backend_data.get(t)
            dfk_norm = _normalize_klines_df(dfk, min_length=5)
            vol = compute_volatility_from_df(dfk_norm)
            vol_rows.append({'ticker': t, 'volatility_pct': None if vol is None else float(vol)})
        try:
            df_top = pd.DataFrame(vol_rows)
            # sort by volatility (ascending), NaNs at the end
            df_top = df_top.sort_values('volatility_pct', ascending=False, na_position='last').reset_index(drop=True)
            df_top.insert(0, 'rank', range(1, len(df_top) + 1))
            # pretty formatting column
            def _fmt(v):
                try:
                    if v is None or (isinstance(v, float) and (pd.isna(v))):
                        return '-'
                    return f"{float(v):.2f}%"
                except Exception:
                    return '-'
            df_top['ë³€ë™ì„±(%)'] = df_top['volatility_pct'].apply(_fmt)
            df_display = df_top[['rank','ticker','ë³€ë™ì„±(%)']]
            _safe_dataframe(df_display, hide_index=True)
        except Exception as e:
            st.warning(f'ìƒë‹¨ ë³€ë™ì„± í‘œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}')

        # Diagnostics: show which tickers have data and which not
        missing = []
        insufficient = []
        for t in tickers:
            df = backend_data.get(t)
            if df is None:
                missing.append(t)
            else:
                try:
                    if hasattr(df, 'shape') and df.shape[0] < 10:
                        insufficient.append((t, int(df.shape[0])))
                except Exception:
                    pass
        if missing:
            st.warning(f"ë°ì´í„°ê°€ ì—†ëŠ” ì¢…ëª©: {', '.join(missing)} (ë°±ì—”ë“œê°€ ìºì‹œë¥¼ ì•„ì§ ì±„ìš°ì§€ ì•Šì•˜ê±°ë‚˜ ìˆ˜ì§‘ ì‹¤íŒ¨)")
        if insufficient:
            st.info('ìƒ˜í”Œì´ ì ì€ ì¢…ëª©: ' + ', '.join([f"{t}({n})" for t,n in insufficient]))

        # Render a grid: 5 rows x 2 cols (max 10)
        max_slots = requested_n
        display_items = tickers[:max_slots]
        display_n = len(display_items)
        rows = (max_slots + 1) // 2
        idx = 0
        for r in range(rows):
            cols = st.columns(2, gap='small')
            for c in range(2):
                if idx >= display_n:
                    with cols[c]:
                        st.empty()
                    idx += 1
                    continue
                ticker = display_items[idx]
                with cols[c]:
                    st.subheader(f"{idx+1}. {ticker}")
                    df = backend_data.get(ticker)
                    df = _normalize_klines_df(df, min_length=30)
                    if df is None or (hasattr(df, 'empty') and df.empty):
                        st.info('ì°¨íŠ¸ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ë°±ì—”ë“œ ìºì‹œ ë˜ëŠ” ìˆ˜ì§‘ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”)')
                    else:
                        # smaller chart per grid cell
                        fig = plot_candles_with_indicators(df, ticker, ma_windows=[20, 60], rsi_period=14)
                        fig.update_layout(height=320, margin=dict(l=8, r=8, t=24, b=12))
                        _safe_plotly_chart(fig)
                idx += 1
        st.caption(f"í‘œì‹œëœ ì¢…ëª©: {display_n} / ìš”ì²­í•œ TopN: {requested_n}")


def render_positions_page():
    st.title('ì›í™”ì”ê³  ë° í¬ì§€ì…˜ ë¶„ì„')
    st.write('ì›í™” ì”ê³ ì™€ ë³´ìœ  í¬ì§€ì…˜ì„ ìš”ì•½í•˜ê³  ê°„ë‹¨í•œ ì‹œê°í™”ë¥¼ ì œê³µí•©ë‹ˆë‹¤.')

    balances = None
    positions = None
    positions_payload: Dict[str, Any] = {}
    api_errors: list[str] = []

    # Try dedicated endpoints first
    reported_krw_from_server = 0.0
    balances_response_meta = {}
    try:
        resp = api_request('get', '/balances', timeout=6)
        if resp and resp.status_code == 200:
            j = resp.json()
            # API returns {'balances': [...], 'reported_krw_balance':..., 'cached':..., 'cached_ts':...}
            if isinstance(j, dict):
                balances = j.get('balances') if 'balances' in j else j
                reported_krw_from_server = float(j.get('reported_krw_balance') or 0.0)
                balances_response_meta = {k: j.get(k) for k in ('cached','cached_ts') if k in j}
            else:
                balances = j
    except Exception as e:
        api_errors.append(f"/balances í˜¸ì¶œ ì‹¤íŒ¨: {e}")

    try:
        resp2 = api_request('get', '/positions', timeout=6)
        if resp2 and resp2.status_code == 200:
            j2 = resp2.json()
            if isinstance(j2, dict):
                positions_payload = j2
                positions = j2.get('positions')
            else:
                positions = j2
    except Exception as e:
        api_errors.append(f"/positions í˜¸ì¶œ ì‹¤íŒ¨: {e}")

    # If both endpoints failed, try returning /status for diagnostics
    if balances is None and positions is None:
        try:
            resp3 = api_request('get', '/debug/status', timeout=4)
            if resp3 and resp3.status_code == 200:
                st.info('ë°±ì—”ë“œ ìƒíƒœ:')
                st.json(resp3.json())
        except Exception:
            pass

    # Show API warnings (but avoid noisy raw exceptions)
    for err in api_errors:
        if 'keys not configured' in err or '503' in err:
            st.warning('ì„œë²„ì— API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ì”ê³ ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ê´€ë¦¬ì ì„¤ì • í•„ìš”)')
        else:
            st.info(err)

    # Normalize balances into DataFrame
    try:
        if balances and isinstance(balances, list):
            bal_df = pd.DataFrame(balances)
        elif balances and isinstance(balances, dict):
            # sometimes API returns map
            bal_df = pd.DataFrame(balances.get('balances') if 'balances' in balances else [balances])
        else:
            bal_df = pd.DataFrame(columns=['currency', 'balance', 'locked', 'avg_buy_price'])

        # Accept multiple possible field names and normalize
        if 'currency' not in bal_df.columns and 'unit' in bal_df.columns:
            bal_df = bal_df.rename(columns={'unit': 'currency'})
        if 'currency' not in bal_df.columns and 'coin' in bal_df.columns:
            bal_df = bal_df.rename(columns={'coin': 'currency'})

        # numeric conversions
        for col in ('balance', 'locked', 'avg_buy_price'):
            if col in bal_df.columns:
                bal_df[col] = pd.to_numeric(bal_df[col], errors='coerce')

        # If currency column named differently
        if 'currency' not in bal_df.columns and 'currency_name' in bal_df.columns:
            bal_df = bal_df.rename(columns={'currency_name': 'currency'})

    except Exception:
        bal_df = pd.DataFrame(columns=['currency', 'balance', 'locked', 'avg_buy_price'])

    # Normalize positions
    try:
        if positions and isinstance(positions, list):
            pos_df = pd.DataFrame(positions)
        elif positions and isinstance(positions, dict):
            pos_df = pd.DataFrame(positions.get('positions') if 'positions' in positions else [positions])
        else:
            pos_df = pd.DataFrame(columns=['symbol','side','qty','entry_price','unrealized_pnl'])
        # common conversions
        for c in ['qty','entry_price','unrealized_pnl','unrealized_pnl_usdt','avg_price']:
            if c in pos_df.columns:
                pos_df[c] = pd.to_numeric(pos_df[c], errors='coerce')
        if 'unrealized_pnl' not in pos_df.columns and 'unrealized_pnl_usdt' in pos_df.columns:
            pos_df['unrealized_pnl'] = pos_df['unrealized_pnl_usdt']
        if 'symbol' not in pos_df.columns and 'ticker' in pos_df.columns:
            pos_df = pos_df.rename(columns={'ticker':'symbol'})
        if 'side' not in pos_df.columns:
            for cand in ('position_side','direction'):
                if cand in pos_df.columns:
                    pos_df['side'] = pos_df[cand]
                    break
    except Exception:
        pos_df = pd.DataFrame(columns=['symbol','side','qty','entry_price','unrealized_pnl'])

    # Fetch history for chart
    history = []
    try:
        resp_hist = api_request('get', '/positions/history', timeout=8)
        if resp_hist and resp_hist.status_code == 200:
            history = resp_hist.json().get('history', []) or []
    except Exception:
        history = []

    # Compute KRW-equivalent values for balances using backend price fetch
    try:
        bal_df = bal_df.copy()
        bal_df['currency'] = bal_df['currency'].astype(str)
        # build market tickers for non-KRW currencies (e.g., BTC -> KRW-BTC)
        markets = []
        currency_to_market = {}
        for cur in bal_df['currency'].unique():
            cur_up = cur.upper()
            if cur_up == 'KRW' or cur_up.startswith('KRW'):
                continue
            market = f"KRW-{cur_up}"
            markets.append(market)
            currency_to_market[cur_up] = market

        price_map: dict = {}
        if markets:
            # fetch latest close price for those markets via backend batch (count=1)
            try:
                kline_map = fetch_klines_batch_from_backend(markets, timeframe='minute1', count=1)
                for m, df in kline_map.items():
                    price = None
                    try:
                        if df is not None and hasattr(df, 'empty') and not df.empty and 'close' in df.columns:
                            # get last available close
                            price = float(df['close'].iloc[-1])
                    except Exception:
                        price = None
                    price_map[m] = price
            except Exception:
                price_map = {}

        # add price_krw and value_krw columns
        def _get_price_krw(cur):
            try:
                cu = str(cur).upper()
                if cu == 'KRW' or cu.startswith('KRW'):
                    return 1.0
                m = currency_to_market.get(cu)
                if not m:
                    return None
                return price_map.get(m)
            except Exception:
                return None

        bal_df['price_krw'] = bal_df['currency'].apply(_get_price_krw)
        # value_krw: for KRW currency, balance is already KRW; otherwise balance * price_krw
        def _compute_value(row):
            try:
                bal = float(row.get('balance') or 0)
            except Exception:
                bal = 0.0
            pr = row.get('price_krw')
            cur = str(row.get('currency') or '').upper()
            if cur == 'KRW' or cur.startswith('KRW'):
                return bal
            if pr is None:
                return None
            return bal * float(pr)

        bal_df['value_krw'] = bal_df.apply(_compute_value, axis=1)

    except Exception:
        # fallback to original simple KRW sum
        bal_df['price_krw'] = None
        bal_df['value_krw'] = None

    # Top metrics: use server-reported KRW cash and compute converted asset value from available prices only
    available_krw_payload = float(positions_payload.get('available_krw') or 0.0)
    total_equity_payload = float(positions_payload.get('total_equity_krw') or 0.0)
    excluded_assets = positions_payload.get('excluded_assets') or []
    krw_cash = float(available_krw_payload or reported_krw_from_server or 0.0)
    conv_sum = total_equity_payload if total_equity_payload else 0.0
    try:
        if not bal_df.empty and 'value_krw' in bal_df.columns and 'currency' in bal_df.columns:
            # only include non-KRW assets where value_krw is a real number (not None/NaN)
            nonkrw = bal_df[~bal_df['currency'].astype(str).str.upper().str.contains('KRW', na=False)]
            conv_sum = float(nonkrw['value_krw'].dropna().sum())
    except Exception:
        conv_sum = 0.0

    # Compute total unrealized PnL
    total_unrealized = 0.0
    try:
        if not pos_df.empty and 'unrealized_pnl' in pos_df.columns:
            total_unrealized = pos_df['unrealized_pnl'].dropna().sum()
    except Exception:
        total_unrealized = 0.0

    c1, c2, c3 = st.columns(3)
    c1.metric('ì›í™” í˜„ê¸ˆ ì”ê³ ', f"{krw_cash:,.0f} ì›")
    c2.metric('í‰ê°€ìì‚° ì´ì•¡(ì›)', f"{(total_equity_payload or (krw_cash + conv_sum)):,.0f} ì›")
    c3.metric('ì´ ë¯¸í™•ì • ì†ìµ', f"{total_unrealized:,.0f} ì›")

    # Show balances table with KRW conversion columns
    try:
        # Prepare display dataframe
        if not bal_df.empty:
            disp = bal_df[['currency', 'balance', 'price_krw', 'value_krw']].copy()

            def _fmt_amount(v):
                try:
                    if v is None or (isinstance(v, float) and pd.isna(v)):
                        return '-'
                    f = float(v)
                    if abs(f) >= 1:
                        return f"{f:,.0f}"
                    return f"{f:.8f}"
                except Exception:
                    return str(v)

            def _fmt_price(v):
                try:
                    if v is None or (isinstance(v, float) and pd.isna(v)):
                        return '-'
                    f = float(v)
                    if f >= 1:
                        return f"{f:,.0f}"
                    return f"{f:.8f}"
                except Exception:
                    return str(v)

            disp['ì”ê³ '] = disp['balance'].apply(_fmt_amount)
            disp['í˜„ì¬ê°€(ì›)'] = disp['price_krw'].apply(_fmt_price)
            disp['ê°€ì¹˜(ì›)'] = disp['value_krw'].apply(lambda v: _fmt_amount(v) if v is not None and not pd.isna(v) else '-')
            disp = disp.rename(columns={'currency': 'í™”í'})
            disp = disp[['í™”í', 'ì”ê³ ', 'í˜„ì¬ê°€(ì›)', 'ê°€ì¹˜(ì›)']]
            _safe_dataframe(disp, hide_index=True)

            # show total caption and note missing price entries
            missing_prices = bal_df[bal_df['value_krw'].isna() & ~bal_df['currency'].astype(str).str.upper().str.contains('KRW')]['currency'].tolist()
            st.caption(f"ì¶”ì • í¬íŠ¸í´ë¦¬ì˜¤ ì´ì•¡(ì›í™”, í˜„ê¸ˆ+í™˜ì‚°): {krw_cash+conv_sum:,.0f} ì›")
            if missing_prices:
                st.info(f"ì•„ë˜ ì¢…ëª©ì€ í˜„ì¬ê°€ê°€ ì—†ì–´ í™˜ì‚°ì—ì„œ ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(missing_prices)}")
        else:
            st.info('ì”ê³  ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.')
    except Exception as e:
        st.warning(f'ì”ê³  í…Œì´ë¸” í‘œì‹œ ì¤‘ ì˜¤ë¥˜: {e}')

    st.divider()

    # Positions table and PnL chart
    try:
        if pos_df.empty:
            st.info('ë³´ìœ  í¬ì§€ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.')
        else:
            # ensure required columns exist even if backend omits them
            required_cols = ['symbol', 'size', 'entry_price', 'current_price', 'unrealized_pnl', 'unrealized_pnl_rate', 'notional_krw']
            for col in required_cols:
                if col not in pos_df.columns:
                    pos_df[col] = None
            disp = pos_df[required_cols].copy()
            disp = disp.rename(columns={
                'symbol': 'ì¢…ëª©í‹°ì»¤',
                'size': 'ìˆ˜ëŸ‰',
                'entry_price': 'ì§„ì…ê°€ê²©',
                'current_price': 'í˜„ì¬ê°€ê²©',
                'unrealized_pnl': 'í‰ê°€ì†ìµ',
                'unrealized_pnl_rate': 'ì†ìµë¹„ìœ¨',
                'notional_krw': 'í‰ê°€ê¸ˆì•¡',
            })
            for col in ('ìˆ˜ëŸ‰','ì§„ì…ê°€ê²©','í˜„ì¬ê°€ê²©','í‰ê°€ì†ìµ','í‰ê°€ê¸ˆì•¡'):
                disp[col] = disp[col].map(lambda v: f"{float(v):,.0f}" if v not in (None, '') and pd.notna(v) else '-')
            disp['ì†ìµë¹„ìœ¨'] = disp['ì†ìµë¹„ìœ¨'].map(lambda v: f"{float(v):.2f}%" if v not in (None, '') and pd.notna(v) else '-')
            _safe_dataframe(disp, hide_index=True)
            if excluded_assets:
                symbols = [item.get('symbol') for item in excluded_assets if isinstance(item, dict) and item.get('symbol')]
                if symbols:
                    st.info(f"í˜„ì¬ê°€ ë¯¸ìˆ˜ì‹ ìœ¼ë¡œ ì œì™¸ëœ ì¢…ëª©: {', '.join(symbols)}")
            st.caption(f"ì‚°ì¶œëœ í¬ì§€ì…˜: {len(disp)}ê°œ Â· ê°€ê²© ì¡°íšŒëœ ì¢…ëª©: {positions_payload.get('prices_fetched', 0)}ê°œ")
            if history:
                chart_cols = st.columns(2)
                line_rows = []
                for record in sorted(history, key=lambda item: item.get('ts', 0)):
                    ts_value = float(record.get('ts', 0))
                    row = {'date': pd.to_datetime(ts_value, unit='s', errors='coerce')}
                    for snapshot in record.get('positions', []):
                        symbol = snapshot.get('symbol')
                        notional = snapshot.get('notional_krw')
                        if symbol and notional is not None:
                            row[symbol] = float(notional)
                    line_rows.append(row)
                if line_rows:
                    line_df = pd.DataFrame(line_rows).set_index('date').sort_index()
                else:
                    line_df = pd.DataFrame()

                # Time-series line chart for position values
                with chart_cols[0]:
                    st.subheader('í¬ì§€ì…˜ ê°€ì¹˜ ì¶”ì´')
                    if line_df.empty:
                        st.info('í¬ì§€ì…˜ ê°€ì¹˜ ë³€í™” ì°¨íŠ¸ì— ì‚¬ìš©í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.')
                    else:
                        fig_line = go.Figure()
                        for sym in line_df.columns:
                            if sym == 'date':
                                continue
                            fig_line.add_trace(go.Scatter(
                                x=line_df.index,
                                y=line_df[sym],
                                mode='lines',
                                name=sym,
                                hovertemplate='%{x}<br>%{y:,.0f} ì›<extra></extra>'
                            ))
                        fig_line.update_layout(title='í¬ì§€ì…˜ë³„ ê°€ì¹˜ ë³€í™”', xaxis_title='ë‚ ì§œ', yaxis_title='ê°€ì¹˜ (KRW)', margin=dict(l=10,r=10,t=30,b=30), height=320)
                        _safe_plotly_chart(fig_line)

                # Bar chart for unrealized PnL
                with chart_cols[1]:
                    st.subheader('í¬ì§€ì…˜ë³„ ì†ìµ í˜„í™©')
                    pnl_df = pos_df[['symbol','unrealized_pnl']].copy()
                    pnl_df = pnl_df.sort_values('unrealized_pnl')
                    if pnl_df['unrealized_pnl'].dropna().empty:
                        st.info('ì†ìµ ì°¨íŠ¸ì— ì‚¬ìš©í•  ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.')
                    else:
                        colors = ['#d64f3a' if v>0 else '#1e40af' for v in pnl_df['unrealized_pnl'].fillna(0)]
                        fig_bar = go.Figure()
                        fig_bar.add_trace(go.Bar(
                            x=pnl_df['symbol'],
                            y=pnl_df['unrealized_pnl'],
                            marker_color=colors,
                            name='í‰ê°€ì†ìµ',
                            hovertemplate='%{x}<br>%{y:,.0f}ì›<extra></extra>'
                        ))
                        fig_bar.update_layout(title='í¬ì§€ì…˜ë³„ ì†ìµ', xaxis_title='ì¢…ëª©', yaxis_title='ì†ìµ (ì›)', bargap=0.2, margin=dict(l=10,r=10,t=30,b=30), height=320)
                        fig_bar.update_yaxes(zeroline=True, zerolinewidth=2, zerolinecolor='#94a3b8')
                        _safe_plotly_chart(fig_bar)
    except Exception as e:
        st.error(f'í¬ì§€ì…˜ í‘œì‹œ ì¤‘ ì˜¤ë¥˜: {e}')


def fetch_ai_history(limit: int = 100):
    try:
        resp = api_request('get', '/ai/history', params={'limit': limit}, timeout=10)
        return resp.json(), None
    except Exception as exc:
        return None, exc


def fetch_bot_status():
    try:
        resp = api_request('get', '/bot/status', timeout=5)
        return resp.json(), None
    except Exception as exc:
        return None, exc


def update_bot_control_api(enabled: Optional[bool] = None, interval_sec: Optional[float] = None):
    payload = {}
    if enabled is not None:
        payload['enabled'] = enabled
    if interval_sec is not None:
        payload['interval_sec'] = interval_sec
    if not payload:
        return None, RuntimeError('enabled ë˜ëŠ” interval_sec ì¤‘ í•˜ë‚˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.')
    try:
        resp = api_request('post', '/bot/control', json=payload, timeout=10)
        return resp.json(), None
    except Exception as exc:
        return None, exc


def render_bot_control_page():
    st.title('ìë™ë§¤ë§¤ë´‡ ê´€ë¦¬')
    st.write('ì„œë²„ì˜ trading_bot ì‹¤í–‰ ì—¬ë¶€, ê²€ì‚¬ ì£¼ê¸° ë“±ì„ ë°”ê¿€ ìˆ˜ ìˆëŠ” ì œì–´ í™”ë©´ì…ë‹ˆë‹¤.')
    status, err = fetch_bot_status()
    if err:
        st.error(f'ë´‡ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {err}')
        status = {}
    enabled = bool(status.get('bot_enabled'))
    interval = float(status.get('bot_interval_sec', cfg.get('loop_interval_sec', 5)))
    st.metric('ìë™ë§¤ë§¤ í—ˆìš©', 'í™œì„±' if enabled else 'ì¤‘ì§€ë¨')
    st.metric('ê²€ì‚¬ ì£¼ê¸°(ì´ˆ)', f'{interval:.1f}')

    with st.form('bot_control_form'):
        desired_interval = st.number_input('ë¦¬í”Œë ˆì´ ì£¼ê¸° (ì´ˆ)', min_value=0.5, value=interval, step=0.5)
        col1, col2, col3 = st.columns(3)
        start = col1.form_submit_button('ë´‡ ì‹œì‘')
        stop = col2.form_submit_button('ë´‡ ì¤‘ì§€')
        update = col3.form_submit_button('ì£¼ê¸° ì €ì¥')
        if start:
            _, err = update_bot_control_api(enabled=True, interval_sec=desired_interval)
            if err:
                st.error(f'ì‹œì‘ ì‹¤íŒ¨: {err}')
            else:
                st.success('ë´‡ ì‹œì‘ ìš”ì²­ ì™„ë£Œ')
                _trigger_rerun()
        if stop:
            _, err = update_bot_control_api(enabled=False)
            if err:
                st.error(f'ì¤‘ì§€ ì‹¤íŒ¨: {err}')
            else:
                st.warning('ë´‡ ì •ì§€ ìš”ì²­ ì™„ë£Œ')
                _trigger_rerun()
        if update:
            _, err = update_bot_control_api(interval_sec=desired_interval)
            if err:
                st.error(f'ì£¼ê¸° ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {err}')
            else:
                st.success('ì£¼ê¸°ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤.')
                _trigger_rerun()

    st.caption('ì„¤ì •ì„ ë°”ê¾¼ ì´í›„ì—ëŠ” trading_bot ë˜ëŠ” config ì¬ë¡œë”©ì„ í™•ì¸í•˜ì„¸ìš”.')


def render_ai_report_page():
    st.title('AI ìë¬¸ ë¦¬í¬íŠ¸')
    st.caption('OpenAIì™€ Geminiê°€ ë‚´ë¦° ìµœì‹  ìë¬¸ ê²°ê³¼ë¥¼ í•œëˆˆì— í™•ì¸í•©ë‹ˆë‹¤.')

    history_payload, history_err = fetch_ai_history(limit=100)
    if history_err:
        st.error(f'AI ìë¬¸ ì´ë ¥ ì¡°íšŒ ì‹¤íŒ¨: {history_err}')
        return

    items = history_payload.get('items') if isinstance(history_payload, dict) else None
    if not items:
        st.info('AI ìë¬¸ ì´ë ¥ì´ ì•„ì§ ì—†ìŠµë‹ˆë‹¤. ë´‡ì„ ì‹¤í–‰í•´ ê¸°ë¡ì„ ìŒ“ì•„ì£¼ì„¸ìš”.')
        return

    latest = items[-1]
    openai_payload = _get_ai_source_payload(latest, 'openai')
    gemini_payload = _get_ai_source_payload(latest, 'gemini')
    latest_ts = _format_ts_kst(latest.get('ts'))
    st.subheader(f'1) ìµœì‹  ìë¬¸ ë¹„êµ (ìƒì„±: {latest_ts})')
    latest_cols = st.columns(2, gap='large')

    def _render_model_card(col, label: str, payload: Dict[str, Any] | None):
        with col:
            st.markdown(f"### {label}")
            if not payload:
                st.info('ë°ì´í„° ì—†ìŒ')
                return
            decision = payload.get('decision') or payload.get('action') or 'N/A'
            st.metric('ê²°ì •', decision)
            confidence = _get_ai_confidence(payload)
            conf_str = _format_confidence(confidence)
            if conf_str != '-':
                st.caption(f"ì‹ ë¢°ë„: {conf_str}")
            st.caption(f"ëª¨ë¸: {payload.get('model', '-')}")
            reasoning = payload.get('reason') or payload.get('reasoning')
            if reasoning:
                st.write(reasoning)
            with st.expander('ì›ë¬¸ JSON ë³´ê¸°', expanded=False):
                st.json(payload)

    _render_model_card(latest_cols[0], 'OpenAI', openai_payload)
    _render_model_card(latest_cols[1], 'Gemini', gemini_payload)

    st.subheader('2) ì…ë ¥ ìº”ë“¤ ì°¨íŠ¸')
    chart_df = _prepare_ai_chart_df(latest)
    if chart_df is None or chart_df.empty:
        st.info('ì°¨íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ ê¸°ë¡ì—ì„œëŠ” `klines` í•„ë“œê°€ ë¹„ì–´ ìˆìœ¼ë¯€ë¡œ ì°¨íŠ¸ë¥¼ ê·¸ë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. `runtime/history/ai_decisions.json`ì„ í™•ì¸í•´ì„œ ì‹¤ì œ ìº”ë“¤ ë°ì´í„°ë¥¼ í¬í•¨í•˜ë„ë¡ ë´‡ ì„¤ì •ì„ ì¡°ì •í•˜ì„¸ìš”.')
    else:
        chart_fig = plot_candles_with_indicators(chart_df, cfg.get('market', 'KRW-BTC'), ma_windows=[20, 60], rsi_period=14)
        chart_fig.update_layout(height=520)
        _safe_plotly_chart(chart_fig)

    st.subheader('3) ì…ë ¥ ì „ë¬¸')
    with st.expander('ì…ë ¥ JSON', expanded=False):
        context_payload = latest.get('context') or {}
        if isinstance(context_payload, str):
            context_payload = _parse_json_field(context_payload)
        st.json(context_payload)

    st.subheader('4) ìë¬¸ íˆìŠ¤í† ë¦¬')
    st.caption('í–‰ì„ í´ë¦­í•˜ë©´ ì•„ë˜ì—ì„œ ìƒì„¸ ë‚´ì—­ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.')

    # íˆìŠ¤í† ë¦¬ í…Œì´ë¸” ìƒì„± (ì—­ìˆœìœ¼ë¡œ í‘œì‹œ)
    history_rows = []
    reversed_items = list(reversed(items))
    for idx, item in enumerate(reversed_items):
        history_openai = _get_ai_source_payload(item, 'openai')
        history_gemini = _get_ai_source_payload(item, 'gemini')
        history_rows.append({
            'ì„ íƒ': idx,
            'ì‹œê°(KST)': _format_ts_kst(item.get('ts')),
            'ìµœì¢… ê²°ì •': item.get('decision'),
            'ì‚¬ìœ ': (item.get('reason') or '')[:50] + '...' if len(item.get('reason') or '') > 50 else (item.get('reason') or '-'),
            'OpenAI': history_openai.get('decision') if history_openai else '-',
            'OpenAI ì‹ ë¢°ë„': _format_confidence(_get_ai_confidence(history_openai)) if history_openai else '-',
            'Gemini': history_gemini.get('decision') if history_gemini else '-',
            'Gemini ì‹ ë¢°ë„': _format_confidence(_get_ai_confidence(history_gemini)) if history_gemini else '-',
        })

    df_history = pd.DataFrame(history_rows)

    # ë°ì´í„°í”„ë ˆì„ í‘œì‹œ ë° í–‰ ì„ íƒ
    event = st.dataframe(
        df_history.fillna('-'),
        hide_index=True,
        on_select='rerun',
        selection_mode='single-row',
        use_container_width=True,
    )

    # ì„ íƒëœ í–‰ì´ ìˆìœ¼ë©´ ìƒì„¸ ë‚´ì—­ í‘œì‹œ
    if event and hasattr(event, 'selection') and event.selection and event.selection.get('rows'):
        selected_idx = event.selection['rows'][0]
        selected_item = reversed_items[selected_idx]

        st.divider()
        st.subheader('ğŸ“‹ ì„ íƒí•œ ìë¬¸ ìƒì„¸ ë‚´ì—­')

        # ë‘ ì»¬ëŸ¼ìœ¼ë¡œ OpenAIì™€ Gemini ìƒì„¸ ë‚´ì—­ í‘œì‹œ
        detail_cols = st.columns(2, gap='large')

        selected_openai = _get_ai_source_payload(selected_item, 'openai')
        selected_gemini = _get_ai_source_payload(selected_item, 'gemini')

        def _render_detailed_card(col, label: str, payload: Dict[str, Any] | None):
            with col:
                st.markdown(f"#### {label}")
                if not payload:
                    st.info('ë°ì´í„° ì—†ìŒ')
                    return

                decision = payload.get('decision') or payload.get('action') or 'N/A'
                confidence = _get_ai_confidence(payload)

                col_metrics = st.columns(2)
                col_metrics[0].metric('ê²°ì •', decision)
                if confidence is not None:
                    col_metrics[1].metric('ì‹ ë¢°ë„', _format_confidence(confidence))

                st.caption(f"ëª¨ë¸: {payload.get('model', '-')}")

                # ìƒì„¸ ì´ìœ  í‘œì‹œ
                reason = payload.get('reason') or payload.get('reasoning')
                if reason:
                    st.markdown('**ê²°ì • ê·¼ê±°:**')
                    st.write(reason)

                # ê°€ê²© ê³„íš í‘œì‹œ
                raw_data = payload.get('raw')
                if raw_data and isinstance(raw_data, dict):
                    decisions = raw_data.get('decisions')
                    if decisions and isinstance(decisions, list) and len(decisions) > 0:
                        decision_detail = decisions[0]
                        risk_mgmt = decision_detail.get('risk_management')
                        if risk_mgmt:
                            st.markdown('**ë¦¬ìŠ¤í¬ ê´€ë¦¬:**')
                            if risk_mgmt.get('stop_loss'):
                                st.write(f"â€¢ ì†ì ˆ: {risk_mgmt['stop_loss']}")
                            if risk_mgmt.get('take_profit'):
                                st.write(f"â€¢ ìµì ˆ: {risk_mgmt['take_profit']}")
                            if risk_mgmt.get('notes'):
                                st.caption(risk_mgmt['notes'])

                # JSON ì›ë¬¸
                with st.expander('ì „ì²´ JSON ë³´ê¸°', expanded=False):
                    st.json(payload)

        _render_detailed_card(detail_cols[0], 'OpenAI ìƒì„¸', selected_openai)
        _render_detailed_card(detail_cols[1], 'Gemini ìƒì„¸', selected_gemini)

        # ì…ë ¥ ì»¨í…ìŠ¤íŠ¸ í‘œì‹œ
        st.markdown('#### ì…ë ¥ ë°ì´í„°')
        with st.expander('ì…ë ¥ ì»¨í…ìŠ¤íŠ¸ JSON', expanded=False):
            context_payload = selected_item.get('context') or {}
            if isinstance(context_payload, str):
                context_payload = _parse_json_field(context_payload)
            st.json(context_payload)


def _format_confidence(value: Any) -> str:
    if value is None:
        return '-'
    try:
        val = float(value)
    except Exception:
        return str(value)
    if val > 1:
        return f"{val:.1f}%"
    return f"{val * 100:.1f}%"


def _format_ts_kst(ts: Any) -> str:
    if ts is None:
        return '-'
    try:
        value = float(ts)
    except Exception:
        return '-'
    if value > 1e12:
        value /= 1000.0
    dt = pd.to_datetime(value, unit='s', utc=True)
    try:
        dt = dt.tz_convert('Asia/Seoul')
    except Exception:
        dt = dt.tz_localize('Asia/Seoul', ambiguous='NaT', nonexistent='shift_forward')
    return dt.strftime('%Y-%m-%d %H:%M:%S')


def _parse_json_field(value: Any) -> Any:
    if isinstance(value, str):
        try:
            return json.loads(value)
        except Exception:
            return value
    return value


def _get_ai_source_payload(entry: Dict[str, Any], provider: str) -> Optional[Dict[str, Any]]:
    payload = entry.get(provider)
    if isinstance(payload, dict):
        return payload
    sources = entry.get('ai_sources') or {}
    return sources.get(provider) if isinstance(sources, dict) else None


def _get_ai_confidence(payload: Any) -> Optional[float]:
    if payload is None:
        return None
    if isinstance(payload, dict) and payload.get('confidence') is not None:
        return payload.get('confidence')
    if isinstance(payload, dict):
        raw = payload.get('raw')
        if raw is not None:
            conf = _get_ai_confidence(raw)
            if conf is not None:
                return conf
    if isinstance(payload, dict):
        for value in payload.values():
            conf = _get_ai_confidence(value)
            if conf is not None:
                return conf
    if isinstance(payload, list):
        for item in payload:
            conf = _get_ai_confidence(item)
            if conf is not None:
                return conf
    return None


def _prepare_ai_chart_df(entry: Dict[str, Any]) -> pd.DataFrame | None:
    klines = entry.get('klines')
    if isinstance(klines, str):
        klines = _parse_json_field(klines)
    if not klines:
        context = entry.get('context') or {}
        if isinstance(context, str):
            context = _parse_json_field(context) or {}
        markets = isinstance(context, dict) and context.get('markets') or []
        if markets:
            market = markets[0]
            timeframe = market.get('timeframes', {})
            for tf_cfg in timeframe.values():
                candles = tf_cfg.get('candles') or tf_cfg.get('history') or tf_cfg.get('klines')
                if candles:
                    klines = candles
                    break
        if not klines:
            return None
    try:
        df = pd.DataFrame(klines)
    except Exception:
        return None
    rename_map = {
        't': 'time',
        'candle_date_time_kst': 'time',
        'trade_price': 'close',
        'opening_price': 'open',
        'high_price': 'high',
        'low_price': 'low',
        'volume': 'volume',
    }
    df = df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns})
    if 'time' not in df.columns:
        return None
    try:
        df['time'] = pd.to_datetime(df['time'], utc=True)
        try:
            df['time'] = df['time'].dt.tz_convert('Asia/Seoul')
        except Exception:
            df['time'] = df['time'].dt.tz_localize('Asia/Seoul', ambiguous='NaT', nonexistent='shift_forward')
    except Exception:
        try:
            df['time'] = pd.to_datetime(df['time'].astype(str), utc=True)
            try:
                df['time'] = df['time'].dt.tz_convert('Asia/Seoul')
            except Exception:
                df['time'] = df['time'].dt.tz_localize('Asia/Seoul', ambiguous='NaT', nonexistent='shift_forward')
        except Exception:
            return None
    for col in ['open', 'high', 'low', 'close', 'volume']:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
    df = df.sort_values('time').dropna(subset=['time']).reset_index(drop=True)
    if df.empty:
        return None
    return df


# --- Main app logic ---
# Sidebar button menu for page selection (user prefers buttons, fixed order)
sb = st.sidebar
sb.title('ì—…ë¹„íŠ¸ íŠ¸ë ˆì´ë”')
sb.caption('ì›í•˜ëŠ” ê¸°ëŠ¥ìœ¼ë¡œ ë°”ë¡œ ê°€ê¸°')

# Fixed NAV order requested by user
NAV_OPTIONS = [
    'WebSocket ëª¨ë‹ˆí„°ë§',
    'ì¢…ëª©ìŠ¤í¬ë¦¬ë‹',
    'AI ìë¬¸ ë¦¬í¬íŠ¸',
    'ìë™ë§¤ë§¤ë´‡ ê´€ë¦¬',
    'ì›í™”ì”ê³  ë° í¬ì§€ì…˜ ë¶„ì„',
    'ì„¤ì • í¸ì§‘',
]

# Ensure page state exists
if 'page' not in st.session_state:
    st.session_state['page'] = NAV_OPTIONS[0]

selected_tab = st.session_state['page']
nav_container = sb.container()
pending_selection = None
for nav_option in NAV_OPTIONS:
    is_selected = selected_tab == nav_option
    btn_type = 'primary' if is_selected else 'secondary'
    try:
        clicked = nav_container.button(
            nav_option,
            key=f"nav_btn_{nav_option.replace(' ', '_')}",
            width='stretch',
            type=btn_type,
        )
    except TypeError:
        # Older Streamlit doesn't support `type` or `width` kwargs; try fallbacks
        try:
            clicked = nav_container.button(nav_option, key=f"nav_btn_{nav_option.replace(' ', '_')}", use_container_width=True)
        except Exception:
            clicked = nav_container.button(nav_option, key=f"nav_btn_{nav_option.replace(' ', '_')}")
    if clicked:
        pending_selection = nav_option

if pending_selection and pending_selection != selected_tab:
    st.session_state['page'] = pending_selection
    # trigger a rerun so UI reflects selection immediately
    try:
        rerun_fn = getattr(st, 'rerun', None) or getattr(st, 'experimental_rerun', None)
        if rerun_fn:
            rerun_fn()
    except Exception:
        pass

# page dispatch using session state
page = st.session_state.get('page', NAV_OPTIONS[0])
if page == 'WebSocket ëª¨ë‹ˆí„°ë§':
    render_ws_monitoring_page()
elif page == 'ì¢…ëª©ìŠ¤í¬ë¦¬ë‹':
    render_screening_page()
elif page == 'AI ìë¬¸ ë¦¬í¬íŠ¸':
    render_ai_report_page()
elif page == 'ì›í™”ì”ê³  ë° í¬ì§€ì…˜ ë¶„ì„':
    try:
        render_positions_page()
    except Exception as e:
        st.error(f'ì›í™”ì”ê³ /í¬ì§€ì…˜ í˜ì´ì§€ ë Œë”ë§ ì¤‘ ì˜¤ë¥˜: {e}')
elif page == 'ì„¤ì • í¸ì§‘':
    render_config_page(cfg)
elif page == 'ìë™ë§¤ë§¤ë´‡ ê´€ë¦¬':
    render_bot_control_page()
